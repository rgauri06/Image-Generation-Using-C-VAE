{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MATH7017 Prababilistic Graphical Models\n",
        "### ---Final Project---\n",
        "#### Student Name - Gauri Ratawal\n",
        "#### Student ID - 22032967"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgvkZ1Pl2heW",
        "outputId": "bcd8055d-f506-4efb-ee9a-acb8d73aa90a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2heWnNkE2gOC",
        "outputId": "60029c46-5039-4ac2-92d8-41256c14c3fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3y8fy2wa2eUk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Defining C-VAE Architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CvN9gpiv2eUm"
      },
      "outputs": [],
      "source": [
        "# Define the Conditional VAE\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, label_dim, style_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.label_dim = label_dim\n",
        "        self.style_dim = style_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.fc1 = nn.Linear(input_dim + label_dim + style_dim, hidden_dim)\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc3 = nn.Linear(latent_dim + label_dim + style_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    def encode(self, x, labels, styles):\n",
        "        x = torch.cat([x, labels, styles], dim=1)\n",
        "        h = F.relu(self.fc1(x))\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, labels, styles):\n",
        "        z = torch.cat([z, labels, styles], dim=1)\n",
        "        h = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h))\n",
        "\n",
        "    def forward(self, x, labels, styles):\n",
        "        mu, logvar = self.encode(x.view(-1, self.input_dim), labels, styles)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z, labels, styles), mu, logvar\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading and processing data sets for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9VjR3ATF2eUn"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "train_imgs = np.load('k49-train-imgs.npz')['arr_0']\n",
        "train_labels = np.load('k49-train-labels.npz')['arr_0']\n",
        "train_styles = np.load('k49-train-style.npz')['styles']\n",
        "test_imgs = np.load('k49-test-imgs.npz')['arr_0']\n",
        "test_labels = np.load('k49-test-labels.npz')['arr_0']\n",
        "test_styles = np.load('k49-test-style.npz')['styles']\n",
        "\n",
        "# Normalize images\n",
        "train_imgs = train_imgs.astype('float32') / 255.\n",
        "test_imgs = test_imgs.astype('float32') / 255.\n",
        "\n",
        "# Flatten images\n",
        "train_imgs = train_imgs.reshape(-1, 784)\n",
        "test_imgs = test_imgs.reshape(-1, 784)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_imgs = torch.tensor(train_imgs, dtype=torch.float32)\n",
        "test_imgs = torch.tensor(test_imgs, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
        "train_styles = torch.tensor(train_styles, dtype=torch.float32).reshape(-1, 1)\n",
        "test_styles = torch.tensor(test_styles, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# One-hot encode labels\n",
        "train_labels_one_hot = F.one_hot(train_labels, num_classes=49).float()\n",
        "test_labels_one_hot = F.one_hot(test_labels, num_classes=49).float()\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 128\n",
        "train_dataset = TensorDataset(train_imgs, train_labels_one_hot, train_styles)\n",
        "test_dataset = TensorDataset(test_imgs, test_labels_one_hot, test_styles)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initializing and Training C-VAE Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5KeUF4s2eUn",
        "outputId": "c9e69004-e281-466c-b607-1fbb76d5e3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train Epoch: 123 [194560/232365 (84%)]\tLoss: 157.086075\n",
            "Train Epoch: 123 [195840/232365 (84%)]\tLoss: 179.338425\n",
            "Train Epoch: 123 [197120/232365 (85%)]\tLoss: 171.140915\n",
            "Train Epoch: 123 [198400/232365 (85%)]\tLoss: 176.190720\n",
            "Train Epoch: 123 [199680/232365 (86%)]\tLoss: 173.300568\n",
            "Train Epoch: 123 [200960/232365 (86%)]\tLoss: 183.700180\n",
            "Train Epoch: 123 [202240/232365 (87%)]\tLoss: 171.659348\n",
            "Train Epoch: 123 [203520/232365 (88%)]\tLoss: 156.350311\n",
            "Train Epoch: 123 [204800/232365 (88%)]\tLoss: 173.683334\n",
            "Train Epoch: 123 [206080/232365 (89%)]\tLoss: 176.326553\n",
            "Train Epoch: 123 [207360/232365 (89%)]\tLoss: 176.865799\n",
            "Train Epoch: 123 [208640/232365 (90%)]\tLoss: 169.273788\n",
            "Train Epoch: 123 [209920/232365 (90%)]\tLoss: 180.783417\n",
            "Train Epoch: 123 [211200/232365 (91%)]\tLoss: 175.411179\n",
            "Train Epoch: 123 [212480/232365 (91%)]\tLoss: 173.140411\n",
            "Train Epoch: 123 [213760/232365 (92%)]\tLoss: 167.293503\n",
            "Train Epoch: 123 [215040/232365 (93%)]\tLoss: 166.085724\n",
            "Train Epoch: 123 [216320/232365 (93%)]\tLoss: 177.394836\n",
            "Train Epoch: 123 [217600/232365 (94%)]\tLoss: 182.436081\n",
            "Train Epoch: 123 [218880/232365 (94%)]\tLoss: 173.760300\n",
            "Train Epoch: 123 [220160/232365 (95%)]\tLoss: 170.416412\n",
            "Train Epoch: 123 [221440/232365 (95%)]\tLoss: 172.572357\n",
            "Train Epoch: 123 [222720/232365 (96%)]\tLoss: 175.263657\n",
            "Train Epoch: 123 [224000/232365 (96%)]\tLoss: 181.129639\n",
            "Train Epoch: 123 [225280/232365 (97%)]\tLoss: 170.342773\n",
            "Train Epoch: 123 [226560/232365 (97%)]\tLoss: 166.977264\n",
            "Train Epoch: 123 [227840/232365 (98%)]\tLoss: 171.661285\n",
            "Train Epoch: 123 [229120/232365 (99%)]\tLoss: 177.869980\n",
            "Train Epoch: 123 [230400/232365 (99%)]\tLoss: 174.470352\n",
            "Train Epoch: 123 [231680/232365 (100%)]\tLoss: 173.951141\n",
            "====> Epoch: 123 Average loss: 172.6293, Accuracy: 74.23%\n",
            "====> Test set loss: 183.4922, Accuracy: 74.13%\n",
            "Train Epoch: 124 [0/232365 (0%)]\tLoss: 171.747025\n",
            "Train Epoch: 124 [1280/232365 (1%)]\tLoss: 167.979889\n",
            "Train Epoch: 124 [2560/232365 (1%)]\tLoss: 184.187424\n",
            "Train Epoch: 124 [3840/232365 (2%)]\tLoss: 164.345596\n",
            "Train Epoch: 124 [5120/232365 (2%)]\tLoss: 173.366440\n",
            "Train Epoch: 124 [6400/232365 (3%)]\tLoss: 167.709457\n",
            "Train Epoch: 124 [7680/232365 (3%)]\tLoss: 162.111771\n",
            "Train Epoch: 124 [8960/232365 (4%)]\tLoss: 170.811295\n",
            "Train Epoch: 124 [10240/232365 (4%)]\tLoss: 167.842133\n",
            "Train Epoch: 124 [11520/232365 (5%)]\tLoss: 177.118240\n",
            "Train Epoch: 124 [12800/232365 (6%)]\tLoss: 177.199570\n",
            "Train Epoch: 124 [14080/232365 (6%)]\tLoss: 170.395126\n",
            "Train Epoch: 124 [15360/232365 (7%)]\tLoss: 177.288116\n",
            "Train Epoch: 124 [16640/232365 (7%)]\tLoss: 174.779236\n",
            "Train Epoch: 124 [17920/232365 (8%)]\tLoss: 172.210800\n",
            "Train Epoch: 124 [19200/232365 (8%)]\tLoss: 175.312500\n",
            "Train Epoch: 124 [20480/232365 (9%)]\tLoss: 168.871964\n",
            "Train Epoch: 124 [21760/232365 (9%)]\tLoss: 173.101730\n",
            "Train Epoch: 124 [23040/232365 (10%)]\tLoss: 168.714905\n",
            "Train Epoch: 124 [24320/232365 (10%)]\tLoss: 170.110245\n",
            "Train Epoch: 124 [25600/232365 (11%)]\tLoss: 171.434708\n",
            "Train Epoch: 124 [26880/232365 (12%)]\tLoss: 180.099335\n",
            "Train Epoch: 124 [28160/232365 (12%)]\tLoss: 175.872925\n",
            "Train Epoch: 124 [29440/232365 (13%)]\tLoss: 174.904556\n",
            "Train Epoch: 124 [30720/232365 (13%)]\tLoss: 175.351532\n",
            "Train Epoch: 124 [32000/232365 (14%)]\tLoss: 164.407120\n",
            "Train Epoch: 124 [33280/232365 (14%)]\tLoss: 160.197311\n",
            "Train Epoch: 124 [34560/232365 (15%)]\tLoss: 166.084442\n",
            "Train Epoch: 124 [35840/232365 (15%)]\tLoss: 169.809296\n",
            "Train Epoch: 124 [37120/232365 (16%)]\tLoss: 173.886459\n",
            "Train Epoch: 124 [38400/232365 (17%)]\tLoss: 173.647354\n",
            "Train Epoch: 124 [39680/232365 (17%)]\tLoss: 165.596024\n",
            "Train Epoch: 124 [40960/232365 (18%)]\tLoss: 180.590042\n",
            "Train Epoch: 124 [42240/232365 (18%)]\tLoss: 175.619003\n",
            "Train Epoch: 124 [43520/232365 (19%)]\tLoss: 167.955582\n",
            "Train Epoch: 124 [44800/232365 (19%)]\tLoss: 165.965469\n",
            "Train Epoch: 124 [46080/232365 (20%)]\tLoss: 172.857422\n",
            "Train Epoch: 124 [47360/232365 (20%)]\tLoss: 179.497803\n",
            "Train Epoch: 124 [48640/232365 (21%)]\tLoss: 171.508896\n",
            "Train Epoch: 124 [49920/232365 (21%)]\tLoss: 181.751328\n",
            "Train Epoch: 124 [51200/232365 (22%)]\tLoss: 171.406921\n",
            "Train Epoch: 124 [52480/232365 (23%)]\tLoss: 178.442947\n",
            "Train Epoch: 124 [53760/232365 (23%)]\tLoss: 177.321686\n",
            "Train Epoch: 124 [55040/232365 (24%)]\tLoss: 177.634186\n",
            "Train Epoch: 124 [56320/232365 (24%)]\tLoss: 167.595398\n",
            "Train Epoch: 124 [57600/232365 (25%)]\tLoss: 171.467407\n",
            "Train Epoch: 124 [58880/232365 (25%)]\tLoss: 163.077591\n",
            "Train Epoch: 124 [60160/232365 (26%)]\tLoss: 182.615433\n",
            "Train Epoch: 124 [61440/232365 (26%)]\tLoss: 168.905991\n",
            "Train Epoch: 124 [62720/232365 (27%)]\tLoss: 181.758163\n",
            "Train Epoch: 124 [64000/232365 (28%)]\tLoss: 164.055634\n",
            "Train Epoch: 124 [65280/232365 (28%)]\tLoss: 169.790695\n",
            "Train Epoch: 124 [66560/232365 (29%)]\tLoss: 174.573151\n",
            "Train Epoch: 124 [67840/232365 (29%)]\tLoss: 175.195923\n",
            "Train Epoch: 124 [69120/232365 (30%)]\tLoss: 179.587128\n",
            "Train Epoch: 124 [70400/232365 (30%)]\tLoss: 172.200272\n",
            "Train Epoch: 124 [71680/232365 (31%)]\tLoss: 169.307220\n",
            "Train Epoch: 124 [72960/232365 (31%)]\tLoss: 173.572144\n",
            "Train Epoch: 124 [74240/232365 (32%)]\tLoss: 164.916229\n",
            "Train Epoch: 124 [75520/232365 (32%)]\tLoss: 172.396149\n",
            "Train Epoch: 124 [76800/232365 (33%)]\tLoss: 177.940704\n",
            "Train Epoch: 124 [78080/232365 (34%)]\tLoss: 172.685165\n",
            "Train Epoch: 124 [79360/232365 (34%)]\tLoss: 181.335129\n",
            "Train Epoch: 124 [80640/232365 (35%)]\tLoss: 177.747925\n",
            "Train Epoch: 124 [81920/232365 (35%)]\tLoss: 187.319153\n",
            "Train Epoch: 124 [83200/232365 (36%)]\tLoss: 169.360077\n",
            "Train Epoch: 124 [84480/232365 (36%)]\tLoss: 172.677704\n",
            "Train Epoch: 124 [85760/232365 (37%)]\tLoss: 180.673355\n",
            "Train Epoch: 124 [87040/232365 (37%)]\tLoss: 177.423492\n",
            "Train Epoch: 124 [88320/232365 (38%)]\tLoss: 171.484924\n",
            "Train Epoch: 124 [89600/232365 (39%)]\tLoss: 172.719910\n",
            "Train Epoch: 124 [90880/232365 (39%)]\tLoss: 174.519974\n",
            "Train Epoch: 124 [92160/232365 (40%)]\tLoss: 171.839371\n",
            "Train Epoch: 124 [93440/232365 (40%)]\tLoss: 165.106339\n",
            "Train Epoch: 124 [94720/232365 (41%)]\tLoss: 164.383667\n",
            "Train Epoch: 124 [96000/232365 (41%)]\tLoss: 173.105743\n",
            "Train Epoch: 124 [97280/232365 (42%)]\tLoss: 167.899200\n",
            "Train Epoch: 124 [98560/232365 (42%)]\tLoss: 172.365280\n",
            "Train Epoch: 124 [99840/232365 (43%)]\tLoss: 172.317596\n",
            "Train Epoch: 124 [101120/232365 (44%)]\tLoss: 171.980164\n",
            "Train Epoch: 124 [102400/232365 (44%)]\tLoss: 178.235931\n",
            "Train Epoch: 124 [103680/232365 (45%)]\tLoss: 168.526764\n",
            "Train Epoch: 124 [104960/232365 (45%)]\tLoss: 167.721039\n",
            "Train Epoch: 124 [106240/232365 (46%)]\tLoss: 160.322433\n",
            "Train Epoch: 124 [107520/232365 (46%)]\tLoss: 171.868988\n",
            "Train Epoch: 124 [108800/232365 (47%)]\tLoss: 169.592896\n",
            "Train Epoch: 124 [110080/232365 (47%)]\tLoss: 170.590652\n",
            "Train Epoch: 124 [111360/232365 (48%)]\tLoss: 171.953262\n",
            "Train Epoch: 124 [112640/232365 (48%)]\tLoss: 167.624146\n",
            "Train Epoch: 124 [113920/232365 (49%)]\tLoss: 169.027557\n",
            "Train Epoch: 124 [115200/232365 (50%)]\tLoss: 172.693069\n",
            "Train Epoch: 124 [116480/232365 (50%)]\tLoss: 173.762939\n",
            "Train Epoch: 124 [117760/232365 (51%)]\tLoss: 180.770538\n",
            "Train Epoch: 124 [119040/232365 (51%)]\tLoss: 168.647705\n",
            "Train Epoch: 124 [120320/232365 (52%)]\tLoss: 181.851624\n",
            "Train Epoch: 124 [121600/232365 (52%)]\tLoss: 179.159622\n",
            "Train Epoch: 124 [122880/232365 (53%)]\tLoss: 176.577881\n",
            "Train Epoch: 124 [124160/232365 (53%)]\tLoss: 175.817551\n",
            "Train Epoch: 124 [125440/232365 (54%)]\tLoss: 169.775665\n",
            "Train Epoch: 124 [126720/232365 (55%)]\tLoss: 164.228622\n",
            "Train Epoch: 124 [128000/232365 (55%)]\tLoss: 175.566162\n",
            "Train Epoch: 124 [129280/232365 (56%)]\tLoss: 166.456207\n",
            "Train Epoch: 124 [130560/232365 (56%)]\tLoss: 173.982529\n",
            "Train Epoch: 124 [131840/232365 (57%)]\tLoss: 159.771698\n",
            "Train Epoch: 124 [133120/232365 (57%)]\tLoss: 178.445694\n",
            "Train Epoch: 124 [134400/232365 (58%)]\tLoss: 171.196030\n",
            "Train Epoch: 124 [135680/232365 (58%)]\tLoss: 169.959702\n",
            "Train Epoch: 124 [136960/232365 (59%)]\tLoss: 171.081696\n",
            "Train Epoch: 124 [138240/232365 (59%)]\tLoss: 169.277451\n",
            "Train Epoch: 124 [139520/232365 (60%)]\tLoss: 172.198288\n",
            "Train Epoch: 124 [140800/232365 (61%)]\tLoss: 178.398270\n",
            "Train Epoch: 124 [142080/232365 (61%)]\tLoss: 168.097351\n",
            "Train Epoch: 124 [143360/232365 (62%)]\tLoss: 173.248627\n",
            "Train Epoch: 124 [144640/232365 (62%)]\tLoss: 169.093842\n",
            "Train Epoch: 124 [145920/232365 (63%)]\tLoss: 172.716522\n",
            "Train Epoch: 124 [147200/232365 (63%)]\tLoss: 172.525864\n",
            "Train Epoch: 124 [148480/232365 (64%)]\tLoss: 167.272369\n",
            "Train Epoch: 124 [149760/232365 (64%)]\tLoss: 168.513550\n",
            "Train Epoch: 124 [151040/232365 (65%)]\tLoss: 177.107300\n",
            "Train Epoch: 124 [152320/232365 (66%)]\tLoss: 166.592804\n",
            "Train Epoch: 124 [153600/232365 (66%)]\tLoss: 169.011673\n",
            "Train Epoch: 124 [154880/232365 (67%)]\tLoss: 164.787796\n",
            "Train Epoch: 124 [156160/232365 (67%)]\tLoss: 169.887970\n",
            "Train Epoch: 124 [157440/232365 (68%)]\tLoss: 172.743500\n",
            "Train Epoch: 124 [158720/232365 (68%)]\tLoss: 177.061417\n",
            "Train Epoch: 124 [160000/232365 (69%)]\tLoss: 171.288467\n",
            "Train Epoch: 124 [161280/232365 (69%)]\tLoss: 165.897369\n",
            "Train Epoch: 124 [162560/232365 (70%)]\tLoss: 173.878052\n",
            "Train Epoch: 124 [163840/232365 (70%)]\tLoss: 175.595016\n",
            "Train Epoch: 124 [165120/232365 (71%)]\tLoss: 164.957062\n",
            "Train Epoch: 124 [166400/232365 (72%)]\tLoss: 177.905640\n",
            "Train Epoch: 124 [167680/232365 (72%)]\tLoss: 171.702652\n",
            "Train Epoch: 124 [168960/232365 (73%)]\tLoss: 171.966873\n",
            "Train Epoch: 124 [170240/232365 (73%)]\tLoss: 184.188477\n",
            "Train Epoch: 124 [171520/232365 (74%)]\tLoss: 164.204086\n",
            "Train Epoch: 124 [172800/232365 (74%)]\tLoss: 177.812744\n",
            "Train Epoch: 124 [174080/232365 (75%)]\tLoss: 190.882935\n",
            "Train Epoch: 124 [175360/232365 (75%)]\tLoss: 162.850876\n",
            "Train Epoch: 124 [176640/232365 (76%)]\tLoss: 163.549744\n",
            "Train Epoch: 124 [177920/232365 (77%)]\tLoss: 166.220306\n",
            "Train Epoch: 124 [179200/232365 (77%)]\tLoss: 173.575226\n",
            "Train Epoch: 124 [180480/232365 (78%)]\tLoss: 175.462280\n",
            "Train Epoch: 124 [181760/232365 (78%)]\tLoss: 165.389542\n",
            "Train Epoch: 124 [183040/232365 (79%)]\tLoss: 168.776718\n",
            "Train Epoch: 124 [184320/232365 (79%)]\tLoss: 167.236893\n",
            "Train Epoch: 124 [185600/232365 (80%)]\tLoss: 172.125061\n",
            "Train Epoch: 124 [186880/232365 (80%)]\tLoss: 166.689102\n",
            "Train Epoch: 124 [188160/232365 (81%)]\tLoss: 174.876205\n",
            "Train Epoch: 124 [189440/232365 (81%)]\tLoss: 178.328049\n",
            "Train Epoch: 124 [190720/232365 (82%)]\tLoss: 174.735306\n",
            "Train Epoch: 124 [192000/232365 (83%)]\tLoss: 178.420013\n",
            "Train Epoch: 124 [193280/232365 (83%)]\tLoss: 177.190521\n",
            "Train Epoch: 124 [194560/232365 (84%)]\tLoss: 175.126617\n",
            "Train Epoch: 124 [195840/232365 (84%)]\tLoss: 170.890167\n",
            "Train Epoch: 124 [197120/232365 (85%)]\tLoss: 169.819366\n",
            "Train Epoch: 124 [198400/232365 (85%)]\tLoss: 173.008286\n",
            "Train Epoch: 124 [199680/232365 (86%)]\tLoss: 177.429886\n",
            "Train Epoch: 124 [200960/232365 (86%)]\tLoss: 183.456955\n",
            "Train Epoch: 124 [202240/232365 (87%)]\tLoss: 172.536682\n",
            "Train Epoch: 124 [203520/232365 (88%)]\tLoss: 165.485519\n",
            "Train Epoch: 124 [204800/232365 (88%)]\tLoss: 162.563217\n",
            "Train Epoch: 124 [206080/232365 (89%)]\tLoss: 172.616837\n",
            "Train Epoch: 124 [207360/232365 (89%)]\tLoss: 164.407410\n",
            "Train Epoch: 124 [208640/232365 (90%)]\tLoss: 169.773743\n",
            "Train Epoch: 124 [209920/232365 (90%)]\tLoss: 166.463867\n",
            "Train Epoch: 124 [211200/232365 (91%)]\tLoss: 170.648483\n",
            "Train Epoch: 124 [212480/232365 (91%)]\tLoss: 173.242889\n",
            "Train Epoch: 124 [213760/232365 (92%)]\tLoss: 164.681915\n",
            "Train Epoch: 124 [215040/232365 (93%)]\tLoss: 173.293030\n",
            "Train Epoch: 124 [216320/232365 (93%)]\tLoss: 175.128372\n",
            "Train Epoch: 124 [217600/232365 (94%)]\tLoss: 163.797806\n",
            "Train Epoch: 124 [218880/232365 (94%)]\tLoss: 169.634598\n",
            "Train Epoch: 124 [220160/232365 (95%)]\tLoss: 165.179932\n",
            "Train Epoch: 124 [221440/232365 (95%)]\tLoss: 175.535248\n",
            "Train Epoch: 124 [222720/232365 (96%)]\tLoss: 172.330109\n",
            "Train Epoch: 124 [224000/232365 (96%)]\tLoss: 177.389557\n",
            "Train Epoch: 124 [225280/232365 (97%)]\tLoss: 173.213776\n",
            "Train Epoch: 124 [226560/232365 (97%)]\tLoss: 168.756927\n",
            "Train Epoch: 124 [227840/232365 (98%)]\tLoss: 175.044373\n",
            "Train Epoch: 124 [229120/232365 (99%)]\tLoss: 176.062820\n",
            "Train Epoch: 124 [230400/232365 (99%)]\tLoss: 173.235367\n",
            "Train Epoch: 124 [231680/232365 (100%)]\tLoss: 174.203659\n",
            "====> Epoch: 124 Average loss: 172.5993, Accuracy: 74.23%\n",
            "====> Test set loss: 183.4511, Accuracy: 74.13%\n",
            "Train Epoch: 125 [0/232365 (0%)]\tLoss: 179.278915\n",
            "Train Epoch: 125 [1280/232365 (1%)]\tLoss: 168.154602\n",
            "Train Epoch: 125 [2560/232365 (1%)]\tLoss: 172.095840\n",
            "Train Epoch: 125 [3840/232365 (2%)]\tLoss: 162.199310\n",
            "Train Epoch: 125 [5120/232365 (2%)]\tLoss: 165.606247\n",
            "Train Epoch: 125 [6400/232365 (3%)]\tLoss: 167.586395\n",
            "Train Epoch: 125 [7680/232365 (3%)]\tLoss: 172.259384\n",
            "Train Epoch: 125 [8960/232365 (4%)]\tLoss: 169.584473\n",
            "Train Epoch: 125 [10240/232365 (4%)]\tLoss: 171.103256\n",
            "Train Epoch: 125 [11520/232365 (5%)]\tLoss: 162.974289\n",
            "Train Epoch: 125 [12800/232365 (6%)]\tLoss: 174.237946\n",
            "Train Epoch: 125 [14080/232365 (6%)]\tLoss: 173.741470\n",
            "Train Epoch: 125 [15360/232365 (7%)]\tLoss: 170.916122\n",
            "Train Epoch: 125 [16640/232365 (7%)]\tLoss: 173.805817\n",
            "Train Epoch: 125 [17920/232365 (8%)]\tLoss: 160.023819\n",
            "Train Epoch: 125 [19200/232365 (8%)]\tLoss: 167.894577\n",
            "Train Epoch: 125 [20480/232365 (9%)]\tLoss: 172.759842\n",
            "Train Epoch: 125 [21760/232365 (9%)]\tLoss: 171.069016\n",
            "Train Epoch: 125 [23040/232365 (10%)]\tLoss: 173.998123\n",
            "Train Epoch: 125 [24320/232365 (10%)]\tLoss: 172.497162\n",
            "Train Epoch: 125 [25600/232365 (11%)]\tLoss: 178.855652\n",
            "Train Epoch: 125 [26880/232365 (12%)]\tLoss: 168.319550\n",
            "Train Epoch: 125 [28160/232365 (12%)]\tLoss: 170.616898\n",
            "Train Epoch: 125 [29440/232365 (13%)]\tLoss: 174.051193\n",
            "Train Epoch: 125 [30720/232365 (13%)]\tLoss: 170.681091\n",
            "Train Epoch: 125 [32000/232365 (14%)]\tLoss: 166.299240\n",
            "Train Epoch: 125 [33280/232365 (14%)]\tLoss: 179.701752\n",
            "Train Epoch: 125 [34560/232365 (15%)]\tLoss: 165.497849\n",
            "Train Epoch: 125 [35840/232365 (15%)]\tLoss: 163.872238\n",
            "Train Epoch: 125 [37120/232365 (16%)]\tLoss: 173.801071\n",
            "Train Epoch: 125 [38400/232365 (17%)]\tLoss: 172.818985\n",
            "Train Epoch: 125 [39680/232365 (17%)]\tLoss: 173.296417\n",
            "Train Epoch: 125 [40960/232365 (18%)]\tLoss: 173.330719\n",
            "Train Epoch: 125 [42240/232365 (18%)]\tLoss: 174.600098\n",
            "Train Epoch: 125 [43520/232365 (19%)]\tLoss: 171.229721\n",
            "Train Epoch: 125 [44800/232365 (19%)]\tLoss: 166.939484\n",
            "Train Epoch: 125 [46080/232365 (20%)]\tLoss: 174.029251\n",
            "Train Epoch: 125 [47360/232365 (20%)]\tLoss: 175.045959\n",
            "Train Epoch: 125 [48640/232365 (21%)]\tLoss: 184.746765\n",
            "Train Epoch: 125 [49920/232365 (21%)]\tLoss: 171.937042\n",
            "Train Epoch: 125 [51200/232365 (22%)]\tLoss: 174.108566\n",
            "Train Epoch: 125 [52480/232365 (23%)]\tLoss: 166.717102\n",
            "Train Epoch: 125 [53760/232365 (23%)]\tLoss: 170.143921\n",
            "Train Epoch: 125 [55040/232365 (24%)]\tLoss: 169.757904\n",
            "Train Epoch: 125 [56320/232365 (24%)]\tLoss: 171.096954\n",
            "Train Epoch: 125 [57600/232365 (25%)]\tLoss: 174.723434\n",
            "Train Epoch: 125 [58880/232365 (25%)]\tLoss: 178.105026\n",
            "Train Epoch: 125 [60160/232365 (26%)]\tLoss: 170.612625\n",
            "Train Epoch: 125 [61440/232365 (26%)]\tLoss: 172.524216\n",
            "Train Epoch: 125 [62720/232365 (27%)]\tLoss: 169.803238\n",
            "Train Epoch: 125 [64000/232365 (28%)]\tLoss: 167.390320\n",
            "Train Epoch: 125 [65280/232365 (28%)]\tLoss: 175.427322\n",
            "Train Epoch: 125 [66560/232365 (29%)]\tLoss: 178.039963\n",
            "Train Epoch: 125 [67840/232365 (29%)]\tLoss: 177.875031\n",
            "Train Epoch: 125 [69120/232365 (30%)]\tLoss: 174.149948\n",
            "Train Epoch: 125 [70400/232365 (30%)]\tLoss: 173.341766\n",
            "Train Epoch: 125 [71680/232365 (31%)]\tLoss: 171.183960\n",
            "Train Epoch: 125 [72960/232365 (31%)]\tLoss: 165.941193\n",
            "Train Epoch: 125 [74240/232365 (32%)]\tLoss: 171.670364\n",
            "Train Epoch: 125 [75520/232365 (32%)]\tLoss: 173.609924\n",
            "Train Epoch: 125 [76800/232365 (33%)]\tLoss: 166.660904\n",
            "Train Epoch: 125 [78080/232365 (34%)]\tLoss: 172.369293\n",
            "Train Epoch: 125 [79360/232365 (34%)]\tLoss: 166.511444\n",
            "Train Epoch: 125 [80640/232365 (35%)]\tLoss: 170.290451\n",
            "Train Epoch: 125 [81920/232365 (35%)]\tLoss: 170.696106\n",
            "Train Epoch: 125 [83200/232365 (36%)]\tLoss: 167.884872\n",
            "Train Epoch: 125 [84480/232365 (36%)]\tLoss: 171.749756\n",
            "Train Epoch: 125 [85760/232365 (37%)]\tLoss: 184.769821\n",
            "Train Epoch: 125 [87040/232365 (37%)]\tLoss: 171.745758\n",
            "Train Epoch: 125 [88320/232365 (38%)]\tLoss: 174.493225\n",
            "Train Epoch: 125 [89600/232365 (39%)]\tLoss: 168.087952\n",
            "Train Epoch: 125 [90880/232365 (39%)]\tLoss: 169.455917\n",
            "Train Epoch: 125 [92160/232365 (40%)]\tLoss: 165.745087\n",
            "Train Epoch: 125 [93440/232365 (40%)]\tLoss: 165.040237\n",
            "Train Epoch: 125 [94720/232365 (41%)]\tLoss: 167.381577\n",
            "Train Epoch: 125 [96000/232365 (41%)]\tLoss: 169.975555\n",
            "Train Epoch: 125 [97280/232365 (42%)]\tLoss: 176.022949\n",
            "Train Epoch: 125 [98560/232365 (42%)]\tLoss: 176.291000\n",
            "Train Epoch: 125 [99840/232365 (43%)]\tLoss: 176.119370\n",
            "Train Epoch: 125 [101120/232365 (44%)]\tLoss: 176.007080\n",
            "Train Epoch: 125 [102400/232365 (44%)]\tLoss: 163.177765\n",
            "Train Epoch: 125 [103680/232365 (45%)]\tLoss: 164.845032\n",
            "Train Epoch: 125 [104960/232365 (45%)]\tLoss: 174.058960\n",
            "Train Epoch: 125 [106240/232365 (46%)]\tLoss: 181.932892\n",
            "Train Epoch: 125 [107520/232365 (46%)]\tLoss: 172.007065\n",
            "Train Epoch: 125 [108800/232365 (47%)]\tLoss: 171.038956\n",
            "Train Epoch: 125 [110080/232365 (47%)]\tLoss: 179.340118\n",
            "Train Epoch: 125 [111360/232365 (48%)]\tLoss: 171.617661\n",
            "Train Epoch: 125 [112640/232365 (48%)]\tLoss: 179.872925\n",
            "Train Epoch: 125 [113920/232365 (49%)]\tLoss: 170.214813\n",
            "Train Epoch: 125 [115200/232365 (50%)]\tLoss: 173.296158\n",
            "Train Epoch: 125 [116480/232365 (50%)]\tLoss: 172.088287\n",
            "Train Epoch: 125 [117760/232365 (51%)]\tLoss: 171.321503\n",
            "Train Epoch: 125 [119040/232365 (51%)]\tLoss: 173.820633\n",
            "Train Epoch: 125 [120320/232365 (52%)]\tLoss: 177.922913\n",
            "Train Epoch: 125 [121600/232365 (52%)]\tLoss: 174.924271\n",
            "Train Epoch: 125 [122880/232365 (53%)]\tLoss: 178.482849\n",
            "Train Epoch: 125 [124160/232365 (53%)]\tLoss: 175.436874\n",
            "Train Epoch: 125 [125440/232365 (54%)]\tLoss: 165.669907\n",
            "Train Epoch: 125 [126720/232365 (55%)]\tLoss: 173.250916\n",
            "Train Epoch: 125 [128000/232365 (55%)]\tLoss: 172.489975\n",
            "Train Epoch: 125 [129280/232365 (56%)]\tLoss: 173.701355\n",
            "Train Epoch: 125 [130560/232365 (56%)]\tLoss: 170.226822\n",
            "Train Epoch: 125 [131840/232365 (57%)]\tLoss: 174.150543\n",
            "Train Epoch: 125 [133120/232365 (57%)]\tLoss: 171.303513\n",
            "Train Epoch: 125 [134400/232365 (58%)]\tLoss: 172.638824\n",
            "Train Epoch: 125 [135680/232365 (58%)]\tLoss: 173.629059\n",
            "Train Epoch: 125 [136960/232365 (59%)]\tLoss: 174.574783\n",
            "Train Epoch: 125 [138240/232365 (59%)]\tLoss: 181.386154\n",
            "Train Epoch: 125 [139520/232365 (60%)]\tLoss: 169.260956\n",
            "Train Epoch: 125 [140800/232365 (61%)]\tLoss: 174.842911\n",
            "Train Epoch: 125 [142080/232365 (61%)]\tLoss: 172.888153\n",
            "Train Epoch: 125 [143360/232365 (62%)]\tLoss: 171.303360\n",
            "Train Epoch: 125 [144640/232365 (62%)]\tLoss: 173.904266\n",
            "Train Epoch: 125 [145920/232365 (63%)]\tLoss: 176.315018\n",
            "Train Epoch: 125 [147200/232365 (63%)]\tLoss: 175.931625\n",
            "Train Epoch: 125 [148480/232365 (64%)]\tLoss: 177.846100\n",
            "Train Epoch: 125 [149760/232365 (64%)]\tLoss: 174.953156\n",
            "Train Epoch: 125 [151040/232365 (65%)]\tLoss: 177.783417\n",
            "Train Epoch: 125 [152320/232365 (66%)]\tLoss: 177.274780\n",
            "Train Epoch: 125 [153600/232365 (66%)]\tLoss: 166.052902\n",
            "Train Epoch: 125 [154880/232365 (67%)]\tLoss: 169.657303\n",
            "Train Epoch: 125 [156160/232365 (67%)]\tLoss: 170.495911\n",
            "Train Epoch: 125 [157440/232365 (68%)]\tLoss: 165.075027\n",
            "Train Epoch: 125 [158720/232365 (68%)]\tLoss: 172.250504\n",
            "Train Epoch: 125 [160000/232365 (69%)]\tLoss: 166.172058\n",
            "Train Epoch: 125 [161280/232365 (69%)]\tLoss: 168.802490\n",
            "Train Epoch: 125 [162560/232365 (70%)]\tLoss: 174.685791\n",
            "Train Epoch: 125 [163840/232365 (70%)]\tLoss: 174.035812\n",
            "Train Epoch: 125 [165120/232365 (71%)]\tLoss: 176.207703\n",
            "Train Epoch: 125 [166400/232365 (72%)]\tLoss: 171.637955\n",
            "Train Epoch: 125 [167680/232365 (72%)]\tLoss: 167.345047\n",
            "Train Epoch: 125 [168960/232365 (73%)]\tLoss: 174.773590\n",
            "Train Epoch: 125 [170240/232365 (73%)]\tLoss: 169.559555\n",
            "Train Epoch: 125 [171520/232365 (74%)]\tLoss: 170.877869\n",
            "Train Epoch: 125 [172800/232365 (74%)]\tLoss: 181.771240\n",
            "Train Epoch: 125 [174080/232365 (75%)]\tLoss: 175.038559\n",
            "Train Epoch: 125 [175360/232365 (75%)]\tLoss: 169.669846\n",
            "Train Epoch: 125 [176640/232365 (76%)]\tLoss: 173.737885\n",
            "Train Epoch: 125 [177920/232365 (77%)]\tLoss: 173.758865\n",
            "Train Epoch: 125 [179200/232365 (77%)]\tLoss: 178.761063\n",
            "Train Epoch: 125 [180480/232365 (78%)]\tLoss: 182.748505\n",
            "Train Epoch: 125 [181760/232365 (78%)]\tLoss: 168.648575\n",
            "Train Epoch: 125 [183040/232365 (79%)]\tLoss: 169.442505\n",
            "Train Epoch: 125 [184320/232365 (79%)]\tLoss: 172.337265\n",
            "Train Epoch: 125 [185600/232365 (80%)]\tLoss: 171.301590\n",
            "Train Epoch: 125 [186880/232365 (80%)]\tLoss: 166.263947\n",
            "Train Epoch: 125 [188160/232365 (81%)]\tLoss: 173.491577\n",
            "Train Epoch: 125 [189440/232365 (81%)]\tLoss: 174.295609\n",
            "Train Epoch: 125 [190720/232365 (82%)]\tLoss: 174.342087\n",
            "Train Epoch: 125 [192000/232365 (83%)]\tLoss: 178.753235\n",
            "Train Epoch: 125 [193280/232365 (83%)]\tLoss: 174.980911\n",
            "Train Epoch: 125 [194560/232365 (84%)]\tLoss: 163.241516\n",
            "Train Epoch: 125 [195840/232365 (84%)]\tLoss: 179.774734\n",
            "Train Epoch: 125 [197120/232365 (85%)]\tLoss: 172.863907\n",
            "Train Epoch: 125 [198400/232365 (85%)]\tLoss: 181.826126\n",
            "Train Epoch: 125 [199680/232365 (86%)]\tLoss: 173.371887\n",
            "Train Epoch: 125 [200960/232365 (86%)]\tLoss: 175.844711\n",
            "Train Epoch: 125 [202240/232365 (87%)]\tLoss: 173.929459\n",
            "Train Epoch: 125 [203520/232365 (88%)]\tLoss: 173.529480\n",
            "Train Epoch: 125 [204800/232365 (88%)]\tLoss: 167.721649\n",
            "Train Epoch: 125 [206080/232365 (89%)]\tLoss: 168.289948\n",
            "Train Epoch: 125 [207360/232365 (89%)]\tLoss: 173.252243\n",
            "Train Epoch: 125 [208640/232365 (90%)]\tLoss: 161.402908\n",
            "Train Epoch: 125 [209920/232365 (90%)]\tLoss: 173.034409\n",
            "Train Epoch: 125 [211200/232365 (91%)]\tLoss: 179.458130\n",
            "Train Epoch: 125 [212480/232365 (91%)]\tLoss: 172.332977\n",
            "Train Epoch: 125 [213760/232365 (92%)]\tLoss: 167.222504\n",
            "Train Epoch: 125 [215040/232365 (93%)]\tLoss: 176.240402\n",
            "Train Epoch: 125 [216320/232365 (93%)]\tLoss: 171.766556\n",
            "Train Epoch: 125 [217600/232365 (94%)]\tLoss: 165.640640\n",
            "Train Epoch: 125 [218880/232365 (94%)]\tLoss: 161.551971\n",
            "Train Epoch: 125 [220160/232365 (95%)]\tLoss: 171.282455\n",
            "Train Epoch: 125 [221440/232365 (95%)]\tLoss: 175.904678\n",
            "Train Epoch: 125 [222720/232365 (96%)]\tLoss: 173.061768\n",
            "Train Epoch: 125 [224000/232365 (96%)]\tLoss: 174.863510\n",
            "Train Epoch: 125 [225280/232365 (97%)]\tLoss: 162.253525\n",
            "Train Epoch: 125 [226560/232365 (97%)]\tLoss: 171.446198\n",
            "Train Epoch: 125 [227840/232365 (98%)]\tLoss: 169.811493\n",
            "Train Epoch: 125 [229120/232365 (99%)]\tLoss: 162.688370\n",
            "Train Epoch: 125 [230400/232365 (99%)]\tLoss: 171.610977\n",
            "Train Epoch: 125 [231680/232365 (100%)]\tLoss: 172.157959\n",
            "====> Epoch: 125 Average loss: 172.5966, Accuracy: 74.23%\n",
            "====> Test set loss: 183.2181, Accuracy: 74.14%\n",
            "Train Epoch: 126 [0/232365 (0%)]\tLoss: 174.727051\n",
            "Train Epoch: 126 [1280/232365 (1%)]\tLoss: 182.861786\n",
            "Train Epoch: 126 [2560/232365 (1%)]\tLoss: 165.713638\n",
            "Train Epoch: 126 [3840/232365 (2%)]\tLoss: 178.199585\n",
            "Train Epoch: 126 [5120/232365 (2%)]\tLoss: 170.077621\n",
            "Train Epoch: 126 [6400/232365 (3%)]\tLoss: 170.839508\n",
            "Train Epoch: 126 [7680/232365 (3%)]\tLoss: 164.121384\n",
            "Train Epoch: 126 [8960/232365 (4%)]\tLoss: 178.694366\n",
            "Train Epoch: 126 [10240/232365 (4%)]\tLoss: 172.489410\n",
            "Train Epoch: 126 [11520/232365 (5%)]\tLoss: 167.048477\n",
            "Train Epoch: 126 [12800/232365 (6%)]\tLoss: 177.111206\n",
            "Train Epoch: 126 [14080/232365 (6%)]\tLoss: 169.122894\n",
            "Train Epoch: 126 [15360/232365 (7%)]\tLoss: 176.172745\n",
            "Train Epoch: 126 [16640/232365 (7%)]\tLoss: 172.670120\n",
            "Train Epoch: 126 [17920/232365 (8%)]\tLoss: 175.032379\n",
            "Train Epoch: 126 [19200/232365 (8%)]\tLoss: 176.396851\n",
            "Train Epoch: 126 [20480/232365 (9%)]\tLoss: 180.198639\n",
            "Train Epoch: 126 [21760/232365 (9%)]\tLoss: 172.332230\n",
            "Train Epoch: 126 [23040/232365 (10%)]\tLoss: 176.552567\n",
            "Train Epoch: 126 [24320/232365 (10%)]\tLoss: 178.625061\n",
            "Train Epoch: 126 [25600/232365 (11%)]\tLoss: 170.172272\n",
            "Train Epoch: 126 [26880/232365 (12%)]\tLoss: 171.621017\n",
            "Train Epoch: 126 [28160/232365 (12%)]\tLoss: 166.611267\n",
            "Train Epoch: 126 [29440/232365 (13%)]\tLoss: 167.100067\n",
            "Train Epoch: 126 [30720/232365 (13%)]\tLoss: 160.661865\n",
            "Train Epoch: 126 [32000/232365 (14%)]\tLoss: 160.408325\n",
            "Train Epoch: 126 [33280/232365 (14%)]\tLoss: 176.454926\n",
            "Train Epoch: 126 [34560/232365 (15%)]\tLoss: 165.912582\n",
            "Train Epoch: 126 [35840/232365 (15%)]\tLoss: 174.127197\n",
            "Train Epoch: 126 [37120/232365 (16%)]\tLoss: 175.129471\n",
            "Train Epoch: 126 [38400/232365 (17%)]\tLoss: 172.713013\n",
            "Train Epoch: 126 [39680/232365 (17%)]\tLoss: 176.501404\n",
            "Train Epoch: 126 [40960/232365 (18%)]\tLoss: 181.528641\n",
            "Train Epoch: 126 [42240/232365 (18%)]\tLoss: 171.633453\n",
            "Train Epoch: 126 [43520/232365 (19%)]\tLoss: 177.774658\n",
            "Train Epoch: 126 [44800/232365 (19%)]\tLoss: 165.535660\n",
            "Train Epoch: 126 [46080/232365 (20%)]\tLoss: 167.727707\n",
            "Train Epoch: 126 [47360/232365 (20%)]\tLoss: 168.012817\n",
            "Train Epoch: 126 [48640/232365 (21%)]\tLoss: 171.273392\n",
            "Train Epoch: 126 [49920/232365 (21%)]\tLoss: 170.575089\n",
            "Train Epoch: 126 [51200/232365 (22%)]\tLoss: 166.048920\n",
            "Train Epoch: 126 [52480/232365 (23%)]\tLoss: 174.712311\n",
            "Train Epoch: 126 [53760/232365 (23%)]\tLoss: 172.271454\n",
            "Train Epoch: 126 [55040/232365 (24%)]\tLoss: 171.202377\n",
            "Train Epoch: 126 [56320/232365 (24%)]\tLoss: 171.453674\n",
            "Train Epoch: 126 [57600/232365 (25%)]\tLoss: 169.979965\n",
            "Train Epoch: 126 [58880/232365 (25%)]\tLoss: 180.030182\n",
            "Train Epoch: 126 [60160/232365 (26%)]\tLoss: 167.290283\n",
            "Train Epoch: 126 [61440/232365 (26%)]\tLoss: 168.646469\n",
            "Train Epoch: 126 [62720/232365 (27%)]\tLoss: 171.459717\n",
            "Train Epoch: 126 [64000/232365 (28%)]\tLoss: 164.990952\n",
            "Train Epoch: 126 [65280/232365 (28%)]\tLoss: 171.453842\n",
            "Train Epoch: 126 [66560/232365 (29%)]\tLoss: 179.848801\n",
            "Train Epoch: 126 [67840/232365 (29%)]\tLoss: 163.050507\n",
            "Train Epoch: 126 [69120/232365 (30%)]\tLoss: 167.407242\n",
            "Train Epoch: 126 [70400/232365 (30%)]\tLoss: 177.570999\n",
            "Train Epoch: 126 [71680/232365 (31%)]\tLoss: 169.065384\n",
            "Train Epoch: 126 [72960/232365 (31%)]\tLoss: 177.357681\n",
            "Train Epoch: 126 [74240/232365 (32%)]\tLoss: 167.175446\n",
            "Train Epoch: 126 [75520/232365 (32%)]\tLoss: 172.892487\n",
            "Train Epoch: 126 [76800/232365 (33%)]\tLoss: 177.042175\n",
            "Train Epoch: 126 [78080/232365 (34%)]\tLoss: 177.303680\n",
            "Train Epoch: 126 [79360/232365 (34%)]\tLoss: 178.036499\n",
            "Train Epoch: 126 [80640/232365 (35%)]\tLoss: 170.888031\n",
            "Train Epoch: 126 [81920/232365 (35%)]\tLoss: 172.990784\n",
            "Train Epoch: 126 [83200/232365 (36%)]\tLoss: 175.078918\n",
            "Train Epoch: 126 [84480/232365 (36%)]\tLoss: 173.702972\n",
            "Train Epoch: 126 [85760/232365 (37%)]\tLoss: 175.451431\n",
            "Train Epoch: 126 [87040/232365 (37%)]\tLoss: 173.846924\n",
            "Train Epoch: 126 [88320/232365 (38%)]\tLoss: 158.688721\n",
            "Train Epoch: 126 [89600/232365 (39%)]\tLoss: 175.866913\n",
            "Train Epoch: 126 [90880/232365 (39%)]\tLoss: 169.763992\n",
            "Train Epoch: 126 [92160/232365 (40%)]\tLoss: 164.312454\n",
            "Train Epoch: 126 [93440/232365 (40%)]\tLoss: 164.747253\n",
            "Train Epoch: 126 [94720/232365 (41%)]\tLoss: 177.690048\n",
            "Train Epoch: 126 [96000/232365 (41%)]\tLoss: 175.613800\n",
            "Train Epoch: 126 [97280/232365 (42%)]\tLoss: 171.340195\n",
            "Train Epoch: 126 [98560/232365 (42%)]\tLoss: 173.690445\n",
            "Train Epoch: 126 [99840/232365 (43%)]\tLoss: 171.308792\n",
            "Train Epoch: 126 [101120/232365 (44%)]\tLoss: 175.366821\n",
            "Train Epoch: 126 [102400/232365 (44%)]\tLoss: 171.475174\n",
            "Train Epoch: 126 [103680/232365 (45%)]\tLoss: 169.201904\n",
            "Train Epoch: 126 [104960/232365 (45%)]\tLoss: 168.625900\n",
            "Train Epoch: 126 [106240/232365 (46%)]\tLoss: 166.854340\n",
            "Train Epoch: 126 [107520/232365 (46%)]\tLoss: 162.572418\n",
            "Train Epoch: 126 [108800/232365 (47%)]\tLoss: 178.845642\n",
            "Train Epoch: 126 [110080/232365 (47%)]\tLoss: 162.087799\n",
            "Train Epoch: 126 [111360/232365 (48%)]\tLoss: 172.529175\n",
            "Train Epoch: 126 [112640/232365 (48%)]\tLoss: 167.579971\n",
            "Train Epoch: 126 [113920/232365 (49%)]\tLoss: 171.616425\n",
            "Train Epoch: 126 [115200/232365 (50%)]\tLoss: 164.610367\n",
            "Train Epoch: 126 [116480/232365 (50%)]\tLoss: 169.643906\n",
            "Train Epoch: 126 [117760/232365 (51%)]\tLoss: 174.367157\n",
            "Train Epoch: 126 [119040/232365 (51%)]\tLoss: 167.647324\n",
            "Train Epoch: 126 [120320/232365 (52%)]\tLoss: 177.563873\n",
            "Train Epoch: 126 [121600/232365 (52%)]\tLoss: 171.899261\n",
            "Train Epoch: 126 [122880/232365 (53%)]\tLoss: 180.016190\n",
            "Train Epoch: 126 [124160/232365 (53%)]\tLoss: 177.032745\n",
            "Train Epoch: 126 [125440/232365 (54%)]\tLoss: 175.445938\n",
            "Train Epoch: 126 [126720/232365 (55%)]\tLoss: 174.329361\n",
            "Train Epoch: 126 [128000/232365 (55%)]\tLoss: 177.611237\n",
            "Train Epoch: 126 [129280/232365 (56%)]\tLoss: 172.003754\n",
            "Train Epoch: 126 [130560/232365 (56%)]\tLoss: 169.571777\n",
            "Train Epoch: 126 [131840/232365 (57%)]\tLoss: 171.226120\n",
            "Train Epoch: 126 [133120/232365 (57%)]\tLoss: 179.182175\n",
            "Train Epoch: 126 [134400/232365 (58%)]\tLoss: 177.886627\n",
            "Train Epoch: 126 [135680/232365 (58%)]\tLoss: 178.337463\n",
            "Train Epoch: 126 [136960/232365 (59%)]\tLoss: 166.221222\n",
            "Train Epoch: 126 [138240/232365 (59%)]\tLoss: 172.308807\n",
            "Train Epoch: 126 [139520/232365 (60%)]\tLoss: 167.767883\n",
            "Train Epoch: 126 [140800/232365 (61%)]\tLoss: 173.384781\n",
            "Train Epoch: 126 [142080/232365 (61%)]\tLoss: 164.213287\n",
            "Train Epoch: 126 [143360/232365 (62%)]\tLoss: 167.231339\n",
            "Train Epoch: 126 [144640/232365 (62%)]\tLoss: 175.598251\n",
            "Train Epoch: 126 [145920/232365 (63%)]\tLoss: 173.262970\n",
            "Train Epoch: 126 [147200/232365 (63%)]\tLoss: 172.440063\n",
            "Train Epoch: 126 [148480/232365 (64%)]\tLoss: 167.518951\n",
            "Train Epoch: 126 [149760/232365 (64%)]\tLoss: 172.660980\n",
            "Train Epoch: 126 [151040/232365 (65%)]\tLoss: 182.084717\n",
            "Train Epoch: 126 [152320/232365 (66%)]\tLoss: 171.150391\n",
            "Train Epoch: 126 [153600/232365 (66%)]\tLoss: 167.785110\n",
            "Train Epoch: 126 [154880/232365 (67%)]\tLoss: 177.544708\n",
            "Train Epoch: 126 [156160/232365 (67%)]\tLoss: 168.286591\n",
            "Train Epoch: 126 [157440/232365 (68%)]\tLoss: 162.858673\n",
            "Train Epoch: 126 [158720/232365 (68%)]\tLoss: 171.871811\n",
            "Train Epoch: 126 [160000/232365 (69%)]\tLoss: 170.312378\n",
            "Train Epoch: 126 [161280/232365 (69%)]\tLoss: 180.122284\n",
            "Train Epoch: 126 [162560/232365 (70%)]\tLoss: 175.086639\n",
            "Train Epoch: 126 [163840/232365 (70%)]\tLoss: 177.128708\n",
            "Train Epoch: 126 [165120/232365 (71%)]\tLoss: 170.384232\n",
            "Train Epoch: 126 [166400/232365 (72%)]\tLoss: 190.441986\n",
            "Train Epoch: 126 [167680/232365 (72%)]\tLoss: 178.382370\n",
            "Train Epoch: 126 [168960/232365 (73%)]\tLoss: 172.634659\n",
            "Train Epoch: 126 [170240/232365 (73%)]\tLoss: 175.077545\n",
            "Train Epoch: 126 [171520/232365 (74%)]\tLoss: 172.593872\n",
            "Train Epoch: 126 [172800/232365 (74%)]\tLoss: 172.058884\n",
            "Train Epoch: 126 [174080/232365 (75%)]\tLoss: 187.807922\n",
            "Train Epoch: 126 [175360/232365 (75%)]\tLoss: 178.860626\n",
            "Train Epoch: 126 [176640/232365 (76%)]\tLoss: 174.596741\n",
            "Train Epoch: 126 [177920/232365 (77%)]\tLoss: 174.704132\n",
            "Train Epoch: 126 [179200/232365 (77%)]\tLoss: 169.598999\n",
            "Train Epoch: 126 [180480/232365 (78%)]\tLoss: 177.507004\n",
            "Train Epoch: 126 [181760/232365 (78%)]\tLoss: 169.877075\n",
            "Train Epoch: 126 [183040/232365 (79%)]\tLoss: 167.965988\n",
            "Train Epoch: 126 [184320/232365 (79%)]\tLoss: 171.125916\n",
            "Train Epoch: 126 [185600/232365 (80%)]\tLoss: 171.107086\n",
            "Train Epoch: 126 [186880/232365 (80%)]\tLoss: 178.641937\n",
            "Train Epoch: 126 [188160/232365 (81%)]\tLoss: 172.438309\n",
            "Train Epoch: 126 [189440/232365 (81%)]\tLoss: 169.960114\n",
            "Train Epoch: 126 [190720/232365 (82%)]\tLoss: 169.617355\n",
            "Train Epoch: 126 [192000/232365 (83%)]\tLoss: 171.018188\n",
            "Train Epoch: 126 [193280/232365 (83%)]\tLoss: 176.002579\n",
            "Train Epoch: 126 [194560/232365 (84%)]\tLoss: 177.905746\n",
            "Train Epoch: 126 [195840/232365 (84%)]\tLoss: 185.278809\n",
            "Train Epoch: 126 [197120/232365 (85%)]\tLoss: 168.727646\n",
            "Train Epoch: 126 [198400/232365 (85%)]\tLoss: 170.104919\n",
            "Train Epoch: 126 [199680/232365 (86%)]\tLoss: 171.865570\n",
            "Train Epoch: 126 [200960/232365 (86%)]\tLoss: 177.041702\n",
            "Train Epoch: 126 [202240/232365 (87%)]\tLoss: 176.110138\n",
            "Train Epoch: 126 [203520/232365 (88%)]\tLoss: 175.553955\n",
            "Train Epoch: 126 [204800/232365 (88%)]\tLoss: 164.427643\n",
            "Train Epoch: 126 [206080/232365 (89%)]\tLoss: 175.716980\n",
            "Train Epoch: 126 [207360/232365 (89%)]\tLoss: 165.450333\n",
            "Train Epoch: 126 [208640/232365 (90%)]\tLoss: 163.150391\n",
            "Train Epoch: 126 [209920/232365 (90%)]\tLoss: 167.696304\n",
            "Train Epoch: 126 [211200/232365 (91%)]\tLoss: 175.836670\n",
            "Train Epoch: 126 [212480/232365 (91%)]\tLoss: 177.441864\n",
            "Train Epoch: 126 [213760/232365 (92%)]\tLoss: 172.373489\n",
            "Train Epoch: 126 [215040/232365 (93%)]\tLoss: 168.403870\n",
            "Train Epoch: 126 [216320/232365 (93%)]\tLoss: 179.957901\n",
            "Train Epoch: 126 [217600/232365 (94%)]\tLoss: 169.684387\n",
            "Train Epoch: 126 [218880/232365 (94%)]\tLoss: 156.971680\n",
            "Train Epoch: 126 [220160/232365 (95%)]\tLoss: 173.685898\n",
            "Train Epoch: 126 [221440/232365 (95%)]\tLoss: 172.912003\n",
            "Train Epoch: 126 [222720/232365 (96%)]\tLoss: 173.795166\n",
            "Train Epoch: 126 [224000/232365 (96%)]\tLoss: 173.061234\n",
            "Train Epoch: 126 [225280/232365 (97%)]\tLoss: 174.936523\n",
            "Train Epoch: 126 [226560/232365 (97%)]\tLoss: 176.418945\n",
            "Train Epoch: 126 [227840/232365 (98%)]\tLoss: 166.425613\n",
            "Train Epoch: 126 [229120/232365 (99%)]\tLoss: 177.626053\n",
            "Train Epoch: 126 [230400/232365 (99%)]\tLoss: 165.772339\n",
            "Train Epoch: 126 [231680/232365 (100%)]\tLoss: 173.774658\n",
            "====> Epoch: 126 Average loss: 172.5932, Accuracy: 74.23%\n",
            "====> Test set loss: 183.3663, Accuracy: 74.12%\n",
            "Train Epoch: 127 [0/232365 (0%)]\tLoss: 167.840820\n",
            "Train Epoch: 127 [1280/232365 (1%)]\tLoss: 174.736374\n",
            "Train Epoch: 127 [2560/232365 (1%)]\tLoss: 170.071808\n",
            "Train Epoch: 127 [3840/232365 (2%)]\tLoss: 168.468933\n",
            "Train Epoch: 127 [5120/232365 (2%)]\tLoss: 178.068161\n",
            "Train Epoch: 127 [6400/232365 (3%)]\tLoss: 173.116333\n",
            "Train Epoch: 127 [7680/232365 (3%)]\tLoss: 177.452713\n",
            "Train Epoch: 127 [8960/232365 (4%)]\tLoss: 169.240448\n",
            "Train Epoch: 127 [10240/232365 (4%)]\tLoss: 175.842545\n",
            "Train Epoch: 127 [11520/232365 (5%)]\tLoss: 172.309631\n",
            "Train Epoch: 127 [12800/232365 (6%)]\tLoss: 170.877335\n",
            "Train Epoch: 127 [14080/232365 (6%)]\tLoss: 179.346313\n",
            "Train Epoch: 127 [15360/232365 (7%)]\tLoss: 164.254379\n",
            "Train Epoch: 127 [16640/232365 (7%)]\tLoss: 175.281342\n",
            "Train Epoch: 127 [17920/232365 (8%)]\tLoss: 179.238953\n",
            "Train Epoch: 127 [19200/232365 (8%)]\tLoss: 183.697357\n",
            "Train Epoch: 127 [20480/232365 (9%)]\tLoss: 178.778366\n",
            "Train Epoch: 127 [21760/232365 (9%)]\tLoss: 166.747940\n",
            "Train Epoch: 127 [23040/232365 (10%)]\tLoss: 173.254425\n",
            "Train Epoch: 127 [24320/232365 (10%)]\tLoss: 163.184982\n",
            "Train Epoch: 127 [25600/232365 (11%)]\tLoss: 164.471375\n",
            "Train Epoch: 127 [26880/232365 (12%)]\tLoss: 165.416092\n",
            "Train Epoch: 127 [28160/232365 (12%)]\tLoss: 164.138885\n",
            "Train Epoch: 127 [29440/232365 (13%)]\tLoss: 170.802429\n",
            "Train Epoch: 127 [30720/232365 (13%)]\tLoss: 177.117722\n",
            "Train Epoch: 127 [32000/232365 (14%)]\tLoss: 173.522568\n",
            "Train Epoch: 127 [33280/232365 (14%)]\tLoss: 167.680801\n",
            "Train Epoch: 127 [34560/232365 (15%)]\tLoss: 179.463135\n",
            "Train Epoch: 127 [35840/232365 (15%)]\tLoss: 161.271500\n",
            "Train Epoch: 127 [37120/232365 (16%)]\tLoss: 161.266617\n",
            "Train Epoch: 127 [38400/232365 (17%)]\tLoss: 178.100235\n",
            "Train Epoch: 127 [39680/232365 (17%)]\tLoss: 169.503860\n",
            "Train Epoch: 127 [40960/232365 (18%)]\tLoss: 178.592285\n",
            "Train Epoch: 127 [42240/232365 (18%)]\tLoss: 170.311264\n",
            "Train Epoch: 127 [43520/232365 (19%)]\tLoss: 176.348862\n",
            "Train Epoch: 127 [44800/232365 (19%)]\tLoss: 180.008728\n",
            "Train Epoch: 127 [46080/232365 (20%)]\tLoss: 167.706329\n",
            "Train Epoch: 127 [47360/232365 (20%)]\tLoss: 168.994324\n",
            "Train Epoch: 127 [48640/232365 (21%)]\tLoss: 177.125290\n",
            "Train Epoch: 127 [49920/232365 (21%)]\tLoss: 181.755951\n",
            "Train Epoch: 127 [51200/232365 (22%)]\tLoss: 165.929657\n",
            "Train Epoch: 127 [52480/232365 (23%)]\tLoss: 185.019592\n",
            "Train Epoch: 127 [53760/232365 (23%)]\tLoss: 176.896301\n",
            "Train Epoch: 127 [55040/232365 (24%)]\tLoss: 171.287674\n",
            "Train Epoch: 127 [56320/232365 (24%)]\tLoss: 174.185089\n",
            "Train Epoch: 127 [57600/232365 (25%)]\tLoss: 174.150177\n",
            "Train Epoch: 127 [58880/232365 (25%)]\tLoss: 174.533325\n",
            "Train Epoch: 127 [60160/232365 (26%)]\tLoss: 169.629501\n",
            "Train Epoch: 127 [61440/232365 (26%)]\tLoss: 171.779785\n",
            "Train Epoch: 127 [62720/232365 (27%)]\tLoss: 177.102661\n",
            "Train Epoch: 127 [64000/232365 (28%)]\tLoss: 174.548889\n",
            "Train Epoch: 127 [65280/232365 (28%)]\tLoss: 171.978973\n",
            "Train Epoch: 127 [66560/232365 (29%)]\tLoss: 174.963409\n",
            "Train Epoch: 127 [67840/232365 (29%)]\tLoss: 179.843704\n",
            "Train Epoch: 127 [69120/232365 (30%)]\tLoss: 179.844208\n",
            "Train Epoch: 127 [70400/232365 (30%)]\tLoss: 179.345245\n",
            "Train Epoch: 127 [71680/232365 (31%)]\tLoss: 164.884598\n",
            "Train Epoch: 127 [72960/232365 (31%)]\tLoss: 176.746765\n",
            "Train Epoch: 127 [74240/232365 (32%)]\tLoss: 174.043427\n",
            "Train Epoch: 127 [75520/232365 (32%)]\tLoss: 171.394470\n",
            "Train Epoch: 127 [76800/232365 (33%)]\tLoss: 171.603653\n",
            "Train Epoch: 127 [78080/232365 (34%)]\tLoss: 176.331039\n",
            "Train Epoch: 127 [79360/232365 (34%)]\tLoss: 167.158752\n",
            "Train Epoch: 127 [80640/232365 (35%)]\tLoss: 176.946030\n",
            "Train Epoch: 127 [81920/232365 (35%)]\tLoss: 163.979141\n",
            "Train Epoch: 127 [83200/232365 (36%)]\tLoss: 172.036972\n",
            "Train Epoch: 127 [84480/232365 (36%)]\tLoss: 168.942245\n",
            "Train Epoch: 127 [85760/232365 (37%)]\tLoss: 187.699875\n",
            "Train Epoch: 127 [87040/232365 (37%)]\tLoss: 173.863846\n",
            "Train Epoch: 127 [88320/232365 (38%)]\tLoss: 176.617767\n",
            "Train Epoch: 127 [89600/232365 (39%)]\tLoss: 162.219009\n",
            "Train Epoch: 127 [90880/232365 (39%)]\tLoss: 185.599487\n",
            "Train Epoch: 127 [92160/232365 (40%)]\tLoss: 167.972656\n",
            "Train Epoch: 127 [93440/232365 (40%)]\tLoss: 177.828094\n",
            "Train Epoch: 127 [94720/232365 (41%)]\tLoss: 171.365067\n",
            "Train Epoch: 127 [96000/232365 (41%)]\tLoss: 168.075027\n",
            "Train Epoch: 127 [97280/232365 (42%)]\tLoss: 167.796936\n",
            "Train Epoch: 127 [98560/232365 (42%)]\tLoss: 173.884949\n",
            "Train Epoch: 127 [99840/232365 (43%)]\tLoss: 164.494858\n",
            "Train Epoch: 127 [101120/232365 (44%)]\tLoss: 175.319855\n",
            "Train Epoch: 127 [102400/232365 (44%)]\tLoss: 181.351608\n",
            "Train Epoch: 127 [103680/232365 (45%)]\tLoss: 176.732880\n",
            "Train Epoch: 127 [104960/232365 (45%)]\tLoss: 171.967514\n",
            "Train Epoch: 127 [106240/232365 (46%)]\tLoss: 176.096024\n",
            "Train Epoch: 127 [107520/232365 (46%)]\tLoss: 168.049454\n",
            "Train Epoch: 127 [108800/232365 (47%)]\tLoss: 175.792969\n",
            "Train Epoch: 127 [110080/232365 (47%)]\tLoss: 173.123566\n",
            "Train Epoch: 127 [111360/232365 (48%)]\tLoss: 169.293854\n",
            "Train Epoch: 127 [112640/232365 (48%)]\tLoss: 172.150650\n",
            "Train Epoch: 127 [113920/232365 (49%)]\tLoss: 179.193604\n",
            "Train Epoch: 127 [115200/232365 (50%)]\tLoss: 168.648758\n",
            "Train Epoch: 127 [116480/232365 (50%)]\tLoss: 175.408752\n",
            "Train Epoch: 127 [117760/232365 (51%)]\tLoss: 170.730392\n",
            "Train Epoch: 127 [119040/232365 (51%)]\tLoss: 172.907257\n",
            "Train Epoch: 127 [120320/232365 (52%)]\tLoss: 173.284760\n",
            "Train Epoch: 127 [121600/232365 (52%)]\tLoss: 175.216675\n",
            "Train Epoch: 127 [122880/232365 (53%)]\tLoss: 175.008133\n",
            "Train Epoch: 127 [124160/232365 (53%)]\tLoss: 177.685272\n",
            "Train Epoch: 127 [125440/232365 (54%)]\tLoss: 167.182831\n",
            "Train Epoch: 127 [126720/232365 (55%)]\tLoss: 180.692963\n",
            "Train Epoch: 127 [128000/232365 (55%)]\tLoss: 165.674927\n",
            "Train Epoch: 127 [129280/232365 (56%)]\tLoss: 176.565109\n",
            "Train Epoch: 127 [130560/232365 (56%)]\tLoss: 170.511230\n",
            "Train Epoch: 127 [131840/232365 (57%)]\tLoss: 173.460037\n",
            "Train Epoch: 127 [133120/232365 (57%)]\tLoss: 174.908401\n",
            "Train Epoch: 127 [134400/232365 (58%)]\tLoss: 172.275665\n",
            "Train Epoch: 127 [135680/232365 (58%)]\tLoss: 173.668884\n",
            "Train Epoch: 127 [136960/232365 (59%)]\tLoss: 172.014999\n",
            "Train Epoch: 127 [138240/232365 (59%)]\tLoss: 167.690201\n",
            "Train Epoch: 127 [139520/232365 (60%)]\tLoss: 169.698303\n",
            "Train Epoch: 127 [140800/232365 (61%)]\tLoss: 169.895966\n",
            "Train Epoch: 127 [142080/232365 (61%)]\tLoss: 172.700989\n",
            "Train Epoch: 127 [143360/232365 (62%)]\tLoss: 176.083130\n",
            "Train Epoch: 127 [144640/232365 (62%)]\tLoss: 172.054047\n",
            "Train Epoch: 127 [145920/232365 (63%)]\tLoss: 176.356064\n",
            "Train Epoch: 127 [147200/232365 (63%)]\tLoss: 167.736252\n",
            "Train Epoch: 127 [148480/232365 (64%)]\tLoss: 170.849716\n",
            "Train Epoch: 127 [149760/232365 (64%)]\tLoss: 174.308517\n",
            "Train Epoch: 127 [151040/232365 (65%)]\tLoss: 175.659988\n",
            "Train Epoch: 127 [152320/232365 (66%)]\tLoss: 183.576553\n",
            "Train Epoch: 127 [153600/232365 (66%)]\tLoss: 173.512527\n",
            "Train Epoch: 127 [154880/232365 (67%)]\tLoss: 164.947769\n",
            "Train Epoch: 127 [156160/232365 (67%)]\tLoss: 163.074020\n",
            "Train Epoch: 127 [157440/232365 (68%)]\tLoss: 171.651855\n",
            "Train Epoch: 127 [158720/232365 (68%)]\tLoss: 172.677719\n",
            "Train Epoch: 127 [160000/232365 (69%)]\tLoss: 177.771912\n",
            "Train Epoch: 127 [161280/232365 (69%)]\tLoss: 167.489334\n",
            "Train Epoch: 127 [162560/232365 (70%)]\tLoss: 163.682861\n",
            "Train Epoch: 127 [163840/232365 (70%)]\tLoss: 171.189072\n",
            "Train Epoch: 127 [165120/232365 (71%)]\tLoss: 170.041397\n",
            "Train Epoch: 127 [166400/232365 (72%)]\tLoss: 172.607819\n",
            "Train Epoch: 127 [167680/232365 (72%)]\tLoss: 168.006027\n",
            "Train Epoch: 127 [168960/232365 (73%)]\tLoss: 181.942337\n",
            "Train Epoch: 127 [170240/232365 (73%)]\tLoss: 170.596405\n",
            "Train Epoch: 127 [171520/232365 (74%)]\tLoss: 177.985931\n",
            "Train Epoch: 127 [172800/232365 (74%)]\tLoss: 163.242691\n",
            "Train Epoch: 127 [174080/232365 (75%)]\tLoss: 173.223709\n",
            "Train Epoch: 127 [175360/232365 (75%)]\tLoss: 171.418945\n",
            "Train Epoch: 127 [176640/232365 (76%)]\tLoss: 176.994598\n",
            "Train Epoch: 127 [177920/232365 (77%)]\tLoss: 179.201523\n",
            "Train Epoch: 127 [179200/232365 (77%)]\tLoss: 171.142105\n",
            "Train Epoch: 127 [180480/232365 (78%)]\tLoss: 178.673874\n",
            "Train Epoch: 127 [181760/232365 (78%)]\tLoss: 169.564270\n",
            "Train Epoch: 127 [183040/232365 (79%)]\tLoss: 170.218231\n",
            "Train Epoch: 127 [184320/232365 (79%)]\tLoss: 167.560898\n",
            "Train Epoch: 127 [185600/232365 (80%)]\tLoss: 181.400238\n",
            "Train Epoch: 127 [186880/232365 (80%)]\tLoss: 173.188080\n",
            "Train Epoch: 127 [188160/232365 (81%)]\tLoss: 173.126923\n",
            "Train Epoch: 127 [189440/232365 (81%)]\tLoss: 175.672653\n",
            "Train Epoch: 127 [190720/232365 (82%)]\tLoss: 175.201416\n",
            "Train Epoch: 127 [192000/232365 (83%)]\tLoss: 169.532074\n",
            "Train Epoch: 127 [193280/232365 (83%)]\tLoss: 176.470978\n",
            "Train Epoch: 127 [194560/232365 (84%)]\tLoss: 175.495773\n",
            "Train Epoch: 127 [195840/232365 (84%)]\tLoss: 173.888260\n",
            "Train Epoch: 127 [197120/232365 (85%)]\tLoss: 171.509674\n",
            "Train Epoch: 127 [198400/232365 (85%)]\tLoss: 162.584839\n",
            "Train Epoch: 127 [199680/232365 (86%)]\tLoss: 179.446396\n",
            "Train Epoch: 127 [200960/232365 (86%)]\tLoss: 169.352249\n",
            "Train Epoch: 127 [202240/232365 (87%)]\tLoss: 167.923630\n",
            "Train Epoch: 127 [203520/232365 (88%)]\tLoss: 181.251953\n",
            "Train Epoch: 127 [204800/232365 (88%)]\tLoss: 167.860153\n",
            "Train Epoch: 127 [206080/232365 (89%)]\tLoss: 173.310791\n",
            "Train Epoch: 127 [207360/232365 (89%)]\tLoss: 174.266815\n",
            "Train Epoch: 127 [208640/232365 (90%)]\tLoss: 178.099106\n",
            "Train Epoch: 127 [209920/232365 (90%)]\tLoss: 179.137955\n",
            "Train Epoch: 127 [211200/232365 (91%)]\tLoss: 168.783096\n",
            "Train Epoch: 127 [212480/232365 (91%)]\tLoss: 176.886078\n",
            "Train Epoch: 127 [213760/232365 (92%)]\tLoss: 166.015854\n",
            "Train Epoch: 127 [215040/232365 (93%)]\tLoss: 179.346558\n",
            "Train Epoch: 127 [216320/232365 (93%)]\tLoss: 164.917755\n",
            "Train Epoch: 127 [217600/232365 (94%)]\tLoss: 177.118546\n",
            "Train Epoch: 127 [218880/232365 (94%)]\tLoss: 171.866013\n",
            "Train Epoch: 127 [220160/232365 (95%)]\tLoss: 165.328445\n",
            "Train Epoch: 127 [221440/232365 (95%)]\tLoss: 166.914459\n",
            "Train Epoch: 127 [222720/232365 (96%)]\tLoss: 178.542603\n",
            "Train Epoch: 127 [224000/232365 (96%)]\tLoss: 169.975632\n",
            "Train Epoch: 127 [225280/232365 (97%)]\tLoss: 171.509979\n",
            "Train Epoch: 127 [226560/232365 (97%)]\tLoss: 172.752625\n",
            "Train Epoch: 127 [227840/232365 (98%)]\tLoss: 166.898102\n",
            "Train Epoch: 127 [229120/232365 (99%)]\tLoss: 169.087311\n",
            "Train Epoch: 127 [230400/232365 (99%)]\tLoss: 177.123108\n",
            "Train Epoch: 127 [231680/232365 (100%)]\tLoss: 170.065765\n",
            "====> Epoch: 127 Average loss: 172.5662, Accuracy: 74.23%\n",
            "====> Test set loss: 183.0699, Accuracy: 74.15%\n",
            "Train Epoch: 128 [0/232365 (0%)]\tLoss: 174.167679\n",
            "Train Epoch: 128 [1280/232365 (1%)]\tLoss: 169.679413\n",
            "Train Epoch: 128 [2560/232365 (1%)]\tLoss: 167.387680\n",
            "Train Epoch: 128 [3840/232365 (2%)]\tLoss: 166.393677\n",
            "Train Epoch: 128 [5120/232365 (2%)]\tLoss: 167.326523\n",
            "Train Epoch: 128 [6400/232365 (3%)]\tLoss: 175.676178\n",
            "Train Epoch: 128 [7680/232365 (3%)]\tLoss: 165.209595\n",
            "Train Epoch: 128 [8960/232365 (4%)]\tLoss: 174.063217\n",
            "Train Epoch: 128 [10240/232365 (4%)]\tLoss: 176.358292\n",
            "Train Epoch: 128 [11520/232365 (5%)]\tLoss: 177.274521\n",
            "Train Epoch: 128 [12800/232365 (6%)]\tLoss: 162.608353\n",
            "Train Epoch: 128 [14080/232365 (6%)]\tLoss: 175.505432\n",
            "Train Epoch: 128 [15360/232365 (7%)]\tLoss: 173.975723\n",
            "Train Epoch: 128 [16640/232365 (7%)]\tLoss: 164.816315\n",
            "Train Epoch: 128 [17920/232365 (8%)]\tLoss: 172.706955\n",
            "Train Epoch: 128 [19200/232365 (8%)]\tLoss: 170.626511\n",
            "Train Epoch: 128 [20480/232365 (9%)]\tLoss: 161.279205\n",
            "Train Epoch: 128 [21760/232365 (9%)]\tLoss: 182.911743\n",
            "Train Epoch: 128 [23040/232365 (10%)]\tLoss: 173.897202\n",
            "Train Epoch: 128 [24320/232365 (10%)]\tLoss: 174.146088\n",
            "Train Epoch: 128 [25600/232365 (11%)]\tLoss: 172.246399\n",
            "Train Epoch: 128 [26880/232365 (12%)]\tLoss: 170.252197\n",
            "Train Epoch: 128 [28160/232365 (12%)]\tLoss: 171.719437\n",
            "Train Epoch: 128 [29440/232365 (13%)]\tLoss: 175.556152\n",
            "Train Epoch: 128 [30720/232365 (13%)]\tLoss: 164.812057\n",
            "Train Epoch: 128 [32000/232365 (14%)]\tLoss: 179.869247\n",
            "Train Epoch: 128 [33280/232365 (14%)]\tLoss: 168.256134\n",
            "Train Epoch: 128 [34560/232365 (15%)]\tLoss: 178.442642\n",
            "Train Epoch: 128 [35840/232365 (15%)]\tLoss: 171.199509\n",
            "Train Epoch: 128 [37120/232365 (16%)]\tLoss: 163.703583\n",
            "Train Epoch: 128 [38400/232365 (17%)]\tLoss: 164.550125\n",
            "Train Epoch: 128 [39680/232365 (17%)]\tLoss: 176.659805\n",
            "Train Epoch: 128 [40960/232365 (18%)]\tLoss: 175.194717\n",
            "Train Epoch: 128 [42240/232365 (18%)]\tLoss: 186.291107\n",
            "Train Epoch: 128 [43520/232365 (19%)]\tLoss: 176.898376\n",
            "Train Epoch: 128 [44800/232365 (19%)]\tLoss: 179.485931\n",
            "Train Epoch: 128 [46080/232365 (20%)]\tLoss: 170.508499\n",
            "Train Epoch: 128 [47360/232365 (20%)]\tLoss: 169.460861\n",
            "Train Epoch: 128 [48640/232365 (21%)]\tLoss: 168.312180\n",
            "Train Epoch: 128 [49920/232365 (21%)]\tLoss: 162.369873\n",
            "Train Epoch: 128 [51200/232365 (22%)]\tLoss: 171.013580\n",
            "Train Epoch: 128 [52480/232365 (23%)]\tLoss: 172.693176\n",
            "Train Epoch: 128 [53760/232365 (23%)]\tLoss: 180.320526\n",
            "Train Epoch: 128 [55040/232365 (24%)]\tLoss: 158.761383\n",
            "Train Epoch: 128 [56320/232365 (24%)]\tLoss: 167.385727\n",
            "Train Epoch: 128 [57600/232365 (25%)]\tLoss: 175.103012\n",
            "Train Epoch: 128 [58880/232365 (25%)]\tLoss: 174.361237\n",
            "Train Epoch: 128 [60160/232365 (26%)]\tLoss: 168.768921\n",
            "Train Epoch: 128 [61440/232365 (26%)]\tLoss: 171.622223\n",
            "Train Epoch: 128 [62720/232365 (27%)]\tLoss: 170.703369\n",
            "Train Epoch: 128 [64000/232365 (28%)]\tLoss: 176.727020\n",
            "Train Epoch: 128 [65280/232365 (28%)]\tLoss: 172.349640\n",
            "Train Epoch: 128 [66560/232365 (29%)]\tLoss: 169.063278\n",
            "Train Epoch: 128 [67840/232365 (29%)]\tLoss: 172.234940\n",
            "Train Epoch: 128 [69120/232365 (30%)]\tLoss: 178.116043\n",
            "Train Epoch: 128 [70400/232365 (30%)]\tLoss: 172.636536\n",
            "Train Epoch: 128 [71680/232365 (31%)]\tLoss: 177.051010\n",
            "Train Epoch: 128 [72960/232365 (31%)]\tLoss: 168.440140\n",
            "Train Epoch: 128 [74240/232365 (32%)]\tLoss: 170.850861\n",
            "Train Epoch: 128 [75520/232365 (32%)]\tLoss: 170.035538\n",
            "Train Epoch: 128 [76800/232365 (33%)]\tLoss: 177.226654\n",
            "Train Epoch: 128 [78080/232365 (34%)]\tLoss: 167.799469\n",
            "Train Epoch: 128 [79360/232365 (34%)]\tLoss: 185.630615\n",
            "Train Epoch: 128 [80640/232365 (35%)]\tLoss: 173.083588\n",
            "Train Epoch: 128 [81920/232365 (35%)]\tLoss: 171.953140\n",
            "Train Epoch: 128 [83200/232365 (36%)]\tLoss: 176.592773\n",
            "Train Epoch: 128 [84480/232365 (36%)]\tLoss: 166.161041\n",
            "Train Epoch: 128 [85760/232365 (37%)]\tLoss: 165.191574\n",
            "Train Epoch: 128 [87040/232365 (37%)]\tLoss: 168.163849\n",
            "Train Epoch: 128 [88320/232365 (38%)]\tLoss: 170.624359\n",
            "Train Epoch: 128 [89600/232365 (39%)]\tLoss: 174.600540\n",
            "Train Epoch: 128 [90880/232365 (39%)]\tLoss: 172.749008\n",
            "Train Epoch: 128 [92160/232365 (40%)]\tLoss: 161.259140\n",
            "Train Epoch: 128 [93440/232365 (40%)]\tLoss: 169.506409\n",
            "Train Epoch: 128 [94720/232365 (41%)]\tLoss: 172.542297\n",
            "Train Epoch: 128 [96000/232365 (41%)]\tLoss: 179.554520\n",
            "Train Epoch: 128 [97280/232365 (42%)]\tLoss: 175.143906\n",
            "Train Epoch: 128 [98560/232365 (42%)]\tLoss: 182.420166\n",
            "Train Epoch: 128 [99840/232365 (43%)]\tLoss: 169.960495\n",
            "Train Epoch: 128 [101120/232365 (44%)]\tLoss: 172.824829\n",
            "Train Epoch: 128 [102400/232365 (44%)]\tLoss: 172.518036\n",
            "Train Epoch: 128 [103680/232365 (45%)]\tLoss: 178.425720\n",
            "Train Epoch: 128 [104960/232365 (45%)]\tLoss: 178.200424\n",
            "Train Epoch: 128 [106240/232365 (46%)]\tLoss: 173.029022\n",
            "Train Epoch: 128 [107520/232365 (46%)]\tLoss: 171.831482\n",
            "Train Epoch: 128 [108800/232365 (47%)]\tLoss: 172.998932\n",
            "Train Epoch: 128 [110080/232365 (47%)]\tLoss: 171.805786\n",
            "Train Epoch: 128 [111360/232365 (48%)]\tLoss: 169.220901\n",
            "Train Epoch: 128 [112640/232365 (48%)]\tLoss: 165.588058\n",
            "Train Epoch: 128 [113920/232365 (49%)]\tLoss: 172.534790\n",
            "Train Epoch: 128 [115200/232365 (50%)]\tLoss: 170.525131\n",
            "Train Epoch: 128 [116480/232365 (50%)]\tLoss: 163.622742\n",
            "Train Epoch: 128 [117760/232365 (51%)]\tLoss: 170.299683\n",
            "Train Epoch: 128 [119040/232365 (51%)]\tLoss: 173.037933\n",
            "Train Epoch: 128 [120320/232365 (52%)]\tLoss: 183.674332\n",
            "Train Epoch: 128 [121600/232365 (52%)]\tLoss: 170.760803\n",
            "Train Epoch: 128 [122880/232365 (53%)]\tLoss: 169.200668\n",
            "Train Epoch: 128 [124160/232365 (53%)]\tLoss: 166.772995\n",
            "Train Epoch: 128 [125440/232365 (54%)]\tLoss: 170.284088\n",
            "Train Epoch: 128 [126720/232365 (55%)]\tLoss: 174.695160\n",
            "Train Epoch: 128 [128000/232365 (55%)]\tLoss: 177.685471\n",
            "Train Epoch: 128 [129280/232365 (56%)]\tLoss: 178.639923\n",
            "Train Epoch: 128 [130560/232365 (56%)]\tLoss: 176.746796\n",
            "Train Epoch: 128 [131840/232365 (57%)]\tLoss: 174.727356\n",
            "Train Epoch: 128 [133120/232365 (57%)]\tLoss: 170.437607\n",
            "Train Epoch: 128 [134400/232365 (58%)]\tLoss: 171.807144\n",
            "Train Epoch: 128 [135680/232365 (58%)]\tLoss: 173.012314\n",
            "Train Epoch: 128 [136960/232365 (59%)]\tLoss: 174.685608\n",
            "Train Epoch: 128 [138240/232365 (59%)]\tLoss: 165.203995\n",
            "Train Epoch: 128 [139520/232365 (60%)]\tLoss: 175.044983\n",
            "Train Epoch: 128 [140800/232365 (61%)]\tLoss: 170.570984\n",
            "Train Epoch: 128 [142080/232365 (61%)]\tLoss: 186.866318\n",
            "Train Epoch: 128 [143360/232365 (62%)]\tLoss: 168.657593\n",
            "Train Epoch: 128 [144640/232365 (62%)]\tLoss: 174.577805\n",
            "Train Epoch: 128 [145920/232365 (63%)]\tLoss: 168.987183\n",
            "Train Epoch: 128 [147200/232365 (63%)]\tLoss: 172.957458\n",
            "Train Epoch: 128 [148480/232365 (64%)]\tLoss: 172.508789\n",
            "Train Epoch: 128 [149760/232365 (64%)]\tLoss: 171.738312\n",
            "Train Epoch: 128 [151040/232365 (65%)]\tLoss: 178.850174\n",
            "Train Epoch: 128 [152320/232365 (66%)]\tLoss: 181.593719\n",
            "Train Epoch: 128 [153600/232365 (66%)]\tLoss: 167.552353\n",
            "Train Epoch: 128 [154880/232365 (67%)]\tLoss: 168.798141\n",
            "Train Epoch: 128 [156160/232365 (67%)]\tLoss: 168.610596\n",
            "Train Epoch: 128 [157440/232365 (68%)]\tLoss: 170.627274\n",
            "Train Epoch: 128 [158720/232365 (68%)]\tLoss: 168.277649\n",
            "Train Epoch: 128 [160000/232365 (69%)]\tLoss: 167.866821\n",
            "Train Epoch: 128 [161280/232365 (69%)]\tLoss: 168.207397\n",
            "Train Epoch: 128 [162560/232365 (70%)]\tLoss: 164.331665\n",
            "Train Epoch: 128 [163840/232365 (70%)]\tLoss: 173.665344\n",
            "Train Epoch: 128 [165120/232365 (71%)]\tLoss: 168.826981\n",
            "Train Epoch: 128 [166400/232365 (72%)]\tLoss: 180.236145\n",
            "Train Epoch: 128 [167680/232365 (72%)]\tLoss: 178.313126\n",
            "Train Epoch: 128 [168960/232365 (73%)]\tLoss: 166.368622\n",
            "Train Epoch: 128 [170240/232365 (73%)]\tLoss: 176.717041\n",
            "Train Epoch: 128 [171520/232365 (74%)]\tLoss: 173.305756\n",
            "Train Epoch: 128 [172800/232365 (74%)]\tLoss: 166.928268\n",
            "Train Epoch: 128 [174080/232365 (75%)]\tLoss: 174.346436\n",
            "Train Epoch: 128 [175360/232365 (75%)]\tLoss: 168.243576\n",
            "Train Epoch: 128 [176640/232365 (76%)]\tLoss: 174.821732\n",
            "Train Epoch: 128 [177920/232365 (77%)]\tLoss: 170.035065\n",
            "Train Epoch: 128 [179200/232365 (77%)]\tLoss: 173.575424\n",
            "Train Epoch: 128 [180480/232365 (78%)]\tLoss: 175.094009\n",
            "Train Epoch: 128 [181760/232365 (78%)]\tLoss: 165.269791\n",
            "Train Epoch: 128 [183040/232365 (79%)]\tLoss: 177.811630\n",
            "Train Epoch: 128 [184320/232365 (79%)]\tLoss: 169.529846\n",
            "Train Epoch: 128 [185600/232365 (80%)]\tLoss: 174.130066\n",
            "Train Epoch: 128 [186880/232365 (80%)]\tLoss: 177.946213\n",
            "Train Epoch: 128 [188160/232365 (81%)]\tLoss: 174.638016\n",
            "Train Epoch: 128 [189440/232365 (81%)]\tLoss: 170.682053\n",
            "Train Epoch: 128 [190720/232365 (82%)]\tLoss: 169.157364\n",
            "Train Epoch: 128 [192000/232365 (83%)]\tLoss: 176.233200\n",
            "Train Epoch: 128 [193280/232365 (83%)]\tLoss: 170.067307\n",
            "Train Epoch: 128 [194560/232365 (84%)]\tLoss: 170.626282\n",
            "Train Epoch: 128 [195840/232365 (84%)]\tLoss: 167.655304\n",
            "Train Epoch: 128 [197120/232365 (85%)]\tLoss: 164.143173\n",
            "Train Epoch: 128 [198400/232365 (85%)]\tLoss: 178.188263\n",
            "Train Epoch: 128 [199680/232365 (86%)]\tLoss: 171.888672\n",
            "Train Epoch: 128 [200960/232365 (86%)]\tLoss: 168.035217\n",
            "Train Epoch: 128 [202240/232365 (87%)]\tLoss: 175.697281\n",
            "Train Epoch: 128 [203520/232365 (88%)]\tLoss: 180.852020\n",
            "Train Epoch: 128 [204800/232365 (88%)]\tLoss: 179.408264\n",
            "Train Epoch: 128 [206080/232365 (89%)]\tLoss: 165.526169\n",
            "Train Epoch: 128 [207360/232365 (89%)]\tLoss: 171.532974\n",
            "Train Epoch: 128 [208640/232365 (90%)]\tLoss: 161.657135\n",
            "Train Epoch: 128 [209920/232365 (90%)]\tLoss: 167.481796\n",
            "Train Epoch: 128 [211200/232365 (91%)]\tLoss: 172.352036\n",
            "Train Epoch: 128 [212480/232365 (91%)]\tLoss: 178.263901\n",
            "Train Epoch: 128 [213760/232365 (92%)]\tLoss: 177.057556\n",
            "Train Epoch: 128 [215040/232365 (93%)]\tLoss: 178.127747\n",
            "Train Epoch: 128 [216320/232365 (93%)]\tLoss: 169.199249\n",
            "Train Epoch: 128 [217600/232365 (94%)]\tLoss: 167.797897\n",
            "Train Epoch: 128 [218880/232365 (94%)]\tLoss: 178.263275\n",
            "Train Epoch: 128 [220160/232365 (95%)]\tLoss: 171.885406\n",
            "Train Epoch: 128 [221440/232365 (95%)]\tLoss: 184.009995\n",
            "Train Epoch: 128 [222720/232365 (96%)]\tLoss: 175.073624\n",
            "Train Epoch: 128 [224000/232365 (96%)]\tLoss: 172.309265\n",
            "Train Epoch: 128 [225280/232365 (97%)]\tLoss: 162.348267\n",
            "Train Epoch: 128 [226560/232365 (97%)]\tLoss: 169.609558\n",
            "Train Epoch: 128 [227840/232365 (98%)]\tLoss: 169.543747\n",
            "Train Epoch: 128 [229120/232365 (99%)]\tLoss: 174.697906\n",
            "Train Epoch: 128 [230400/232365 (99%)]\tLoss: 177.963867\n",
            "Train Epoch: 128 [231680/232365 (100%)]\tLoss: 170.756317\n",
            "====> Epoch: 128 Average loss: 172.5787, Accuracy: 74.23%\n",
            "====> Test set loss: 183.4540, Accuracy: 74.13%\n",
            "Train Epoch: 129 [0/232365 (0%)]\tLoss: 173.687057\n",
            "Train Epoch: 129 [1280/232365 (1%)]\tLoss: 157.848511\n",
            "Train Epoch: 129 [2560/232365 (1%)]\tLoss: 169.273163\n",
            "Train Epoch: 129 [3840/232365 (2%)]\tLoss: 165.258652\n",
            "Train Epoch: 129 [5120/232365 (2%)]\tLoss: 170.363403\n",
            "Train Epoch: 129 [6400/232365 (3%)]\tLoss: 171.348022\n",
            "Train Epoch: 129 [7680/232365 (3%)]\tLoss: 165.596481\n",
            "Train Epoch: 129 [8960/232365 (4%)]\tLoss: 172.661072\n",
            "Train Epoch: 129 [10240/232365 (4%)]\tLoss: 178.106125\n",
            "Train Epoch: 129 [11520/232365 (5%)]\tLoss: 169.261093\n",
            "Train Epoch: 129 [12800/232365 (6%)]\tLoss: 171.111404\n",
            "Train Epoch: 129 [14080/232365 (6%)]\tLoss: 165.613190\n",
            "Train Epoch: 129 [15360/232365 (7%)]\tLoss: 171.370041\n",
            "Train Epoch: 129 [16640/232365 (7%)]\tLoss: 172.808670\n",
            "Train Epoch: 129 [17920/232365 (8%)]\tLoss: 167.096451\n",
            "Train Epoch: 129 [19200/232365 (8%)]\tLoss: 176.139404\n",
            "Train Epoch: 129 [20480/232365 (9%)]\tLoss: 177.746552\n",
            "Train Epoch: 129 [21760/232365 (9%)]\tLoss: 176.270447\n",
            "Train Epoch: 129 [23040/232365 (10%)]\tLoss: 179.901337\n",
            "Train Epoch: 129 [24320/232365 (10%)]\tLoss: 166.901733\n",
            "Train Epoch: 129 [25600/232365 (11%)]\tLoss: 165.765793\n",
            "Train Epoch: 129 [26880/232365 (12%)]\tLoss: 181.019379\n",
            "Train Epoch: 129 [28160/232365 (12%)]\tLoss: 177.741119\n",
            "Train Epoch: 129 [29440/232365 (13%)]\tLoss: 171.982819\n",
            "Train Epoch: 129 [30720/232365 (13%)]\tLoss: 169.133484\n",
            "Train Epoch: 129 [32000/232365 (14%)]\tLoss: 178.911560\n",
            "Train Epoch: 129 [33280/232365 (14%)]\tLoss: 175.524628\n",
            "Train Epoch: 129 [34560/232365 (15%)]\tLoss: 166.518356\n",
            "Train Epoch: 129 [35840/232365 (15%)]\tLoss: 166.559174\n",
            "Train Epoch: 129 [37120/232365 (16%)]\tLoss: 167.180542\n",
            "Train Epoch: 129 [38400/232365 (17%)]\tLoss: 170.448532\n",
            "Train Epoch: 129 [39680/232365 (17%)]\tLoss: 170.061584\n",
            "Train Epoch: 129 [40960/232365 (18%)]\tLoss: 176.273010\n",
            "Train Epoch: 129 [42240/232365 (18%)]\tLoss: 173.821411\n",
            "Train Epoch: 129 [43520/232365 (19%)]\tLoss: 172.386627\n",
            "Train Epoch: 129 [44800/232365 (19%)]\tLoss: 169.586090\n",
            "Train Epoch: 129 [46080/232365 (20%)]\tLoss: 164.642227\n",
            "Train Epoch: 129 [47360/232365 (20%)]\tLoss: 168.513535\n",
            "Train Epoch: 129 [48640/232365 (21%)]\tLoss: 172.954926\n",
            "Train Epoch: 129 [49920/232365 (21%)]\tLoss: 167.199417\n",
            "Train Epoch: 129 [51200/232365 (22%)]\tLoss: 175.919632\n",
            "Train Epoch: 129 [52480/232365 (23%)]\tLoss: 175.873978\n",
            "Train Epoch: 129 [53760/232365 (23%)]\tLoss: 181.685455\n",
            "Train Epoch: 129 [55040/232365 (24%)]\tLoss: 176.474670\n",
            "Train Epoch: 129 [56320/232365 (24%)]\tLoss: 169.265900\n",
            "Train Epoch: 129 [57600/232365 (25%)]\tLoss: 170.787369\n",
            "Train Epoch: 129 [58880/232365 (25%)]\tLoss: 169.665924\n",
            "Train Epoch: 129 [60160/232365 (26%)]\tLoss: 175.205780\n",
            "Train Epoch: 129 [61440/232365 (26%)]\tLoss: 177.048279\n",
            "Train Epoch: 129 [62720/232365 (27%)]\tLoss: 173.690079\n",
            "Train Epoch: 129 [64000/232365 (28%)]\tLoss: 168.372482\n",
            "Train Epoch: 129 [65280/232365 (28%)]\tLoss: 166.517670\n",
            "Train Epoch: 129 [66560/232365 (29%)]\tLoss: 186.422974\n",
            "Train Epoch: 129 [67840/232365 (29%)]\tLoss: 178.226440\n",
            "Train Epoch: 129 [69120/232365 (30%)]\tLoss: 171.416901\n",
            "Train Epoch: 129 [70400/232365 (30%)]\tLoss: 173.458954\n",
            "Train Epoch: 129 [71680/232365 (31%)]\tLoss: 172.138290\n",
            "Train Epoch: 129 [72960/232365 (31%)]\tLoss: 174.681702\n",
            "Train Epoch: 129 [74240/232365 (32%)]\tLoss: 172.452515\n",
            "Train Epoch: 129 [75520/232365 (32%)]\tLoss: 173.606445\n",
            "Train Epoch: 129 [76800/232365 (33%)]\tLoss: 171.201080\n",
            "Train Epoch: 129 [78080/232365 (34%)]\tLoss: 169.101517\n",
            "Train Epoch: 129 [79360/232365 (34%)]\tLoss: 169.901215\n",
            "Train Epoch: 129 [80640/232365 (35%)]\tLoss: 166.279007\n",
            "Train Epoch: 129 [81920/232365 (35%)]\tLoss: 178.558655\n",
            "Train Epoch: 129 [83200/232365 (36%)]\tLoss: 168.575226\n",
            "Train Epoch: 129 [84480/232365 (36%)]\tLoss: 175.748840\n",
            "Train Epoch: 129 [85760/232365 (37%)]\tLoss: 165.764221\n",
            "Train Epoch: 129 [87040/232365 (37%)]\tLoss: 166.921143\n",
            "Train Epoch: 129 [88320/232365 (38%)]\tLoss: 175.749390\n",
            "Train Epoch: 129 [89600/232365 (39%)]\tLoss: 179.151413\n",
            "Train Epoch: 129 [90880/232365 (39%)]\tLoss: 174.311493\n",
            "Train Epoch: 129 [92160/232365 (40%)]\tLoss: 172.245331\n",
            "Train Epoch: 129 [93440/232365 (40%)]\tLoss: 178.304474\n",
            "Train Epoch: 129 [94720/232365 (41%)]\tLoss: 168.800339\n",
            "Train Epoch: 129 [96000/232365 (41%)]\tLoss: 177.174744\n",
            "Train Epoch: 129 [97280/232365 (42%)]\tLoss: 173.095337\n",
            "Train Epoch: 129 [98560/232365 (42%)]\tLoss: 169.782730\n",
            "Train Epoch: 129 [99840/232365 (43%)]\tLoss: 169.365585\n",
            "Train Epoch: 129 [101120/232365 (44%)]\tLoss: 176.814804\n",
            "Train Epoch: 129 [102400/232365 (44%)]\tLoss: 171.108444\n",
            "Train Epoch: 129 [103680/232365 (45%)]\tLoss: 174.005463\n",
            "Train Epoch: 129 [104960/232365 (45%)]\tLoss: 174.646271\n",
            "Train Epoch: 129 [106240/232365 (46%)]\tLoss: 169.929810\n",
            "Train Epoch: 129 [107520/232365 (46%)]\tLoss: 182.400269\n",
            "Train Epoch: 129 [108800/232365 (47%)]\tLoss: 165.390625\n",
            "Train Epoch: 129 [110080/232365 (47%)]\tLoss: 168.081070\n",
            "Train Epoch: 129 [111360/232365 (48%)]\tLoss: 180.317886\n",
            "Train Epoch: 129 [112640/232365 (48%)]\tLoss: 172.605011\n",
            "Train Epoch: 129 [113920/232365 (49%)]\tLoss: 167.034546\n",
            "Train Epoch: 129 [115200/232365 (50%)]\tLoss: 165.565811\n",
            "Train Epoch: 129 [116480/232365 (50%)]\tLoss: 167.147385\n",
            "Train Epoch: 129 [117760/232365 (51%)]\tLoss: 173.007843\n",
            "Train Epoch: 129 [119040/232365 (51%)]\tLoss: 169.486267\n",
            "Train Epoch: 129 [120320/232365 (52%)]\tLoss: 169.801498\n",
            "Train Epoch: 129 [121600/232365 (52%)]\tLoss: 173.642303\n",
            "Train Epoch: 129 [122880/232365 (53%)]\tLoss: 170.345200\n",
            "Train Epoch: 129 [124160/232365 (53%)]\tLoss: 174.002762\n",
            "Train Epoch: 129 [125440/232365 (54%)]\tLoss: 180.510101\n",
            "Train Epoch: 129 [126720/232365 (55%)]\tLoss: 181.170837\n",
            "Train Epoch: 129 [128000/232365 (55%)]\tLoss: 165.814941\n",
            "Train Epoch: 129 [129280/232365 (56%)]\tLoss: 171.698517\n",
            "Train Epoch: 129 [130560/232365 (56%)]\tLoss: 162.125763\n",
            "Train Epoch: 129 [131840/232365 (57%)]\tLoss: 178.508728\n",
            "Train Epoch: 129 [133120/232365 (57%)]\tLoss: 170.108521\n",
            "Train Epoch: 129 [134400/232365 (58%)]\tLoss: 169.296219\n",
            "Train Epoch: 129 [135680/232365 (58%)]\tLoss: 167.323853\n",
            "Train Epoch: 129 [136960/232365 (59%)]\tLoss: 168.833527\n",
            "Train Epoch: 129 [138240/232365 (59%)]\tLoss: 172.235886\n",
            "Train Epoch: 129 [139520/232365 (60%)]\tLoss: 178.247314\n",
            "Train Epoch: 129 [140800/232365 (61%)]\tLoss: 181.805450\n",
            "Train Epoch: 129 [142080/232365 (61%)]\tLoss: 169.537720\n",
            "Train Epoch: 129 [143360/232365 (62%)]\tLoss: 178.760849\n",
            "Train Epoch: 129 [144640/232365 (62%)]\tLoss: 168.765717\n",
            "Train Epoch: 129 [145920/232365 (63%)]\tLoss: 171.375931\n",
            "Train Epoch: 129 [147200/232365 (63%)]\tLoss: 179.746078\n",
            "Train Epoch: 129 [148480/232365 (64%)]\tLoss: 175.587814\n",
            "Train Epoch: 129 [149760/232365 (64%)]\tLoss: 169.431610\n",
            "Train Epoch: 129 [151040/232365 (65%)]\tLoss: 168.284134\n",
            "Train Epoch: 129 [152320/232365 (66%)]\tLoss: 167.658539\n",
            "Train Epoch: 129 [153600/232365 (66%)]\tLoss: 166.687820\n",
            "Train Epoch: 129 [154880/232365 (67%)]\tLoss: 176.131714\n",
            "Train Epoch: 129 [156160/232365 (67%)]\tLoss: 180.655762\n",
            "Train Epoch: 129 [157440/232365 (68%)]\tLoss: 166.585907\n",
            "Train Epoch: 129 [158720/232365 (68%)]\tLoss: 168.786163\n",
            "Train Epoch: 129 [160000/232365 (69%)]\tLoss: 178.323486\n",
            "Train Epoch: 129 [161280/232365 (69%)]\tLoss: 168.593475\n",
            "Train Epoch: 129 [162560/232365 (70%)]\tLoss: 171.203461\n",
            "Train Epoch: 129 [163840/232365 (70%)]\tLoss: 171.799988\n",
            "Train Epoch: 129 [165120/232365 (71%)]\tLoss: 173.693878\n",
            "Train Epoch: 129 [166400/232365 (72%)]\tLoss: 165.206879\n",
            "Train Epoch: 129 [167680/232365 (72%)]\tLoss: 179.504395\n",
            "Train Epoch: 129 [168960/232365 (73%)]\tLoss: 177.360199\n",
            "Train Epoch: 129 [170240/232365 (73%)]\tLoss: 174.207581\n",
            "Train Epoch: 129 [171520/232365 (74%)]\tLoss: 188.107224\n",
            "Train Epoch: 129 [172800/232365 (74%)]\tLoss: 165.796570\n",
            "Train Epoch: 129 [174080/232365 (75%)]\tLoss: 171.408386\n",
            "Train Epoch: 129 [175360/232365 (75%)]\tLoss: 168.854340\n",
            "Train Epoch: 129 [176640/232365 (76%)]\tLoss: 181.446640\n",
            "Train Epoch: 129 [177920/232365 (77%)]\tLoss: 171.335815\n",
            "Train Epoch: 129 [179200/232365 (77%)]\tLoss: 180.374695\n",
            "Train Epoch: 129 [180480/232365 (78%)]\tLoss: 169.023087\n",
            "Train Epoch: 129 [181760/232365 (78%)]\tLoss: 173.235107\n",
            "Train Epoch: 129 [183040/232365 (79%)]\tLoss: 173.200104\n",
            "Train Epoch: 129 [184320/232365 (79%)]\tLoss: 174.360931\n",
            "Train Epoch: 129 [185600/232365 (80%)]\tLoss: 172.551773\n",
            "Train Epoch: 129 [186880/232365 (80%)]\tLoss: 177.059296\n",
            "Train Epoch: 129 [188160/232365 (81%)]\tLoss: 172.250519\n",
            "Train Epoch: 129 [189440/232365 (81%)]\tLoss: 179.553009\n",
            "Train Epoch: 129 [190720/232365 (82%)]\tLoss: 182.671021\n",
            "Train Epoch: 129 [192000/232365 (83%)]\tLoss: 167.978577\n",
            "Train Epoch: 129 [193280/232365 (83%)]\tLoss: 164.770203\n",
            "Train Epoch: 129 [194560/232365 (84%)]\tLoss: 178.166321\n",
            "Train Epoch: 129 [195840/232365 (84%)]\tLoss: 178.249878\n",
            "Train Epoch: 129 [197120/232365 (85%)]\tLoss: 173.258301\n",
            "Train Epoch: 129 [198400/232365 (85%)]\tLoss: 168.186523\n",
            "Train Epoch: 129 [199680/232365 (86%)]\tLoss: 177.614288\n",
            "Train Epoch: 129 [200960/232365 (86%)]\tLoss: 166.894348\n",
            "Train Epoch: 129 [202240/232365 (87%)]\tLoss: 174.089874\n",
            "Train Epoch: 129 [203520/232365 (88%)]\tLoss: 177.760468\n",
            "Train Epoch: 129 [204800/232365 (88%)]\tLoss: 174.827072\n",
            "Train Epoch: 129 [206080/232365 (89%)]\tLoss: 179.916199\n",
            "Train Epoch: 129 [207360/232365 (89%)]\tLoss: 170.225220\n",
            "Train Epoch: 129 [208640/232365 (90%)]\tLoss: 184.541153\n",
            "Train Epoch: 129 [209920/232365 (90%)]\tLoss: 168.937637\n",
            "Train Epoch: 129 [211200/232365 (91%)]\tLoss: 181.832321\n",
            "Train Epoch: 129 [212480/232365 (91%)]\tLoss: 176.440247\n",
            "Train Epoch: 129 [213760/232365 (92%)]\tLoss: 177.466034\n",
            "Train Epoch: 129 [215040/232365 (93%)]\tLoss: 170.688675\n",
            "Train Epoch: 129 [216320/232365 (93%)]\tLoss: 176.011398\n",
            "Train Epoch: 129 [217600/232365 (94%)]\tLoss: 179.743820\n",
            "Train Epoch: 129 [218880/232365 (94%)]\tLoss: 171.281128\n",
            "Train Epoch: 129 [220160/232365 (95%)]\tLoss: 170.046341\n",
            "Train Epoch: 129 [221440/232365 (95%)]\tLoss: 180.261276\n",
            "Train Epoch: 129 [222720/232365 (96%)]\tLoss: 178.600388\n",
            "Train Epoch: 129 [224000/232365 (96%)]\tLoss: 167.856491\n",
            "Train Epoch: 129 [225280/232365 (97%)]\tLoss: 180.355255\n",
            "Train Epoch: 129 [226560/232365 (97%)]\tLoss: 169.740631\n",
            "Train Epoch: 129 [227840/232365 (98%)]\tLoss: 174.985535\n",
            "Train Epoch: 129 [229120/232365 (99%)]\tLoss: 172.349915\n",
            "Train Epoch: 129 [230400/232365 (99%)]\tLoss: 168.389389\n",
            "Train Epoch: 129 [231680/232365 (100%)]\tLoss: 165.306534\n",
            "====> Epoch: 129 Average loss: 172.5614, Accuracy: 74.23%\n",
            "====> Test set loss: 183.0740, Accuracy: 74.14%\n",
            "Train Epoch: 130 [0/232365 (0%)]\tLoss: 165.911942\n",
            "Train Epoch: 130 [1280/232365 (1%)]\tLoss: 166.676483\n",
            "Train Epoch: 130 [2560/232365 (1%)]\tLoss: 167.258698\n",
            "Train Epoch: 130 [3840/232365 (2%)]\tLoss: 163.723694\n",
            "Train Epoch: 130 [5120/232365 (2%)]\tLoss: 170.674591\n",
            "Train Epoch: 130 [6400/232365 (3%)]\tLoss: 175.044800\n",
            "Train Epoch: 130 [7680/232365 (3%)]\tLoss: 162.423874\n",
            "Train Epoch: 130 [8960/232365 (4%)]\tLoss: 183.151947\n",
            "Train Epoch: 130 [10240/232365 (4%)]\tLoss: 165.577530\n",
            "Train Epoch: 130 [11520/232365 (5%)]\tLoss: 161.355713\n",
            "Train Epoch: 130 [12800/232365 (6%)]\tLoss: 175.434341\n",
            "Train Epoch: 130 [14080/232365 (6%)]\tLoss: 173.264664\n",
            "Train Epoch: 130 [15360/232365 (7%)]\tLoss: 180.154175\n",
            "Train Epoch: 130 [16640/232365 (7%)]\tLoss: 173.811050\n",
            "Train Epoch: 130 [17920/232365 (8%)]\tLoss: 169.623718\n",
            "Train Epoch: 130 [19200/232365 (8%)]\tLoss: 170.905960\n",
            "Train Epoch: 130 [20480/232365 (9%)]\tLoss: 167.253571\n",
            "Train Epoch: 130 [21760/232365 (9%)]\tLoss: 175.664703\n",
            "Train Epoch: 130 [23040/232365 (10%)]\tLoss: 174.231491\n",
            "Train Epoch: 130 [24320/232365 (10%)]\tLoss: 166.520660\n",
            "Train Epoch: 130 [25600/232365 (11%)]\tLoss: 183.297913\n",
            "Train Epoch: 130 [26880/232365 (12%)]\tLoss: 174.991608\n",
            "Train Epoch: 130 [28160/232365 (12%)]\tLoss: 177.651764\n",
            "Train Epoch: 130 [29440/232365 (13%)]\tLoss: 169.490326\n",
            "Train Epoch: 130 [30720/232365 (13%)]\tLoss: 176.754578\n",
            "Train Epoch: 130 [32000/232365 (14%)]\tLoss: 169.690796\n",
            "Train Epoch: 130 [33280/232365 (14%)]\tLoss: 172.911285\n",
            "Train Epoch: 130 [34560/232365 (15%)]\tLoss: 165.266403\n",
            "Train Epoch: 130 [35840/232365 (15%)]\tLoss: 172.576447\n",
            "Train Epoch: 130 [37120/232365 (16%)]\tLoss: 174.673309\n",
            "Train Epoch: 130 [38400/232365 (17%)]\tLoss: 171.914383\n",
            "Train Epoch: 130 [39680/232365 (17%)]\tLoss: 179.740311\n",
            "Train Epoch: 130 [40960/232365 (18%)]\tLoss: 162.963989\n",
            "Train Epoch: 130 [42240/232365 (18%)]\tLoss: 173.226868\n",
            "Train Epoch: 130 [43520/232365 (19%)]\tLoss: 167.985458\n",
            "Train Epoch: 130 [44800/232365 (19%)]\tLoss: 174.975113\n",
            "Train Epoch: 130 [46080/232365 (20%)]\tLoss: 177.217468\n",
            "Train Epoch: 130 [47360/232365 (20%)]\tLoss: 166.879013\n",
            "Train Epoch: 130 [48640/232365 (21%)]\tLoss: 171.963867\n",
            "Train Epoch: 130 [49920/232365 (21%)]\tLoss: 162.585083\n",
            "Train Epoch: 130 [51200/232365 (22%)]\tLoss: 181.109314\n",
            "Train Epoch: 130 [52480/232365 (23%)]\tLoss: 186.633560\n",
            "Train Epoch: 130 [53760/232365 (23%)]\tLoss: 168.711838\n",
            "Train Epoch: 130 [55040/232365 (24%)]\tLoss: 162.266937\n",
            "Train Epoch: 130 [56320/232365 (24%)]\tLoss: 173.694550\n",
            "Train Epoch: 130 [57600/232365 (25%)]\tLoss: 172.471344\n",
            "Train Epoch: 130 [58880/232365 (25%)]\tLoss: 171.544968\n",
            "Train Epoch: 130 [60160/232365 (26%)]\tLoss: 175.921997\n",
            "Train Epoch: 130 [61440/232365 (26%)]\tLoss: 175.308365\n",
            "Train Epoch: 130 [62720/232365 (27%)]\tLoss: 173.291550\n",
            "Train Epoch: 130 [64000/232365 (28%)]\tLoss: 171.828781\n",
            "Train Epoch: 130 [65280/232365 (28%)]\tLoss: 173.726501\n",
            "Train Epoch: 130 [66560/232365 (29%)]\tLoss: 179.497604\n",
            "Train Epoch: 130 [67840/232365 (29%)]\tLoss: 177.188568\n",
            "Train Epoch: 130 [69120/232365 (30%)]\tLoss: 165.485657\n",
            "Train Epoch: 130 [70400/232365 (30%)]\tLoss: 176.882141\n",
            "Train Epoch: 130 [71680/232365 (31%)]\tLoss: 163.829132\n",
            "Train Epoch: 130 [72960/232365 (31%)]\tLoss: 170.425003\n",
            "Train Epoch: 130 [74240/232365 (32%)]\tLoss: 166.187088\n",
            "Train Epoch: 130 [75520/232365 (32%)]\tLoss: 167.952560\n",
            "Train Epoch: 130 [76800/232365 (33%)]\tLoss: 170.510513\n",
            "Train Epoch: 130 [78080/232365 (34%)]\tLoss: 162.803253\n",
            "Train Epoch: 130 [79360/232365 (34%)]\tLoss: 166.200455\n",
            "Train Epoch: 130 [80640/232365 (35%)]\tLoss: 169.301788\n",
            "Train Epoch: 130 [81920/232365 (35%)]\tLoss: 165.220520\n",
            "Train Epoch: 130 [83200/232365 (36%)]\tLoss: 181.378403\n",
            "Train Epoch: 130 [84480/232365 (36%)]\tLoss: 169.152634\n",
            "Train Epoch: 130 [85760/232365 (37%)]\tLoss: 176.860870\n",
            "Train Epoch: 130 [87040/232365 (37%)]\tLoss: 171.526413\n",
            "Train Epoch: 130 [88320/232365 (38%)]\tLoss: 171.283920\n",
            "Train Epoch: 130 [89600/232365 (39%)]\tLoss: 178.795258\n",
            "Train Epoch: 130 [90880/232365 (39%)]\tLoss: 170.618301\n",
            "Train Epoch: 130 [92160/232365 (40%)]\tLoss: 175.573135\n",
            "Train Epoch: 130 [93440/232365 (40%)]\tLoss: 176.427414\n",
            "Train Epoch: 130 [94720/232365 (41%)]\tLoss: 176.219559\n",
            "Train Epoch: 130 [96000/232365 (41%)]\tLoss: 177.447296\n",
            "Train Epoch: 130 [97280/232365 (42%)]\tLoss: 182.442017\n",
            "Train Epoch: 130 [98560/232365 (42%)]\tLoss: 178.462692\n",
            "Train Epoch: 130 [99840/232365 (43%)]\tLoss: 175.185684\n",
            "Train Epoch: 130 [101120/232365 (44%)]\tLoss: 172.599960\n",
            "Train Epoch: 130 [102400/232365 (44%)]\tLoss: 170.323090\n",
            "Train Epoch: 130 [103680/232365 (45%)]\tLoss: 167.478851\n",
            "Train Epoch: 130 [104960/232365 (45%)]\tLoss: 166.403793\n",
            "Train Epoch: 130 [106240/232365 (46%)]\tLoss: 182.767456\n",
            "Train Epoch: 130 [107520/232365 (46%)]\tLoss: 174.611435\n",
            "Train Epoch: 130 [108800/232365 (47%)]\tLoss: 176.225128\n",
            "Train Epoch: 130 [110080/232365 (47%)]\tLoss: 175.730499\n",
            "Train Epoch: 130 [111360/232365 (48%)]\tLoss: 168.628830\n",
            "Train Epoch: 130 [112640/232365 (48%)]\tLoss: 169.393555\n",
            "Train Epoch: 130 [113920/232365 (49%)]\tLoss: 182.872543\n",
            "Train Epoch: 130 [115200/232365 (50%)]\tLoss: 169.789719\n",
            "Train Epoch: 130 [116480/232365 (50%)]\tLoss: 170.051498\n",
            "Train Epoch: 130 [117760/232365 (51%)]\tLoss: 172.209320\n",
            "Train Epoch: 130 [119040/232365 (51%)]\tLoss: 165.753754\n",
            "Train Epoch: 130 [120320/232365 (52%)]\tLoss: 176.636002\n",
            "Train Epoch: 130 [121600/232365 (52%)]\tLoss: 166.932663\n",
            "Train Epoch: 130 [122880/232365 (53%)]\tLoss: 172.756104\n",
            "Train Epoch: 130 [124160/232365 (53%)]\tLoss: 163.722809\n",
            "Train Epoch: 130 [125440/232365 (54%)]\tLoss: 176.162903\n",
            "Train Epoch: 130 [126720/232365 (55%)]\tLoss: 173.467957\n",
            "Train Epoch: 130 [128000/232365 (55%)]\tLoss: 181.728729\n",
            "Train Epoch: 130 [129280/232365 (56%)]\tLoss: 175.382553\n",
            "Train Epoch: 130 [130560/232365 (56%)]\tLoss: 170.067383\n",
            "Train Epoch: 130 [131840/232365 (57%)]\tLoss: 175.562073\n",
            "Train Epoch: 130 [133120/232365 (57%)]\tLoss: 166.729095\n",
            "Train Epoch: 130 [134400/232365 (58%)]\tLoss: 171.951752\n",
            "Train Epoch: 130 [135680/232365 (58%)]\tLoss: 171.460052\n",
            "Train Epoch: 130 [136960/232365 (59%)]\tLoss: 166.862869\n",
            "Train Epoch: 130 [138240/232365 (59%)]\tLoss: 182.667023\n",
            "Train Epoch: 130 [139520/232365 (60%)]\tLoss: 180.503952\n",
            "Train Epoch: 130 [140800/232365 (61%)]\tLoss: 172.875214\n",
            "Train Epoch: 130 [142080/232365 (61%)]\tLoss: 171.836090\n",
            "Train Epoch: 130 [143360/232365 (62%)]\tLoss: 170.984558\n",
            "Train Epoch: 130 [144640/232365 (62%)]\tLoss: 174.117096\n",
            "Train Epoch: 130 [145920/232365 (63%)]\tLoss: 179.090149\n",
            "Train Epoch: 130 [147200/232365 (63%)]\tLoss: 174.826065\n",
            "Train Epoch: 130 [148480/232365 (64%)]\tLoss: 171.145599\n",
            "Train Epoch: 130 [149760/232365 (64%)]\tLoss: 169.244873\n",
            "Train Epoch: 130 [151040/232365 (65%)]\tLoss: 170.993454\n",
            "Train Epoch: 130 [152320/232365 (66%)]\tLoss: 170.475037\n",
            "Train Epoch: 130 [153600/232365 (66%)]\tLoss: 169.325516\n",
            "Train Epoch: 130 [154880/232365 (67%)]\tLoss: 164.556671\n",
            "Train Epoch: 130 [156160/232365 (67%)]\tLoss: 169.627777\n",
            "Train Epoch: 130 [157440/232365 (68%)]\tLoss: 169.517548\n",
            "Train Epoch: 130 [158720/232365 (68%)]\tLoss: 173.962006\n",
            "Train Epoch: 130 [160000/232365 (69%)]\tLoss: 178.603012\n",
            "Train Epoch: 130 [161280/232365 (69%)]\tLoss: 177.460587\n",
            "Train Epoch: 130 [162560/232365 (70%)]\tLoss: 174.417084\n",
            "Train Epoch: 130 [163840/232365 (70%)]\tLoss: 170.430328\n",
            "Train Epoch: 130 [165120/232365 (71%)]\tLoss: 177.688065\n",
            "Train Epoch: 130 [166400/232365 (72%)]\tLoss: 173.687714\n",
            "Train Epoch: 130 [167680/232365 (72%)]\tLoss: 174.315369\n",
            "Train Epoch: 130 [168960/232365 (73%)]\tLoss: 169.474915\n",
            "Train Epoch: 130 [170240/232365 (73%)]\tLoss: 177.915344\n",
            "Train Epoch: 130 [171520/232365 (74%)]\tLoss: 169.300385\n",
            "Train Epoch: 130 [172800/232365 (74%)]\tLoss: 160.016495\n",
            "Train Epoch: 130 [174080/232365 (75%)]\tLoss: 171.651398\n",
            "Train Epoch: 130 [175360/232365 (75%)]\tLoss: 166.807709\n",
            "Train Epoch: 130 [176640/232365 (76%)]\tLoss: 175.254227\n",
            "Train Epoch: 130 [177920/232365 (77%)]\tLoss: 167.100983\n",
            "Train Epoch: 130 [179200/232365 (77%)]\tLoss: 167.569290\n",
            "Train Epoch: 130 [180480/232365 (78%)]\tLoss: 170.214294\n",
            "Train Epoch: 130 [181760/232365 (78%)]\tLoss: 183.583694\n",
            "Train Epoch: 130 [183040/232365 (79%)]\tLoss: 171.432846\n",
            "Train Epoch: 130 [184320/232365 (79%)]\tLoss: 175.316101\n",
            "Train Epoch: 130 [185600/232365 (80%)]\tLoss: 163.016693\n",
            "Train Epoch: 130 [186880/232365 (80%)]\tLoss: 165.946655\n",
            "Train Epoch: 130 [188160/232365 (81%)]\tLoss: 170.037201\n",
            "Train Epoch: 130 [189440/232365 (81%)]\tLoss: 168.110062\n",
            "Train Epoch: 130 [190720/232365 (82%)]\tLoss: 176.399780\n",
            "Train Epoch: 130 [192000/232365 (83%)]\tLoss: 168.068665\n",
            "Train Epoch: 130 [193280/232365 (83%)]\tLoss: 177.756744\n",
            "Train Epoch: 130 [194560/232365 (84%)]\tLoss: 170.264771\n",
            "Train Epoch: 130 [195840/232365 (84%)]\tLoss: 175.226288\n",
            "Train Epoch: 130 [197120/232365 (85%)]\tLoss: 169.208389\n",
            "Train Epoch: 130 [198400/232365 (85%)]\tLoss: 175.688766\n",
            "Train Epoch: 130 [199680/232365 (86%)]\tLoss: 175.656311\n",
            "Train Epoch: 130 [200960/232365 (86%)]\tLoss: 170.866043\n",
            "Train Epoch: 130 [202240/232365 (87%)]\tLoss: 180.732849\n",
            "Train Epoch: 130 [203520/232365 (88%)]\tLoss: 170.675079\n",
            "Train Epoch: 130 [204800/232365 (88%)]\tLoss: 164.532593\n",
            "Train Epoch: 130 [206080/232365 (89%)]\tLoss: 171.401566\n",
            "Train Epoch: 130 [207360/232365 (89%)]\tLoss: 173.536621\n",
            "Train Epoch: 130 [208640/232365 (90%)]\tLoss: 181.372971\n",
            "Train Epoch: 130 [209920/232365 (90%)]\tLoss: 177.994141\n",
            "Train Epoch: 130 [211200/232365 (91%)]\tLoss: 170.172821\n",
            "Train Epoch: 130 [212480/232365 (91%)]\tLoss: 169.898865\n",
            "Train Epoch: 130 [213760/232365 (92%)]\tLoss: 161.848907\n",
            "Train Epoch: 130 [215040/232365 (93%)]\tLoss: 174.162186\n",
            "Train Epoch: 130 [216320/232365 (93%)]\tLoss: 178.670853\n",
            "Train Epoch: 130 [217600/232365 (94%)]\tLoss: 173.889130\n",
            "Train Epoch: 130 [218880/232365 (94%)]\tLoss: 182.238113\n",
            "Train Epoch: 130 [220160/232365 (95%)]\tLoss: 171.228989\n",
            "Train Epoch: 130 [221440/232365 (95%)]\tLoss: 179.662598\n",
            "Train Epoch: 130 [222720/232365 (96%)]\tLoss: 169.932816\n",
            "Train Epoch: 130 [224000/232365 (96%)]\tLoss: 169.712494\n",
            "Train Epoch: 130 [225280/232365 (97%)]\tLoss: 169.666611\n",
            "Train Epoch: 130 [226560/232365 (97%)]\tLoss: 185.017822\n",
            "Train Epoch: 130 [227840/232365 (98%)]\tLoss: 173.770859\n",
            "Train Epoch: 130 [229120/232365 (99%)]\tLoss: 171.809814\n",
            "Train Epoch: 130 [230400/232365 (99%)]\tLoss: 178.199310\n",
            "Train Epoch: 130 [231680/232365 (100%)]\tLoss: 171.018753\n",
            "====> Epoch: 130 Average loss: 172.5429, Accuracy: 74.23%\n",
            "====> Test set loss: 183.4053, Accuracy: 74.13%\n",
            "Train Epoch: 131 [0/232365 (0%)]\tLoss: 179.269424\n",
            "Train Epoch: 131 [1280/232365 (1%)]\tLoss: 177.450897\n",
            "Train Epoch: 131 [2560/232365 (1%)]\tLoss: 176.984055\n",
            "Train Epoch: 131 [3840/232365 (2%)]\tLoss: 185.140427\n",
            "Train Epoch: 131 [5120/232365 (2%)]\tLoss: 162.702423\n",
            "Train Epoch: 131 [6400/232365 (3%)]\tLoss: 174.754913\n",
            "Train Epoch: 131 [7680/232365 (3%)]\tLoss: 170.033432\n",
            "Train Epoch: 131 [8960/232365 (4%)]\tLoss: 176.553314\n",
            "Train Epoch: 131 [10240/232365 (4%)]\tLoss: 170.013306\n",
            "Train Epoch: 131 [11520/232365 (5%)]\tLoss: 171.123062\n",
            "Train Epoch: 131 [12800/232365 (6%)]\tLoss: 167.859863\n",
            "Train Epoch: 131 [14080/232365 (6%)]\tLoss: 171.415695\n",
            "Train Epoch: 131 [15360/232365 (7%)]\tLoss: 167.167755\n",
            "Train Epoch: 131 [16640/232365 (7%)]\tLoss: 172.000092\n",
            "Train Epoch: 131 [17920/232365 (8%)]\tLoss: 167.190613\n",
            "Train Epoch: 131 [19200/232365 (8%)]\tLoss: 174.773666\n",
            "Train Epoch: 131 [20480/232365 (9%)]\tLoss: 169.936096\n",
            "Train Epoch: 131 [21760/232365 (9%)]\tLoss: 160.073807\n",
            "Train Epoch: 131 [23040/232365 (10%)]\tLoss: 172.449158\n",
            "Train Epoch: 131 [24320/232365 (10%)]\tLoss: 166.262741\n",
            "Train Epoch: 131 [25600/232365 (11%)]\tLoss: 172.457489\n",
            "Train Epoch: 131 [26880/232365 (12%)]\tLoss: 177.469269\n",
            "Train Epoch: 131 [28160/232365 (12%)]\tLoss: 176.332184\n",
            "Train Epoch: 131 [29440/232365 (13%)]\tLoss: 172.310257\n",
            "Train Epoch: 131 [30720/232365 (13%)]\tLoss: 163.701981\n",
            "Train Epoch: 131 [32000/232365 (14%)]\tLoss: 175.288864\n",
            "Train Epoch: 131 [33280/232365 (14%)]\tLoss: 169.568390\n",
            "Train Epoch: 131 [34560/232365 (15%)]\tLoss: 168.345474\n",
            "Train Epoch: 131 [35840/232365 (15%)]\tLoss: 177.218445\n",
            "Train Epoch: 131 [37120/232365 (16%)]\tLoss: 186.246643\n",
            "Train Epoch: 131 [38400/232365 (17%)]\tLoss: 177.148682\n",
            "Train Epoch: 131 [39680/232365 (17%)]\tLoss: 180.066895\n",
            "Train Epoch: 131 [40960/232365 (18%)]\tLoss: 172.712814\n",
            "Train Epoch: 131 [42240/232365 (18%)]\tLoss: 174.976135\n",
            "Train Epoch: 131 [43520/232365 (19%)]\tLoss: 163.817352\n",
            "Train Epoch: 131 [44800/232365 (19%)]\tLoss: 176.914185\n",
            "Train Epoch: 131 [46080/232365 (20%)]\tLoss: 164.098022\n",
            "Train Epoch: 131 [47360/232365 (20%)]\tLoss: 163.316040\n",
            "Train Epoch: 131 [48640/232365 (21%)]\tLoss: 171.086975\n",
            "Train Epoch: 131 [49920/232365 (21%)]\tLoss: 171.207504\n",
            "Train Epoch: 131 [51200/232365 (22%)]\tLoss: 172.244553\n",
            "Train Epoch: 131 [52480/232365 (23%)]\tLoss: 174.423584\n",
            "Train Epoch: 131 [53760/232365 (23%)]\tLoss: 173.991684\n",
            "Train Epoch: 131 [55040/232365 (24%)]\tLoss: 177.359589\n",
            "Train Epoch: 131 [56320/232365 (24%)]\tLoss: 170.614441\n",
            "Train Epoch: 131 [57600/232365 (25%)]\tLoss: 175.460892\n",
            "Train Epoch: 131 [58880/232365 (25%)]\tLoss: 175.200211\n",
            "Train Epoch: 131 [60160/232365 (26%)]\tLoss: 167.342102\n",
            "Train Epoch: 131 [61440/232365 (26%)]\tLoss: 173.344666\n",
            "Train Epoch: 131 [62720/232365 (27%)]\tLoss: 178.034149\n",
            "Train Epoch: 131 [64000/232365 (28%)]\tLoss: 177.121689\n",
            "Train Epoch: 131 [65280/232365 (28%)]\tLoss: 178.286713\n",
            "Train Epoch: 131 [66560/232365 (29%)]\tLoss: 172.195953\n",
            "Train Epoch: 131 [67840/232365 (29%)]\tLoss: 158.418304\n",
            "Train Epoch: 131 [69120/232365 (30%)]\tLoss: 166.757431\n",
            "Train Epoch: 131 [70400/232365 (30%)]\tLoss: 171.921585\n",
            "Train Epoch: 131 [71680/232365 (31%)]\tLoss: 165.601761\n",
            "Train Epoch: 131 [72960/232365 (31%)]\tLoss: 173.902969\n",
            "Train Epoch: 131 [74240/232365 (32%)]\tLoss: 179.431458\n",
            "Train Epoch: 131 [75520/232365 (32%)]\tLoss: 172.756256\n",
            "Train Epoch: 131 [76800/232365 (33%)]\tLoss: 184.402679\n",
            "Train Epoch: 131 [78080/232365 (34%)]\tLoss: 175.243347\n",
            "Train Epoch: 131 [79360/232365 (34%)]\tLoss: 172.472794\n",
            "Train Epoch: 131 [80640/232365 (35%)]\tLoss: 172.855255\n",
            "Train Epoch: 131 [81920/232365 (35%)]\tLoss: 160.106476\n",
            "Train Epoch: 131 [83200/232365 (36%)]\tLoss: 171.794907\n",
            "Train Epoch: 131 [84480/232365 (36%)]\tLoss: 175.868668\n",
            "Train Epoch: 131 [85760/232365 (37%)]\tLoss: 184.567596\n",
            "Train Epoch: 131 [87040/232365 (37%)]\tLoss: 174.152954\n",
            "Train Epoch: 131 [88320/232365 (38%)]\tLoss: 166.078049\n",
            "Train Epoch: 131 [89600/232365 (39%)]\tLoss: 164.226303\n",
            "Train Epoch: 131 [90880/232365 (39%)]\tLoss: 180.779099\n",
            "Train Epoch: 131 [92160/232365 (40%)]\tLoss: 173.842865\n",
            "Train Epoch: 131 [93440/232365 (40%)]\tLoss: 175.764359\n",
            "Train Epoch: 131 [94720/232365 (41%)]\tLoss: 169.284821\n",
            "Train Epoch: 131 [96000/232365 (41%)]\tLoss: 175.113983\n",
            "Train Epoch: 131 [97280/232365 (42%)]\tLoss: 177.830750\n",
            "Train Epoch: 131 [98560/232365 (42%)]\tLoss: 181.669922\n",
            "Train Epoch: 131 [99840/232365 (43%)]\tLoss: 168.035080\n",
            "Train Epoch: 131 [101120/232365 (44%)]\tLoss: 166.016479\n",
            "Train Epoch: 131 [102400/232365 (44%)]\tLoss: 172.965424\n",
            "Train Epoch: 131 [103680/232365 (45%)]\tLoss: 173.534363\n",
            "Train Epoch: 131 [104960/232365 (45%)]\tLoss: 175.250290\n",
            "Train Epoch: 131 [106240/232365 (46%)]\tLoss: 169.074417\n",
            "Train Epoch: 131 [107520/232365 (46%)]\tLoss: 175.976105\n",
            "Train Epoch: 131 [108800/232365 (47%)]\tLoss: 175.692535\n",
            "Train Epoch: 131 [110080/232365 (47%)]\tLoss: 163.731827\n",
            "Train Epoch: 131 [111360/232365 (48%)]\tLoss: 166.399231\n",
            "Train Epoch: 131 [112640/232365 (48%)]\tLoss: 168.629669\n",
            "Train Epoch: 131 [113920/232365 (49%)]\tLoss: 167.642120\n",
            "Train Epoch: 131 [115200/232365 (50%)]\tLoss: 180.294144\n",
            "Train Epoch: 131 [116480/232365 (50%)]\tLoss: 169.077850\n",
            "Train Epoch: 131 [117760/232365 (51%)]\tLoss: 180.078400\n",
            "Train Epoch: 131 [119040/232365 (51%)]\tLoss: 169.205612\n",
            "Train Epoch: 131 [120320/232365 (52%)]\tLoss: 171.625092\n",
            "Train Epoch: 131 [121600/232365 (52%)]\tLoss: 172.553314\n",
            "Train Epoch: 131 [122880/232365 (53%)]\tLoss: 173.529129\n",
            "Train Epoch: 131 [124160/232365 (53%)]\tLoss: 170.702164\n",
            "Train Epoch: 131 [125440/232365 (54%)]\tLoss: 170.761337\n",
            "Train Epoch: 131 [126720/232365 (55%)]\tLoss: 177.094177\n",
            "Train Epoch: 131 [128000/232365 (55%)]\tLoss: 177.541428\n",
            "Train Epoch: 131 [129280/232365 (56%)]\tLoss: 168.826874\n",
            "Train Epoch: 131 [130560/232365 (56%)]\tLoss: 169.725784\n",
            "Train Epoch: 131 [131840/232365 (57%)]\tLoss: 171.985550\n",
            "Train Epoch: 131 [133120/232365 (57%)]\tLoss: 164.525208\n",
            "Train Epoch: 131 [134400/232365 (58%)]\tLoss: 172.911224\n",
            "Train Epoch: 131 [135680/232365 (58%)]\tLoss: 162.446030\n",
            "Train Epoch: 131 [136960/232365 (59%)]\tLoss: 171.360611\n",
            "Train Epoch: 131 [138240/232365 (59%)]\tLoss: 176.562790\n",
            "Train Epoch: 131 [139520/232365 (60%)]\tLoss: 167.964447\n",
            "Train Epoch: 131 [140800/232365 (61%)]\tLoss: 181.549271\n",
            "Train Epoch: 131 [142080/232365 (61%)]\tLoss: 176.149048\n",
            "Train Epoch: 131 [143360/232365 (62%)]\tLoss: 168.501907\n",
            "Train Epoch: 131 [144640/232365 (62%)]\tLoss: 173.806107\n",
            "Train Epoch: 131 [145920/232365 (63%)]\tLoss: 175.038345\n",
            "Train Epoch: 131 [147200/232365 (63%)]\tLoss: 179.951523\n",
            "Train Epoch: 131 [148480/232365 (64%)]\tLoss: 183.494507\n",
            "Train Epoch: 131 [149760/232365 (64%)]\tLoss: 173.700775\n",
            "Train Epoch: 131 [151040/232365 (65%)]\tLoss: 169.645996\n",
            "Train Epoch: 131 [152320/232365 (66%)]\tLoss: 170.266129\n",
            "Train Epoch: 131 [153600/232365 (66%)]\tLoss: 176.023468\n",
            "Train Epoch: 131 [154880/232365 (67%)]\tLoss: 173.466049\n",
            "Train Epoch: 131 [156160/232365 (67%)]\tLoss: 177.524078\n",
            "Train Epoch: 131 [157440/232365 (68%)]\tLoss: 183.991669\n",
            "Train Epoch: 131 [158720/232365 (68%)]\tLoss: 171.424164\n",
            "Train Epoch: 131 [160000/232365 (69%)]\tLoss: 174.737930\n",
            "Train Epoch: 131 [161280/232365 (69%)]\tLoss: 177.259460\n",
            "Train Epoch: 131 [162560/232365 (70%)]\tLoss: 168.173248\n",
            "Train Epoch: 131 [163840/232365 (70%)]\tLoss: 172.184525\n",
            "Train Epoch: 131 [165120/232365 (71%)]\tLoss: 174.605972\n",
            "Train Epoch: 131 [166400/232365 (72%)]\tLoss: 169.555923\n",
            "Train Epoch: 131 [167680/232365 (72%)]\tLoss: 174.442047\n",
            "Train Epoch: 131 [168960/232365 (73%)]\tLoss: 168.287399\n",
            "Train Epoch: 131 [170240/232365 (73%)]\tLoss: 165.919373\n",
            "Train Epoch: 131 [171520/232365 (74%)]\tLoss: 169.856964\n",
            "Train Epoch: 131 [172800/232365 (74%)]\tLoss: 173.736893\n",
            "Train Epoch: 131 [174080/232365 (75%)]\tLoss: 180.199539\n",
            "Train Epoch: 131 [175360/232365 (75%)]\tLoss: 177.764847\n",
            "Train Epoch: 131 [176640/232365 (76%)]\tLoss: 174.587524\n",
            "Train Epoch: 131 [177920/232365 (77%)]\tLoss: 177.402130\n",
            "Train Epoch: 131 [179200/232365 (77%)]\tLoss: 174.786316\n",
            "Train Epoch: 131 [180480/232365 (78%)]\tLoss: 180.476746\n",
            "Train Epoch: 131 [181760/232365 (78%)]\tLoss: 170.287064\n",
            "Train Epoch: 131 [183040/232365 (79%)]\tLoss: 161.754715\n",
            "Train Epoch: 131 [184320/232365 (79%)]\tLoss: 168.599182\n",
            "Train Epoch: 131 [185600/232365 (80%)]\tLoss: 175.086426\n",
            "Train Epoch: 131 [186880/232365 (80%)]\tLoss: 172.414551\n",
            "Train Epoch: 131 [188160/232365 (81%)]\tLoss: 185.103180\n",
            "Train Epoch: 131 [189440/232365 (81%)]\tLoss: 169.003693\n",
            "Train Epoch: 131 [190720/232365 (82%)]\tLoss: 170.259476\n",
            "Train Epoch: 131 [192000/232365 (83%)]\tLoss: 166.795837\n",
            "Train Epoch: 131 [193280/232365 (83%)]\tLoss: 173.783813\n",
            "Train Epoch: 131 [194560/232365 (84%)]\tLoss: 168.817810\n",
            "Train Epoch: 131 [195840/232365 (84%)]\tLoss: 175.084183\n",
            "Train Epoch: 131 [197120/232365 (85%)]\tLoss: 160.432938\n",
            "Train Epoch: 131 [198400/232365 (85%)]\tLoss: 177.725037\n",
            "Train Epoch: 131 [199680/232365 (86%)]\tLoss: 173.252563\n",
            "Train Epoch: 131 [200960/232365 (86%)]\tLoss: 172.528580\n",
            "Train Epoch: 131 [202240/232365 (87%)]\tLoss: 170.266235\n",
            "Train Epoch: 131 [203520/232365 (88%)]\tLoss: 172.377625\n",
            "Train Epoch: 131 [204800/232365 (88%)]\tLoss: 166.195923\n",
            "Train Epoch: 131 [206080/232365 (89%)]\tLoss: 172.079102\n",
            "Train Epoch: 131 [207360/232365 (89%)]\tLoss: 160.971222\n",
            "Train Epoch: 131 [208640/232365 (90%)]\tLoss: 168.425049\n",
            "Train Epoch: 131 [209920/232365 (90%)]\tLoss: 172.172455\n",
            "Train Epoch: 131 [211200/232365 (91%)]\tLoss: 173.359222\n",
            "Train Epoch: 131 [212480/232365 (91%)]\tLoss: 171.130066\n",
            "Train Epoch: 131 [213760/232365 (92%)]\tLoss: 170.542908\n",
            "Train Epoch: 131 [215040/232365 (93%)]\tLoss: 169.653183\n",
            "Train Epoch: 131 [216320/232365 (93%)]\tLoss: 171.094818\n",
            "Train Epoch: 131 [217600/232365 (94%)]\tLoss: 170.916595\n",
            "Train Epoch: 131 [218880/232365 (94%)]\tLoss: 174.324982\n",
            "Train Epoch: 131 [220160/232365 (95%)]\tLoss: 166.766098\n",
            "Train Epoch: 131 [221440/232365 (95%)]\tLoss: 172.007629\n",
            "Train Epoch: 131 [222720/232365 (96%)]\tLoss: 171.984009\n",
            "Train Epoch: 131 [224000/232365 (96%)]\tLoss: 155.255692\n",
            "Train Epoch: 131 [225280/232365 (97%)]\tLoss: 162.035889\n",
            "Train Epoch: 131 [226560/232365 (97%)]\tLoss: 174.686966\n",
            "Train Epoch: 131 [227840/232365 (98%)]\tLoss: 177.366150\n",
            "Train Epoch: 131 [229120/232365 (99%)]\tLoss: 175.195221\n",
            "Train Epoch: 131 [230400/232365 (99%)]\tLoss: 178.482498\n",
            "Train Epoch: 131 [231680/232365 (100%)]\tLoss: 169.707748\n",
            "====> Epoch: 131 Average loss: 172.5295, Accuracy: 74.23%\n",
            "====> Test set loss: 183.2076, Accuracy: 74.12%\n",
            "Train Epoch: 132 [0/232365 (0%)]\tLoss: 171.223969\n",
            "Train Epoch: 132 [1280/232365 (1%)]\tLoss: 172.952377\n",
            "Train Epoch: 132 [2560/232365 (1%)]\tLoss: 175.905151\n",
            "Train Epoch: 132 [3840/232365 (2%)]\tLoss: 170.792740\n",
            "Train Epoch: 132 [5120/232365 (2%)]\tLoss: 156.497879\n",
            "Train Epoch: 132 [6400/232365 (3%)]\tLoss: 169.663391\n",
            "Train Epoch: 132 [7680/232365 (3%)]\tLoss: 173.339584\n",
            "Train Epoch: 132 [8960/232365 (4%)]\tLoss: 169.715546\n",
            "Train Epoch: 132 [10240/232365 (4%)]\tLoss: 164.656647\n",
            "Train Epoch: 132 [11520/232365 (5%)]\tLoss: 173.073807\n",
            "Train Epoch: 132 [12800/232365 (6%)]\tLoss: 175.558762\n",
            "Train Epoch: 132 [14080/232365 (6%)]\tLoss: 166.180328\n",
            "Train Epoch: 132 [15360/232365 (7%)]\tLoss: 167.475784\n",
            "Train Epoch: 132 [16640/232365 (7%)]\tLoss: 175.047043\n",
            "Train Epoch: 132 [17920/232365 (8%)]\tLoss: 162.919098\n",
            "Train Epoch: 132 [19200/232365 (8%)]\tLoss: 165.011612\n",
            "Train Epoch: 132 [20480/232365 (9%)]\tLoss: 165.889236\n",
            "Train Epoch: 132 [21760/232365 (9%)]\tLoss: 174.640625\n",
            "Train Epoch: 132 [23040/232365 (10%)]\tLoss: 173.836975\n",
            "Train Epoch: 132 [24320/232365 (10%)]\tLoss: 179.987701\n",
            "Train Epoch: 132 [25600/232365 (11%)]\tLoss: 167.346298\n",
            "Train Epoch: 132 [26880/232365 (12%)]\tLoss: 170.360016\n",
            "Train Epoch: 132 [28160/232365 (12%)]\tLoss: 171.312149\n",
            "Train Epoch: 132 [29440/232365 (13%)]\tLoss: 167.851120\n",
            "Train Epoch: 132 [30720/232365 (13%)]\tLoss: 170.932251\n",
            "Train Epoch: 132 [32000/232365 (14%)]\tLoss: 165.889969\n",
            "Train Epoch: 132 [33280/232365 (14%)]\tLoss: 177.856384\n",
            "Train Epoch: 132 [34560/232365 (15%)]\tLoss: 171.754166\n",
            "Train Epoch: 132 [35840/232365 (15%)]\tLoss: 176.636749\n",
            "Train Epoch: 132 [37120/232365 (16%)]\tLoss: 172.952164\n",
            "Train Epoch: 132 [38400/232365 (17%)]\tLoss: 175.504776\n",
            "Train Epoch: 132 [39680/232365 (17%)]\tLoss: 178.588821\n",
            "Train Epoch: 132 [40960/232365 (18%)]\tLoss: 174.587158\n",
            "Train Epoch: 132 [42240/232365 (18%)]\tLoss: 176.822586\n",
            "Train Epoch: 132 [43520/232365 (19%)]\tLoss: 181.367798\n",
            "Train Epoch: 132 [44800/232365 (19%)]\tLoss: 181.977478\n",
            "Train Epoch: 132 [46080/232365 (20%)]\tLoss: 170.132889\n",
            "Train Epoch: 132 [47360/232365 (20%)]\tLoss: 172.055176\n",
            "Train Epoch: 132 [48640/232365 (21%)]\tLoss: 173.467468\n",
            "Train Epoch: 132 [49920/232365 (21%)]\tLoss: 164.983948\n",
            "Train Epoch: 132 [51200/232365 (22%)]\tLoss: 177.772156\n",
            "Train Epoch: 132 [52480/232365 (23%)]\tLoss: 177.961060\n",
            "Train Epoch: 132 [53760/232365 (23%)]\tLoss: 170.444565\n",
            "Train Epoch: 132 [55040/232365 (24%)]\tLoss: 175.172485\n",
            "Train Epoch: 132 [56320/232365 (24%)]\tLoss: 167.364532\n",
            "Train Epoch: 132 [57600/232365 (25%)]\tLoss: 171.081436\n",
            "Train Epoch: 132 [58880/232365 (25%)]\tLoss: 167.873718\n",
            "Train Epoch: 132 [60160/232365 (26%)]\tLoss: 168.941544\n",
            "Train Epoch: 132 [61440/232365 (26%)]\tLoss: 164.339127\n",
            "Train Epoch: 132 [62720/232365 (27%)]\tLoss: 173.680847\n",
            "Train Epoch: 132 [64000/232365 (28%)]\tLoss: 171.648209\n",
            "Train Epoch: 132 [65280/232365 (28%)]\tLoss: 171.609985\n",
            "Train Epoch: 132 [66560/232365 (29%)]\tLoss: 166.454422\n",
            "Train Epoch: 132 [67840/232365 (29%)]\tLoss: 178.657410\n",
            "Train Epoch: 132 [69120/232365 (30%)]\tLoss: 171.091599\n",
            "Train Epoch: 132 [70400/232365 (30%)]\tLoss: 160.873566\n",
            "Train Epoch: 132 [71680/232365 (31%)]\tLoss: 178.117081\n",
            "Train Epoch: 132 [72960/232365 (31%)]\tLoss: 166.505783\n",
            "Train Epoch: 132 [74240/232365 (32%)]\tLoss: 171.014191\n",
            "Train Epoch: 132 [75520/232365 (32%)]\tLoss: 173.818726\n",
            "Train Epoch: 132 [76800/232365 (33%)]\tLoss: 163.315308\n",
            "Train Epoch: 132 [78080/232365 (34%)]\tLoss: 171.860748\n",
            "Train Epoch: 132 [79360/232365 (34%)]\tLoss: 174.368912\n",
            "Train Epoch: 132 [80640/232365 (35%)]\tLoss: 173.655014\n",
            "Train Epoch: 132 [81920/232365 (35%)]\tLoss: 169.989380\n",
            "Train Epoch: 132 [83200/232365 (36%)]\tLoss: 175.931870\n",
            "Train Epoch: 132 [84480/232365 (36%)]\tLoss: 179.890228\n",
            "Train Epoch: 132 [85760/232365 (37%)]\tLoss: 178.322113\n",
            "Train Epoch: 132 [87040/232365 (37%)]\tLoss: 173.037247\n",
            "Train Epoch: 132 [88320/232365 (38%)]\tLoss: 170.488800\n",
            "Train Epoch: 132 [89600/232365 (39%)]\tLoss: 171.723419\n",
            "Train Epoch: 132 [90880/232365 (39%)]\tLoss: 182.761353\n",
            "Train Epoch: 132 [92160/232365 (40%)]\tLoss: 180.591812\n",
            "Train Epoch: 132 [93440/232365 (40%)]\tLoss: 177.209579\n",
            "Train Epoch: 132 [94720/232365 (41%)]\tLoss: 175.853012\n",
            "Train Epoch: 132 [96000/232365 (41%)]\tLoss: 173.702621\n",
            "Train Epoch: 132 [97280/232365 (42%)]\tLoss: 171.360901\n",
            "Train Epoch: 132 [98560/232365 (42%)]\tLoss: 168.036819\n",
            "Train Epoch: 132 [99840/232365 (43%)]\tLoss: 164.465698\n",
            "Train Epoch: 132 [101120/232365 (44%)]\tLoss: 173.904129\n",
            "Train Epoch: 132 [102400/232365 (44%)]\tLoss: 179.330368\n",
            "Train Epoch: 132 [103680/232365 (45%)]\tLoss: 177.574890\n",
            "Train Epoch: 132 [104960/232365 (45%)]\tLoss: 178.069427\n",
            "Train Epoch: 132 [106240/232365 (46%)]\tLoss: 174.444427\n",
            "Train Epoch: 132 [107520/232365 (46%)]\tLoss: 179.728561\n",
            "Train Epoch: 132 [108800/232365 (47%)]\tLoss: 178.107040\n",
            "Train Epoch: 132 [110080/232365 (47%)]\tLoss: 161.474670\n",
            "Train Epoch: 132 [111360/232365 (48%)]\tLoss: 183.165009\n",
            "Train Epoch: 132 [112640/232365 (48%)]\tLoss: 163.893478\n",
            "Train Epoch: 132 [113920/232365 (49%)]\tLoss: 168.061188\n",
            "Train Epoch: 132 [115200/232365 (50%)]\tLoss: 172.749756\n",
            "Train Epoch: 132 [116480/232365 (50%)]\tLoss: 173.675629\n",
            "Train Epoch: 132 [117760/232365 (51%)]\tLoss: 177.246490\n",
            "Train Epoch: 132 [119040/232365 (51%)]\tLoss: 180.325714\n",
            "Train Epoch: 132 [120320/232365 (52%)]\tLoss: 171.661255\n",
            "Train Epoch: 132 [121600/232365 (52%)]\tLoss: 166.225830\n",
            "Train Epoch: 132 [122880/232365 (53%)]\tLoss: 174.848999\n",
            "Train Epoch: 132 [124160/232365 (53%)]\tLoss: 165.782806\n",
            "Train Epoch: 132 [125440/232365 (54%)]\tLoss: 174.256821\n",
            "Train Epoch: 132 [126720/232365 (55%)]\tLoss: 172.961731\n",
            "Train Epoch: 132 [128000/232365 (55%)]\tLoss: 168.996048\n",
            "Train Epoch: 132 [129280/232365 (56%)]\tLoss: 162.247894\n",
            "Train Epoch: 132 [130560/232365 (56%)]\tLoss: 179.563416\n",
            "Train Epoch: 132 [131840/232365 (57%)]\tLoss: 169.216476\n",
            "Train Epoch: 132 [133120/232365 (57%)]\tLoss: 167.265152\n",
            "Train Epoch: 132 [134400/232365 (58%)]\tLoss: 179.922089\n",
            "Train Epoch: 132 [135680/232365 (58%)]\tLoss: 171.010162\n",
            "Train Epoch: 132 [136960/232365 (59%)]\tLoss: 162.899506\n",
            "Train Epoch: 132 [138240/232365 (59%)]\tLoss: 171.240967\n",
            "Train Epoch: 132 [139520/232365 (60%)]\tLoss: 177.258881\n",
            "Train Epoch: 132 [140800/232365 (61%)]\tLoss: 173.493179\n",
            "Train Epoch: 132 [142080/232365 (61%)]\tLoss: 175.900604\n",
            "Train Epoch: 132 [143360/232365 (62%)]\tLoss: 177.297699\n",
            "Train Epoch: 132 [144640/232365 (62%)]\tLoss: 175.608704\n",
            "Train Epoch: 132 [145920/232365 (63%)]\tLoss: 169.828842\n",
            "Train Epoch: 132 [147200/232365 (63%)]\tLoss: 169.131226\n",
            "Train Epoch: 132 [148480/232365 (64%)]\tLoss: 176.016586\n",
            "Train Epoch: 132 [149760/232365 (64%)]\tLoss: 169.891907\n",
            "Train Epoch: 132 [151040/232365 (65%)]\tLoss: 180.265244\n",
            "Train Epoch: 132 [152320/232365 (66%)]\tLoss: 167.280487\n",
            "Train Epoch: 132 [153600/232365 (66%)]\tLoss: 177.489273\n",
            "Train Epoch: 132 [154880/232365 (67%)]\tLoss: 172.944168\n",
            "Train Epoch: 132 [156160/232365 (67%)]\tLoss: 175.551422\n",
            "Train Epoch: 132 [157440/232365 (68%)]\tLoss: 176.608871\n",
            "Train Epoch: 132 [158720/232365 (68%)]\tLoss: 172.237656\n",
            "Train Epoch: 132 [160000/232365 (69%)]\tLoss: 163.644699\n",
            "Train Epoch: 132 [161280/232365 (69%)]\tLoss: 174.705917\n",
            "Train Epoch: 132 [162560/232365 (70%)]\tLoss: 167.245331\n",
            "Train Epoch: 132 [163840/232365 (70%)]\tLoss: 176.414474\n",
            "Train Epoch: 132 [165120/232365 (71%)]\tLoss: 171.382492\n",
            "Train Epoch: 132 [166400/232365 (72%)]\tLoss: 164.386185\n",
            "Train Epoch: 132 [167680/232365 (72%)]\tLoss: 170.177032\n",
            "Train Epoch: 132 [168960/232365 (73%)]\tLoss: 167.674881\n",
            "Train Epoch: 132 [170240/232365 (73%)]\tLoss: 166.502518\n",
            "Train Epoch: 132 [171520/232365 (74%)]\tLoss: 163.163239\n",
            "Train Epoch: 132 [172800/232365 (74%)]\tLoss: 177.726303\n",
            "Train Epoch: 132 [174080/232365 (75%)]\tLoss: 169.056793\n",
            "Train Epoch: 132 [175360/232365 (75%)]\tLoss: 169.108856\n",
            "Train Epoch: 132 [176640/232365 (76%)]\tLoss: 169.399078\n",
            "Train Epoch: 132 [177920/232365 (77%)]\tLoss: 176.203568\n",
            "Train Epoch: 132 [179200/232365 (77%)]\tLoss: 162.164368\n",
            "Train Epoch: 132 [180480/232365 (78%)]\tLoss: 168.092316\n",
            "Train Epoch: 132 [181760/232365 (78%)]\tLoss: 182.325409\n",
            "Train Epoch: 132 [183040/232365 (79%)]\tLoss: 171.741089\n",
            "Train Epoch: 132 [184320/232365 (79%)]\tLoss: 167.495514\n",
            "Train Epoch: 132 [185600/232365 (80%)]\tLoss: 163.902481\n",
            "Train Epoch: 132 [186880/232365 (80%)]\tLoss: 173.998276\n",
            "Train Epoch: 132 [188160/232365 (81%)]\tLoss: 182.561630\n",
            "Train Epoch: 132 [189440/232365 (81%)]\tLoss: 170.539368\n",
            "Train Epoch: 132 [190720/232365 (82%)]\tLoss: 171.147644\n",
            "Train Epoch: 132 [192000/232365 (83%)]\tLoss: 170.782990\n",
            "Train Epoch: 132 [193280/232365 (83%)]\tLoss: 175.134109\n",
            "Train Epoch: 132 [194560/232365 (84%)]\tLoss: 179.700012\n",
            "Train Epoch: 132 [195840/232365 (84%)]\tLoss: 172.271347\n",
            "Train Epoch: 132 [197120/232365 (85%)]\tLoss: 172.109802\n",
            "Train Epoch: 132 [198400/232365 (85%)]\tLoss: 175.597137\n",
            "Train Epoch: 132 [199680/232365 (86%)]\tLoss: 169.952713\n",
            "Train Epoch: 132 [200960/232365 (86%)]\tLoss: 172.029877\n",
            "Train Epoch: 132 [202240/232365 (87%)]\tLoss: 173.006775\n",
            "Train Epoch: 132 [203520/232365 (88%)]\tLoss: 166.569656\n",
            "Train Epoch: 132 [204800/232365 (88%)]\tLoss: 169.575073\n",
            "Train Epoch: 132 [206080/232365 (89%)]\tLoss: 166.736023\n",
            "Train Epoch: 132 [207360/232365 (89%)]\tLoss: 161.221054\n",
            "Train Epoch: 132 [208640/232365 (90%)]\tLoss: 172.113785\n",
            "Train Epoch: 132 [209920/232365 (90%)]\tLoss: 176.566391\n",
            "Train Epoch: 132 [211200/232365 (91%)]\tLoss: 176.963257\n",
            "Train Epoch: 132 [212480/232365 (91%)]\tLoss: 182.413528\n",
            "Train Epoch: 132 [213760/232365 (92%)]\tLoss: 169.887390\n",
            "Train Epoch: 132 [215040/232365 (93%)]\tLoss: 170.786896\n",
            "Train Epoch: 132 [216320/232365 (93%)]\tLoss: 175.882904\n",
            "Train Epoch: 132 [217600/232365 (94%)]\tLoss: 183.001770\n",
            "Train Epoch: 132 [218880/232365 (94%)]\tLoss: 176.657486\n",
            "Train Epoch: 132 [220160/232365 (95%)]\tLoss: 177.891968\n",
            "Train Epoch: 132 [221440/232365 (95%)]\tLoss: 174.542404\n",
            "Train Epoch: 132 [222720/232365 (96%)]\tLoss: 174.549164\n",
            "Train Epoch: 132 [224000/232365 (96%)]\tLoss: 179.857605\n",
            "Train Epoch: 132 [225280/232365 (97%)]\tLoss: 173.391785\n",
            "Train Epoch: 132 [226560/232365 (97%)]\tLoss: 179.322784\n",
            "Train Epoch: 132 [227840/232365 (98%)]\tLoss: 167.657562\n",
            "Train Epoch: 132 [229120/232365 (99%)]\tLoss: 176.896729\n",
            "Train Epoch: 132 [230400/232365 (99%)]\tLoss: 169.541626\n",
            "Train Epoch: 132 [231680/232365 (100%)]\tLoss: 166.331879\n",
            "====> Epoch: 132 Average loss: 172.5344, Accuracy: 74.23%\n",
            "====> Test set loss: 183.3510, Accuracy: 74.11%\n",
            "Train Epoch: 133 [0/232365 (0%)]\tLoss: 170.017105\n",
            "Train Epoch: 133 [1280/232365 (1%)]\tLoss: 178.476227\n",
            "Train Epoch: 133 [2560/232365 (1%)]\tLoss: 179.812225\n",
            "Train Epoch: 133 [3840/232365 (2%)]\tLoss: 170.827911\n",
            "Train Epoch: 133 [5120/232365 (2%)]\tLoss: 164.688965\n",
            "Train Epoch: 133 [6400/232365 (3%)]\tLoss: 164.400635\n",
            "Train Epoch: 133 [7680/232365 (3%)]\tLoss: 165.046921\n",
            "Train Epoch: 133 [8960/232365 (4%)]\tLoss: 169.377655\n",
            "Train Epoch: 133 [10240/232365 (4%)]\tLoss: 177.844604\n",
            "Train Epoch: 133 [11520/232365 (5%)]\tLoss: 164.864670\n",
            "Train Epoch: 133 [12800/232365 (6%)]\tLoss: 170.696869\n",
            "Train Epoch: 133 [14080/232365 (6%)]\tLoss: 165.192368\n",
            "Train Epoch: 133 [15360/232365 (7%)]\tLoss: 164.331970\n",
            "Train Epoch: 133 [16640/232365 (7%)]\tLoss: 171.035492\n",
            "Train Epoch: 133 [17920/232365 (8%)]\tLoss: 175.341446\n",
            "Train Epoch: 133 [19200/232365 (8%)]\tLoss: 160.874954\n",
            "Train Epoch: 133 [20480/232365 (9%)]\tLoss: 176.779343\n",
            "Train Epoch: 133 [21760/232365 (9%)]\tLoss: 173.231064\n",
            "Train Epoch: 133 [23040/232365 (10%)]\tLoss: 174.316803\n",
            "Train Epoch: 133 [24320/232365 (10%)]\tLoss: 168.427521\n",
            "Train Epoch: 133 [25600/232365 (11%)]\tLoss: 178.190491\n",
            "Train Epoch: 133 [26880/232365 (12%)]\tLoss: 165.507462\n",
            "Train Epoch: 133 [28160/232365 (12%)]\tLoss: 167.521271\n",
            "Train Epoch: 133 [29440/232365 (13%)]\tLoss: 174.180115\n",
            "Train Epoch: 133 [30720/232365 (13%)]\tLoss: 168.512024\n",
            "Train Epoch: 133 [32000/232365 (14%)]\tLoss: 166.114868\n",
            "Train Epoch: 133 [33280/232365 (14%)]\tLoss: 180.828094\n",
            "Train Epoch: 133 [34560/232365 (15%)]\tLoss: 169.686523\n",
            "Train Epoch: 133 [35840/232365 (15%)]\tLoss: 173.997681\n",
            "Train Epoch: 133 [37120/232365 (16%)]\tLoss: 174.295837\n",
            "Train Epoch: 133 [38400/232365 (17%)]\tLoss: 164.205750\n",
            "Train Epoch: 133 [39680/232365 (17%)]\tLoss: 163.077225\n",
            "Train Epoch: 133 [40960/232365 (18%)]\tLoss: 170.738190\n",
            "Train Epoch: 133 [42240/232365 (18%)]\tLoss: 169.831741\n",
            "Train Epoch: 133 [43520/232365 (19%)]\tLoss: 169.055756\n",
            "Train Epoch: 133 [44800/232365 (19%)]\tLoss: 167.245316\n",
            "Train Epoch: 133 [46080/232365 (20%)]\tLoss: 173.388062\n",
            "Train Epoch: 133 [47360/232365 (20%)]\tLoss: 169.739258\n",
            "Train Epoch: 133 [48640/232365 (21%)]\tLoss: 169.413818\n",
            "Train Epoch: 133 [49920/232365 (21%)]\tLoss: 176.851410\n",
            "Train Epoch: 133 [51200/232365 (22%)]\tLoss: 176.615952\n",
            "Train Epoch: 133 [52480/232365 (23%)]\tLoss: 168.089706\n",
            "Train Epoch: 133 [53760/232365 (23%)]\tLoss: 171.287857\n",
            "Train Epoch: 133 [55040/232365 (24%)]\tLoss: 169.189392\n",
            "Train Epoch: 133 [56320/232365 (24%)]\tLoss: 171.672791\n",
            "Train Epoch: 133 [57600/232365 (25%)]\tLoss: 172.774002\n",
            "Train Epoch: 133 [58880/232365 (25%)]\tLoss: 175.583984\n",
            "Train Epoch: 133 [60160/232365 (26%)]\tLoss: 170.327850\n",
            "Train Epoch: 133 [61440/232365 (26%)]\tLoss: 166.455124\n",
            "Train Epoch: 133 [62720/232365 (27%)]\tLoss: 171.263397\n",
            "Train Epoch: 133 [64000/232365 (28%)]\tLoss: 164.109711\n",
            "Train Epoch: 133 [65280/232365 (28%)]\tLoss: 158.139221\n",
            "Train Epoch: 133 [66560/232365 (29%)]\tLoss: 172.224365\n",
            "Train Epoch: 133 [67840/232365 (29%)]\tLoss: 185.958969\n",
            "Train Epoch: 133 [69120/232365 (30%)]\tLoss: 174.156067\n",
            "Train Epoch: 133 [70400/232365 (30%)]\tLoss: 173.354279\n",
            "Train Epoch: 133 [71680/232365 (31%)]\tLoss: 169.782196\n",
            "Train Epoch: 133 [72960/232365 (31%)]\tLoss: 171.181610\n",
            "Train Epoch: 133 [74240/232365 (32%)]\tLoss: 170.329834\n",
            "Train Epoch: 133 [75520/232365 (32%)]\tLoss: 173.917297\n",
            "Train Epoch: 133 [76800/232365 (33%)]\tLoss: 183.455811\n",
            "Train Epoch: 133 [78080/232365 (34%)]\tLoss: 170.785309\n",
            "Train Epoch: 133 [79360/232365 (34%)]\tLoss: 166.172165\n",
            "Train Epoch: 133 [80640/232365 (35%)]\tLoss: 175.044785\n",
            "Train Epoch: 133 [81920/232365 (35%)]\tLoss: 172.977798\n",
            "Train Epoch: 133 [83200/232365 (36%)]\tLoss: 178.872818\n",
            "Train Epoch: 133 [84480/232365 (36%)]\tLoss: 178.315689\n",
            "Train Epoch: 133 [85760/232365 (37%)]\tLoss: 174.631836\n",
            "Train Epoch: 133 [87040/232365 (37%)]\tLoss: 168.148026\n",
            "Train Epoch: 133 [88320/232365 (38%)]\tLoss: 173.761703\n",
            "Train Epoch: 133 [89600/232365 (39%)]\tLoss: 163.691666\n",
            "Train Epoch: 133 [90880/232365 (39%)]\tLoss: 167.952393\n",
            "Train Epoch: 133 [92160/232365 (40%)]\tLoss: 191.655228\n",
            "Train Epoch: 133 [93440/232365 (40%)]\tLoss: 171.776398\n",
            "Train Epoch: 133 [94720/232365 (41%)]\tLoss: 175.343781\n",
            "Train Epoch: 133 [96000/232365 (41%)]\tLoss: 173.117081\n",
            "Train Epoch: 133 [97280/232365 (42%)]\tLoss: 180.738037\n",
            "Train Epoch: 133 [98560/232365 (42%)]\tLoss: 162.372498\n",
            "Train Epoch: 133 [99840/232365 (43%)]\tLoss: 158.259033\n",
            "Train Epoch: 133 [101120/232365 (44%)]\tLoss: 177.092743\n",
            "Train Epoch: 133 [102400/232365 (44%)]\tLoss: 180.787903\n",
            "Train Epoch: 133 [103680/232365 (45%)]\tLoss: 176.765778\n",
            "Train Epoch: 133 [104960/232365 (45%)]\tLoss: 167.860840\n",
            "Train Epoch: 133 [106240/232365 (46%)]\tLoss: 169.225677\n",
            "Train Epoch: 133 [107520/232365 (46%)]\tLoss: 171.439529\n",
            "Train Epoch: 133 [108800/232365 (47%)]\tLoss: 174.486542\n",
            "Train Epoch: 133 [110080/232365 (47%)]\tLoss: 181.342941\n",
            "Train Epoch: 133 [111360/232365 (48%)]\tLoss: 171.663055\n",
            "Train Epoch: 133 [112640/232365 (48%)]\tLoss: 177.347397\n",
            "Train Epoch: 133 [113920/232365 (49%)]\tLoss: 165.977234\n",
            "Train Epoch: 133 [115200/232365 (50%)]\tLoss: 173.024338\n",
            "Train Epoch: 133 [116480/232365 (50%)]\tLoss: 167.808853\n",
            "Train Epoch: 133 [117760/232365 (51%)]\tLoss: 179.718628\n",
            "Train Epoch: 133 [119040/232365 (51%)]\tLoss: 174.113007\n",
            "Train Epoch: 133 [120320/232365 (52%)]\tLoss: 164.524872\n",
            "Train Epoch: 133 [121600/232365 (52%)]\tLoss: 165.495300\n",
            "Train Epoch: 133 [122880/232365 (53%)]\tLoss: 170.257416\n",
            "Train Epoch: 133 [124160/232365 (53%)]\tLoss: 175.786301\n",
            "Train Epoch: 133 [125440/232365 (54%)]\tLoss: 159.852905\n",
            "Train Epoch: 133 [126720/232365 (55%)]\tLoss: 164.218155\n",
            "Train Epoch: 133 [128000/232365 (55%)]\tLoss: 180.375183\n",
            "Train Epoch: 133 [129280/232365 (56%)]\tLoss: 172.573105\n",
            "Train Epoch: 133 [130560/232365 (56%)]\tLoss: 178.077042\n",
            "Train Epoch: 133 [131840/232365 (57%)]\tLoss: 168.364899\n",
            "Train Epoch: 133 [133120/232365 (57%)]\tLoss: 167.192490\n",
            "Train Epoch: 133 [134400/232365 (58%)]\tLoss: 173.190689\n",
            "Train Epoch: 133 [135680/232365 (58%)]\tLoss: 172.252930\n",
            "Train Epoch: 133 [136960/232365 (59%)]\tLoss: 163.675217\n",
            "Train Epoch: 133 [138240/232365 (59%)]\tLoss: 166.179367\n",
            "Train Epoch: 133 [139520/232365 (60%)]\tLoss: 168.022873\n",
            "Train Epoch: 133 [140800/232365 (61%)]\tLoss: 171.730942\n",
            "Train Epoch: 133 [142080/232365 (61%)]\tLoss: 170.675140\n",
            "Train Epoch: 133 [143360/232365 (62%)]\tLoss: 169.766998\n",
            "Train Epoch: 133 [144640/232365 (62%)]\tLoss: 172.452637\n",
            "Train Epoch: 133 [145920/232365 (63%)]\tLoss: 179.464340\n",
            "Train Epoch: 133 [147200/232365 (63%)]\tLoss: 168.685165\n",
            "Train Epoch: 133 [148480/232365 (64%)]\tLoss: 163.447800\n",
            "Train Epoch: 133 [149760/232365 (64%)]\tLoss: 174.697571\n",
            "Train Epoch: 133 [151040/232365 (65%)]\tLoss: 171.261810\n",
            "Train Epoch: 133 [152320/232365 (66%)]\tLoss: 170.808105\n",
            "Train Epoch: 133 [153600/232365 (66%)]\tLoss: 171.479813\n",
            "Train Epoch: 133 [154880/232365 (67%)]\tLoss: 163.988647\n",
            "Train Epoch: 133 [156160/232365 (67%)]\tLoss: 167.881058\n",
            "Train Epoch: 133 [157440/232365 (68%)]\tLoss: 172.928711\n",
            "Train Epoch: 133 [158720/232365 (68%)]\tLoss: 164.689636\n",
            "Train Epoch: 133 [160000/232365 (69%)]\tLoss: 175.395050\n",
            "Train Epoch: 133 [161280/232365 (69%)]\tLoss: 171.094055\n",
            "Train Epoch: 133 [162560/232365 (70%)]\tLoss: 171.929993\n",
            "Train Epoch: 133 [163840/232365 (70%)]\tLoss: 167.880524\n",
            "Train Epoch: 133 [165120/232365 (71%)]\tLoss: 171.066803\n",
            "Train Epoch: 133 [166400/232365 (72%)]\tLoss: 175.822266\n",
            "Train Epoch: 133 [167680/232365 (72%)]\tLoss: 172.261826\n",
            "Train Epoch: 133 [168960/232365 (73%)]\tLoss: 166.415329\n",
            "Train Epoch: 133 [170240/232365 (73%)]\tLoss: 177.622787\n",
            "Train Epoch: 133 [171520/232365 (74%)]\tLoss: 180.701935\n",
            "Train Epoch: 133 [172800/232365 (74%)]\tLoss: 177.069885\n",
            "Train Epoch: 133 [174080/232365 (75%)]\tLoss: 176.614120\n",
            "Train Epoch: 133 [175360/232365 (75%)]\tLoss: 167.700592\n",
            "Train Epoch: 133 [176640/232365 (76%)]\tLoss: 171.022812\n",
            "Train Epoch: 133 [177920/232365 (77%)]\tLoss: 166.698166\n",
            "Train Epoch: 133 [179200/232365 (77%)]\tLoss: 180.509460\n",
            "Train Epoch: 133 [180480/232365 (78%)]\tLoss: 163.649445\n",
            "Train Epoch: 133 [181760/232365 (78%)]\tLoss: 170.427826\n",
            "Train Epoch: 133 [183040/232365 (79%)]\tLoss: 169.665298\n",
            "Train Epoch: 133 [184320/232365 (79%)]\tLoss: 173.467834\n",
            "Train Epoch: 133 [185600/232365 (80%)]\tLoss: 175.057129\n",
            "Train Epoch: 133 [186880/232365 (80%)]\tLoss: 171.110458\n",
            "Train Epoch: 133 [188160/232365 (81%)]\tLoss: 180.253571\n",
            "Train Epoch: 133 [189440/232365 (81%)]\tLoss: 168.682449\n",
            "Train Epoch: 133 [190720/232365 (82%)]\tLoss: 169.425568\n",
            "Train Epoch: 133 [192000/232365 (83%)]\tLoss: 169.978653\n",
            "Train Epoch: 133 [193280/232365 (83%)]\tLoss: 168.742981\n",
            "Train Epoch: 133 [194560/232365 (84%)]\tLoss: 165.121674\n",
            "Train Epoch: 133 [195840/232365 (84%)]\tLoss: 168.034775\n",
            "Train Epoch: 133 [197120/232365 (85%)]\tLoss: 175.111038\n",
            "Train Epoch: 133 [198400/232365 (85%)]\tLoss: 179.156662\n",
            "Train Epoch: 133 [199680/232365 (86%)]\tLoss: 162.739288\n",
            "Train Epoch: 133 [200960/232365 (86%)]\tLoss: 176.121399\n",
            "Train Epoch: 133 [202240/232365 (87%)]\tLoss: 170.507324\n",
            "Train Epoch: 133 [203520/232365 (88%)]\tLoss: 173.509125\n",
            "Train Epoch: 133 [204800/232365 (88%)]\tLoss: 163.919632\n",
            "Train Epoch: 133 [206080/232365 (89%)]\tLoss: 161.196014\n",
            "Train Epoch: 133 [207360/232365 (89%)]\tLoss: 171.725586\n",
            "Train Epoch: 133 [208640/232365 (90%)]\tLoss: 180.970139\n",
            "Train Epoch: 133 [209920/232365 (90%)]\tLoss: 172.230667\n",
            "Train Epoch: 133 [211200/232365 (91%)]\tLoss: 173.385269\n",
            "Train Epoch: 133 [212480/232365 (91%)]\tLoss: 172.577362\n",
            "Train Epoch: 133 [213760/232365 (92%)]\tLoss: 169.237427\n",
            "Train Epoch: 133 [215040/232365 (93%)]\tLoss: 175.786850\n",
            "Train Epoch: 133 [216320/232365 (93%)]\tLoss: 183.884460\n",
            "Train Epoch: 133 [217600/232365 (94%)]\tLoss: 168.622467\n",
            "Train Epoch: 133 [218880/232365 (94%)]\tLoss: 178.442673\n",
            "Train Epoch: 133 [220160/232365 (95%)]\tLoss: 168.190521\n",
            "Train Epoch: 133 [221440/232365 (95%)]\tLoss: 173.250595\n",
            "Train Epoch: 133 [222720/232365 (96%)]\tLoss: 184.918564\n",
            "Train Epoch: 133 [224000/232365 (96%)]\tLoss: 167.443588\n",
            "Train Epoch: 133 [225280/232365 (97%)]\tLoss: 176.568237\n",
            "Train Epoch: 133 [226560/232365 (97%)]\tLoss: 179.665787\n",
            "Train Epoch: 133 [227840/232365 (98%)]\tLoss: 169.653992\n",
            "Train Epoch: 133 [229120/232365 (99%)]\tLoss: 168.886566\n",
            "Train Epoch: 133 [230400/232365 (99%)]\tLoss: 170.141479\n",
            "Train Epoch: 133 [231680/232365 (100%)]\tLoss: 174.843048\n",
            "====> Epoch: 133 Average loss: 172.5435, Accuracy: 74.23%\n",
            "====> Test set loss: 183.3710, Accuracy: 74.12%\n",
            "Train Epoch: 134 [0/232365 (0%)]\tLoss: 158.710770\n",
            "Train Epoch: 134 [1280/232365 (1%)]\tLoss: 168.916229\n",
            "Train Epoch: 134 [2560/232365 (1%)]\tLoss: 174.699493\n",
            "Train Epoch: 134 [3840/232365 (2%)]\tLoss: 173.646378\n",
            "Train Epoch: 134 [5120/232365 (2%)]\tLoss: 168.236694\n",
            "Train Epoch: 134 [6400/232365 (3%)]\tLoss: 177.939636\n",
            "Train Epoch: 134 [7680/232365 (3%)]\tLoss: 172.266495\n",
            "Train Epoch: 134 [8960/232365 (4%)]\tLoss: 164.380035\n",
            "Train Epoch: 134 [10240/232365 (4%)]\tLoss: 175.366287\n",
            "Train Epoch: 134 [11520/232365 (5%)]\tLoss: 172.699310\n",
            "Train Epoch: 134 [12800/232365 (6%)]\tLoss: 175.970459\n",
            "Train Epoch: 134 [14080/232365 (6%)]\tLoss: 167.484283\n",
            "Train Epoch: 134 [15360/232365 (7%)]\tLoss: 174.394943\n",
            "Train Epoch: 134 [16640/232365 (7%)]\tLoss: 162.848251\n",
            "Train Epoch: 134 [17920/232365 (8%)]\tLoss: 174.051300\n",
            "Train Epoch: 134 [19200/232365 (8%)]\tLoss: 172.436813\n",
            "Train Epoch: 134 [20480/232365 (9%)]\tLoss: 172.756897\n",
            "Train Epoch: 134 [21760/232365 (9%)]\tLoss: 180.606522\n",
            "Train Epoch: 134 [23040/232365 (10%)]\tLoss: 181.293243\n",
            "Train Epoch: 134 [24320/232365 (10%)]\tLoss: 173.042511\n",
            "Train Epoch: 134 [25600/232365 (11%)]\tLoss: 175.698776\n",
            "Train Epoch: 134 [26880/232365 (12%)]\tLoss: 172.453827\n",
            "Train Epoch: 134 [28160/232365 (12%)]\tLoss: 170.910507\n",
            "Train Epoch: 134 [29440/232365 (13%)]\tLoss: 167.968475\n",
            "Train Epoch: 134 [30720/232365 (13%)]\tLoss: 167.099319\n",
            "Train Epoch: 134 [32000/232365 (14%)]\tLoss: 172.123199\n",
            "Train Epoch: 134 [33280/232365 (14%)]\tLoss: 166.436478\n",
            "Train Epoch: 134 [34560/232365 (15%)]\tLoss: 185.712692\n",
            "Train Epoch: 134 [35840/232365 (15%)]\tLoss: 159.066605\n",
            "Train Epoch: 134 [37120/232365 (16%)]\tLoss: 167.912399\n",
            "Train Epoch: 134 [38400/232365 (17%)]\tLoss: 170.679474\n",
            "Train Epoch: 134 [39680/232365 (17%)]\tLoss: 164.790436\n",
            "Train Epoch: 134 [40960/232365 (18%)]\tLoss: 171.993790\n",
            "Train Epoch: 134 [42240/232365 (18%)]\tLoss: 157.004791\n",
            "Train Epoch: 134 [43520/232365 (19%)]\tLoss: 169.357697\n",
            "Train Epoch: 134 [44800/232365 (19%)]\tLoss: 172.942093\n",
            "Train Epoch: 134 [46080/232365 (20%)]\tLoss: 179.716263\n",
            "Train Epoch: 134 [47360/232365 (20%)]\tLoss: 171.954498\n",
            "Train Epoch: 134 [48640/232365 (21%)]\tLoss: 181.927490\n",
            "Train Epoch: 134 [49920/232365 (21%)]\tLoss: 181.646820\n",
            "Train Epoch: 134 [51200/232365 (22%)]\tLoss: 171.745987\n",
            "Train Epoch: 134 [52480/232365 (23%)]\tLoss: 172.419769\n",
            "Train Epoch: 134 [53760/232365 (23%)]\tLoss: 176.112396\n",
            "Train Epoch: 134 [55040/232365 (24%)]\tLoss: 174.296631\n",
            "Train Epoch: 134 [56320/232365 (24%)]\tLoss: 173.218658\n",
            "Train Epoch: 134 [57600/232365 (25%)]\tLoss: 174.237823\n",
            "Train Epoch: 134 [58880/232365 (25%)]\tLoss: 169.626678\n",
            "Train Epoch: 134 [60160/232365 (26%)]\tLoss: 172.125397\n",
            "Train Epoch: 134 [61440/232365 (26%)]\tLoss: 177.101425\n",
            "Train Epoch: 134 [62720/232365 (27%)]\tLoss: 165.910431\n",
            "Train Epoch: 134 [64000/232365 (28%)]\tLoss: 177.973328\n",
            "Train Epoch: 134 [65280/232365 (28%)]\tLoss: 177.638702\n",
            "Train Epoch: 134 [66560/232365 (29%)]\tLoss: 172.444275\n",
            "Train Epoch: 134 [67840/232365 (29%)]\tLoss: 161.309067\n",
            "Train Epoch: 134 [69120/232365 (30%)]\tLoss: 166.281494\n",
            "Train Epoch: 134 [70400/232365 (30%)]\tLoss: 171.954132\n",
            "Train Epoch: 134 [71680/232365 (31%)]\tLoss: 189.389633\n",
            "Train Epoch: 134 [72960/232365 (31%)]\tLoss: 169.343781\n",
            "Train Epoch: 134 [74240/232365 (32%)]\tLoss: 175.895386\n",
            "Train Epoch: 134 [75520/232365 (32%)]\tLoss: 173.356720\n",
            "Train Epoch: 134 [76800/232365 (33%)]\tLoss: 169.470367\n",
            "Train Epoch: 134 [78080/232365 (34%)]\tLoss: 183.658066\n",
            "Train Epoch: 134 [79360/232365 (34%)]\tLoss: 174.672455\n",
            "Train Epoch: 134 [80640/232365 (35%)]\tLoss: 178.408783\n",
            "Train Epoch: 134 [81920/232365 (35%)]\tLoss: 161.892380\n",
            "Train Epoch: 134 [83200/232365 (36%)]\tLoss: 169.602554\n",
            "Train Epoch: 134 [84480/232365 (36%)]\tLoss: 172.101517\n",
            "Train Epoch: 134 [85760/232365 (37%)]\tLoss: 179.150757\n",
            "Train Epoch: 134 [87040/232365 (37%)]\tLoss: 175.939621\n",
            "Train Epoch: 134 [88320/232365 (38%)]\tLoss: 177.843369\n",
            "Train Epoch: 134 [89600/232365 (39%)]\tLoss: 165.485611\n",
            "Train Epoch: 134 [90880/232365 (39%)]\tLoss: 171.408066\n",
            "Train Epoch: 134 [92160/232365 (40%)]\tLoss: 171.046570\n",
            "Train Epoch: 134 [93440/232365 (40%)]\tLoss: 171.408264\n",
            "Train Epoch: 134 [94720/232365 (41%)]\tLoss: 171.130554\n",
            "Train Epoch: 134 [96000/232365 (41%)]\tLoss: 173.594727\n",
            "Train Epoch: 134 [97280/232365 (42%)]\tLoss: 173.393387\n",
            "Train Epoch: 134 [98560/232365 (42%)]\tLoss: 175.063736\n",
            "Train Epoch: 134 [99840/232365 (43%)]\tLoss: 171.233566\n",
            "Train Epoch: 134 [101120/232365 (44%)]\tLoss: 176.189941\n",
            "Train Epoch: 134 [102400/232365 (44%)]\tLoss: 176.152267\n",
            "Train Epoch: 134 [103680/232365 (45%)]\tLoss: 167.677475\n",
            "Train Epoch: 134 [104960/232365 (45%)]\tLoss: 177.143250\n",
            "Train Epoch: 134 [106240/232365 (46%)]\tLoss: 177.467545\n",
            "Train Epoch: 134 [107520/232365 (46%)]\tLoss: 169.948517\n",
            "Train Epoch: 134 [108800/232365 (47%)]\tLoss: 161.575485\n",
            "Train Epoch: 134 [110080/232365 (47%)]\tLoss: 164.264969\n",
            "Train Epoch: 134 [111360/232365 (48%)]\tLoss: 173.586548\n",
            "Train Epoch: 134 [112640/232365 (48%)]\tLoss: 174.409729\n",
            "Train Epoch: 134 [113920/232365 (49%)]\tLoss: 177.765976\n",
            "Train Epoch: 134 [115200/232365 (50%)]\tLoss: 178.844208\n",
            "Train Epoch: 134 [116480/232365 (50%)]\tLoss: 164.134705\n",
            "Train Epoch: 134 [117760/232365 (51%)]\tLoss: 171.983307\n",
            "Train Epoch: 134 [119040/232365 (51%)]\tLoss: 171.150330\n",
            "Train Epoch: 134 [120320/232365 (52%)]\tLoss: 181.030319\n",
            "Train Epoch: 134 [121600/232365 (52%)]\tLoss: 175.502777\n",
            "Train Epoch: 134 [122880/232365 (53%)]\tLoss: 171.310944\n",
            "Train Epoch: 134 [124160/232365 (53%)]\tLoss: 172.691177\n",
            "Train Epoch: 134 [125440/232365 (54%)]\tLoss: 175.607941\n",
            "Train Epoch: 134 [126720/232365 (55%)]\tLoss: 179.778595\n",
            "Train Epoch: 134 [128000/232365 (55%)]\tLoss: 183.806900\n",
            "Train Epoch: 134 [129280/232365 (56%)]\tLoss: 173.949432\n",
            "Train Epoch: 134 [130560/232365 (56%)]\tLoss: 164.281128\n",
            "Train Epoch: 134 [131840/232365 (57%)]\tLoss: 169.207794\n",
            "Train Epoch: 134 [133120/232365 (57%)]\tLoss: 163.311981\n",
            "Train Epoch: 134 [134400/232365 (58%)]\tLoss: 176.868759\n",
            "Train Epoch: 134 [135680/232365 (58%)]\tLoss: 172.457901\n",
            "Train Epoch: 134 [136960/232365 (59%)]\tLoss: 176.803696\n",
            "Train Epoch: 134 [138240/232365 (59%)]\tLoss: 166.941620\n",
            "Train Epoch: 134 [139520/232365 (60%)]\tLoss: 167.480530\n",
            "Train Epoch: 134 [140800/232365 (61%)]\tLoss: 185.098846\n",
            "Train Epoch: 134 [142080/232365 (61%)]\tLoss: 181.614166\n",
            "Train Epoch: 134 [143360/232365 (62%)]\tLoss: 163.146790\n",
            "Train Epoch: 134 [144640/232365 (62%)]\tLoss: 170.542130\n",
            "Train Epoch: 134 [145920/232365 (63%)]\tLoss: 169.201660\n",
            "Train Epoch: 134 [147200/232365 (63%)]\tLoss: 175.948227\n",
            "Train Epoch: 134 [148480/232365 (64%)]\tLoss: 181.474396\n",
            "Train Epoch: 134 [149760/232365 (64%)]\tLoss: 162.526337\n",
            "Train Epoch: 134 [151040/232365 (65%)]\tLoss: 174.171051\n",
            "Train Epoch: 134 [152320/232365 (66%)]\tLoss: 166.363297\n",
            "Train Epoch: 134 [153600/232365 (66%)]\tLoss: 181.961884\n",
            "Train Epoch: 134 [154880/232365 (67%)]\tLoss: 175.377640\n",
            "Train Epoch: 134 [156160/232365 (67%)]\tLoss: 170.497437\n",
            "Train Epoch: 134 [157440/232365 (68%)]\tLoss: 174.244522\n",
            "Train Epoch: 134 [158720/232365 (68%)]\tLoss: 167.090973\n",
            "Train Epoch: 134 [160000/232365 (69%)]\tLoss: 176.706055\n",
            "Train Epoch: 134 [161280/232365 (69%)]\tLoss: 178.551971\n",
            "Train Epoch: 134 [162560/232365 (70%)]\tLoss: 161.450775\n",
            "Train Epoch: 134 [163840/232365 (70%)]\tLoss: 182.282745\n",
            "Train Epoch: 134 [165120/232365 (71%)]\tLoss: 163.361557\n",
            "Train Epoch: 134 [166400/232365 (72%)]\tLoss: 171.171402\n",
            "Train Epoch: 134 [167680/232365 (72%)]\tLoss: 175.510071\n",
            "Train Epoch: 134 [168960/232365 (73%)]\tLoss: 166.325195\n",
            "Train Epoch: 134 [170240/232365 (73%)]\tLoss: 171.203583\n",
            "Train Epoch: 134 [171520/232365 (74%)]\tLoss: 170.246506\n",
            "Train Epoch: 134 [172800/232365 (74%)]\tLoss: 179.449707\n",
            "Train Epoch: 134 [174080/232365 (75%)]\tLoss: 171.808243\n",
            "Train Epoch: 134 [175360/232365 (75%)]\tLoss: 170.197632\n",
            "Train Epoch: 134 [176640/232365 (76%)]\tLoss: 180.226089\n",
            "Train Epoch: 134 [177920/232365 (77%)]\tLoss: 176.888184\n",
            "Train Epoch: 134 [179200/232365 (77%)]\tLoss: 173.804001\n",
            "Train Epoch: 134 [180480/232365 (78%)]\tLoss: 168.973267\n",
            "Train Epoch: 134 [181760/232365 (78%)]\tLoss: 167.356781\n",
            "Train Epoch: 134 [183040/232365 (79%)]\tLoss: 170.047745\n",
            "Train Epoch: 134 [184320/232365 (79%)]\tLoss: 178.235962\n",
            "Train Epoch: 134 [185600/232365 (80%)]\tLoss: 176.503296\n",
            "Train Epoch: 134 [186880/232365 (80%)]\tLoss: 163.472931\n",
            "Train Epoch: 134 [188160/232365 (81%)]\tLoss: 175.052078\n",
            "Train Epoch: 134 [189440/232365 (81%)]\tLoss: 166.915131\n",
            "Train Epoch: 134 [190720/232365 (82%)]\tLoss: 177.863495\n",
            "Train Epoch: 134 [192000/232365 (83%)]\tLoss: 171.413696\n",
            "Train Epoch: 134 [193280/232365 (83%)]\tLoss: 181.886673\n",
            "Train Epoch: 134 [194560/232365 (84%)]\tLoss: 164.962234\n",
            "Train Epoch: 134 [195840/232365 (84%)]\tLoss: 160.478378\n",
            "Train Epoch: 134 [197120/232365 (85%)]\tLoss: 161.416901\n",
            "Train Epoch: 134 [198400/232365 (85%)]\tLoss: 173.479706\n",
            "Train Epoch: 134 [199680/232365 (86%)]\tLoss: 177.681763\n",
            "Train Epoch: 134 [200960/232365 (86%)]\tLoss: 178.540924\n",
            "Train Epoch: 134 [202240/232365 (87%)]\tLoss: 174.622498\n",
            "Train Epoch: 134 [203520/232365 (88%)]\tLoss: 176.342239\n",
            "Train Epoch: 134 [204800/232365 (88%)]\tLoss: 174.111023\n",
            "Train Epoch: 134 [206080/232365 (89%)]\tLoss: 182.756638\n",
            "Train Epoch: 134 [207360/232365 (89%)]\tLoss: 170.366135\n",
            "Train Epoch: 134 [208640/232365 (90%)]\tLoss: 167.345795\n",
            "Train Epoch: 134 [209920/232365 (90%)]\tLoss: 168.692612\n",
            "Train Epoch: 134 [211200/232365 (91%)]\tLoss: 177.398819\n",
            "Train Epoch: 134 [212480/232365 (91%)]\tLoss: 176.499664\n",
            "Train Epoch: 134 [213760/232365 (92%)]\tLoss: 176.760468\n",
            "Train Epoch: 134 [215040/232365 (93%)]\tLoss: 171.918793\n",
            "Train Epoch: 134 [216320/232365 (93%)]\tLoss: 170.946426\n",
            "Train Epoch: 134 [217600/232365 (94%)]\tLoss: 166.756989\n",
            "Train Epoch: 134 [218880/232365 (94%)]\tLoss: 169.526413\n",
            "Train Epoch: 134 [220160/232365 (95%)]\tLoss: 168.008957\n",
            "Train Epoch: 134 [221440/232365 (95%)]\tLoss: 169.766510\n",
            "Train Epoch: 134 [222720/232365 (96%)]\tLoss: 178.640503\n",
            "Train Epoch: 134 [224000/232365 (96%)]\tLoss: 175.920319\n",
            "Train Epoch: 134 [225280/232365 (97%)]\tLoss: 169.728333\n",
            "Train Epoch: 134 [226560/232365 (97%)]\tLoss: 164.235260\n",
            "Train Epoch: 134 [227840/232365 (98%)]\tLoss: 168.544403\n",
            "Train Epoch: 134 [229120/232365 (99%)]\tLoss: 170.060501\n",
            "Train Epoch: 134 [230400/232365 (99%)]\tLoss: 173.853119\n",
            "Train Epoch: 134 [231680/232365 (100%)]\tLoss: 169.705627\n",
            "====> Epoch: 134 Average loss: 172.5302, Accuracy: 74.23%\n",
            "====> Test set loss: 183.1649, Accuracy: 74.12%\n",
            "Train Epoch: 135 [0/232365 (0%)]\tLoss: 173.908218\n",
            "Train Epoch: 135 [1280/232365 (1%)]\tLoss: 172.063095\n",
            "Train Epoch: 135 [2560/232365 (1%)]\tLoss: 174.386353\n",
            "Train Epoch: 135 [3840/232365 (2%)]\tLoss: 166.716293\n",
            "Train Epoch: 135 [5120/232365 (2%)]\tLoss: 178.661148\n",
            "Train Epoch: 135 [6400/232365 (3%)]\tLoss: 171.930695\n",
            "Train Epoch: 135 [7680/232365 (3%)]\tLoss: 181.107590\n",
            "Train Epoch: 135 [8960/232365 (4%)]\tLoss: 170.775177\n",
            "Train Epoch: 135 [10240/232365 (4%)]\tLoss: 180.282196\n",
            "Train Epoch: 135 [11520/232365 (5%)]\tLoss: 181.733948\n",
            "Train Epoch: 135 [12800/232365 (6%)]\tLoss: 181.858185\n",
            "Train Epoch: 135 [14080/232365 (6%)]\tLoss: 176.873932\n",
            "Train Epoch: 135 [15360/232365 (7%)]\tLoss: 170.437988\n",
            "Train Epoch: 135 [16640/232365 (7%)]\tLoss: 172.400513\n",
            "Train Epoch: 135 [17920/232365 (8%)]\tLoss: 178.402298\n",
            "Train Epoch: 135 [19200/232365 (8%)]\tLoss: 181.852356\n",
            "Train Epoch: 135 [20480/232365 (9%)]\tLoss: 175.504745\n",
            "Train Epoch: 135 [21760/232365 (9%)]\tLoss: 165.963425\n",
            "Train Epoch: 135 [23040/232365 (10%)]\tLoss: 171.930847\n",
            "Train Epoch: 135 [24320/232365 (10%)]\tLoss: 169.074097\n",
            "Train Epoch: 135 [25600/232365 (11%)]\tLoss: 170.475601\n",
            "Train Epoch: 135 [26880/232365 (12%)]\tLoss: 180.804565\n",
            "Train Epoch: 135 [28160/232365 (12%)]\tLoss: 167.776031\n",
            "Train Epoch: 135 [29440/232365 (13%)]\tLoss: 171.898407\n",
            "Train Epoch: 135 [30720/232365 (13%)]\tLoss: 176.048370\n",
            "Train Epoch: 135 [32000/232365 (14%)]\tLoss: 177.522537\n",
            "Train Epoch: 135 [33280/232365 (14%)]\tLoss: 167.877136\n",
            "Train Epoch: 135 [34560/232365 (15%)]\tLoss: 174.922012\n",
            "Train Epoch: 135 [35840/232365 (15%)]\tLoss: 176.839783\n",
            "Train Epoch: 135 [37120/232365 (16%)]\tLoss: 182.120972\n",
            "Train Epoch: 135 [38400/232365 (17%)]\tLoss: 169.500916\n",
            "Train Epoch: 135 [39680/232365 (17%)]\tLoss: 165.403625\n",
            "Train Epoch: 135 [40960/232365 (18%)]\tLoss: 165.598602\n",
            "Train Epoch: 135 [42240/232365 (18%)]\tLoss: 175.797119\n",
            "Train Epoch: 135 [43520/232365 (19%)]\tLoss: 164.599854\n",
            "Train Epoch: 135 [44800/232365 (19%)]\tLoss: 177.185104\n",
            "Train Epoch: 135 [46080/232365 (20%)]\tLoss: 174.406555\n",
            "Train Epoch: 135 [47360/232365 (20%)]\tLoss: 167.921097\n",
            "Train Epoch: 135 [48640/232365 (21%)]\tLoss: 170.671478\n",
            "Train Epoch: 135 [49920/232365 (21%)]\tLoss: 176.138397\n",
            "Train Epoch: 135 [51200/232365 (22%)]\tLoss: 164.357178\n",
            "Train Epoch: 135 [52480/232365 (23%)]\tLoss: 178.337463\n",
            "Train Epoch: 135 [53760/232365 (23%)]\tLoss: 174.944794\n",
            "Train Epoch: 135 [55040/232365 (24%)]\tLoss: 173.678528\n",
            "Train Epoch: 135 [56320/232365 (24%)]\tLoss: 171.122925\n",
            "Train Epoch: 135 [57600/232365 (25%)]\tLoss: 172.109940\n",
            "Train Epoch: 135 [58880/232365 (25%)]\tLoss: 181.133957\n",
            "Train Epoch: 135 [60160/232365 (26%)]\tLoss: 172.100388\n",
            "Train Epoch: 135 [61440/232365 (26%)]\tLoss: 171.163361\n",
            "Train Epoch: 135 [62720/232365 (27%)]\tLoss: 170.962006\n",
            "Train Epoch: 135 [64000/232365 (28%)]\tLoss: 169.237854\n",
            "Train Epoch: 135 [65280/232365 (28%)]\tLoss: 180.562531\n",
            "Train Epoch: 135 [66560/232365 (29%)]\tLoss: 177.981522\n",
            "Train Epoch: 135 [67840/232365 (29%)]\tLoss: 175.202438\n",
            "Train Epoch: 135 [69120/232365 (30%)]\tLoss: 170.249435\n",
            "Train Epoch: 135 [70400/232365 (30%)]\tLoss: 181.281509\n",
            "Train Epoch: 135 [71680/232365 (31%)]\tLoss: 165.387253\n",
            "Train Epoch: 135 [72960/232365 (31%)]\tLoss: 169.958755\n",
            "Train Epoch: 135 [74240/232365 (32%)]\tLoss: 169.680466\n",
            "Train Epoch: 135 [75520/232365 (32%)]\tLoss: 163.295532\n",
            "Train Epoch: 135 [76800/232365 (33%)]\tLoss: 177.160080\n",
            "Train Epoch: 135 [78080/232365 (34%)]\tLoss: 165.548431\n",
            "Train Epoch: 135 [79360/232365 (34%)]\tLoss: 166.421219\n",
            "Train Epoch: 135 [80640/232365 (35%)]\tLoss: 174.180801\n",
            "Train Epoch: 135 [81920/232365 (35%)]\tLoss: 170.652710\n",
            "Train Epoch: 135 [83200/232365 (36%)]\tLoss: 167.908157\n",
            "Train Epoch: 135 [84480/232365 (36%)]\tLoss: 177.515015\n",
            "Train Epoch: 135 [85760/232365 (37%)]\tLoss: 170.054932\n",
            "Train Epoch: 135 [87040/232365 (37%)]\tLoss: 169.423904\n",
            "Train Epoch: 135 [88320/232365 (38%)]\tLoss: 175.014206\n",
            "Train Epoch: 135 [89600/232365 (39%)]\tLoss: 170.105301\n",
            "Train Epoch: 135 [90880/232365 (39%)]\tLoss: 169.697433\n",
            "Train Epoch: 135 [92160/232365 (40%)]\tLoss: 173.228958\n",
            "Train Epoch: 135 [93440/232365 (40%)]\tLoss: 175.313477\n",
            "Train Epoch: 135 [94720/232365 (41%)]\tLoss: 167.699051\n",
            "Train Epoch: 135 [96000/232365 (41%)]\tLoss: 176.154968\n",
            "Train Epoch: 135 [97280/232365 (42%)]\tLoss: 180.752716\n",
            "Train Epoch: 135 [98560/232365 (42%)]\tLoss: 172.114456\n",
            "Train Epoch: 135 [99840/232365 (43%)]\tLoss: 178.505585\n",
            "Train Epoch: 135 [101120/232365 (44%)]\tLoss: 179.947876\n",
            "Train Epoch: 135 [102400/232365 (44%)]\tLoss: 172.319077\n",
            "Train Epoch: 135 [103680/232365 (45%)]\tLoss: 176.155731\n",
            "Train Epoch: 135 [104960/232365 (45%)]\tLoss: 175.801346\n",
            "Train Epoch: 135 [106240/232365 (46%)]\tLoss: 169.516006\n",
            "Train Epoch: 135 [107520/232365 (46%)]\tLoss: 167.469025\n",
            "Train Epoch: 135 [108800/232365 (47%)]\tLoss: 180.251495\n",
            "Train Epoch: 135 [110080/232365 (47%)]\tLoss: 175.018417\n",
            "Train Epoch: 135 [111360/232365 (48%)]\tLoss: 163.551971\n",
            "Train Epoch: 135 [112640/232365 (48%)]\tLoss: 171.701218\n",
            "Train Epoch: 135 [113920/232365 (49%)]\tLoss: 170.425766\n",
            "Train Epoch: 135 [115200/232365 (50%)]\tLoss: 168.986572\n",
            "Train Epoch: 135 [116480/232365 (50%)]\tLoss: 170.014282\n",
            "Train Epoch: 135 [117760/232365 (51%)]\tLoss: 170.984238\n",
            "Train Epoch: 135 [119040/232365 (51%)]\tLoss: 175.875504\n",
            "Train Epoch: 135 [120320/232365 (52%)]\tLoss: 172.525726\n",
            "Train Epoch: 135 [121600/232365 (52%)]\tLoss: 177.508362\n",
            "Train Epoch: 135 [122880/232365 (53%)]\tLoss: 173.923508\n",
            "Train Epoch: 135 [124160/232365 (53%)]\tLoss: 169.965210\n",
            "Train Epoch: 135 [125440/232365 (54%)]\tLoss: 174.725220\n",
            "Train Epoch: 135 [126720/232365 (55%)]\tLoss: 169.172943\n",
            "Train Epoch: 135 [128000/232365 (55%)]\tLoss: 172.851608\n",
            "Train Epoch: 135 [129280/232365 (56%)]\tLoss: 167.060867\n",
            "Train Epoch: 135 [130560/232365 (56%)]\tLoss: 181.422272\n",
            "Train Epoch: 135 [131840/232365 (57%)]\tLoss: 176.945541\n",
            "Train Epoch: 135 [133120/232365 (57%)]\tLoss: 170.153214\n",
            "Train Epoch: 135 [134400/232365 (58%)]\tLoss: 169.056625\n",
            "Train Epoch: 135 [135680/232365 (58%)]\tLoss: 185.784470\n",
            "Train Epoch: 135 [136960/232365 (59%)]\tLoss: 174.607040\n",
            "Train Epoch: 135 [138240/232365 (59%)]\tLoss: 171.438431\n",
            "Train Epoch: 135 [139520/232365 (60%)]\tLoss: 170.245712\n",
            "Train Epoch: 135 [140800/232365 (61%)]\tLoss: 170.787369\n",
            "Train Epoch: 135 [142080/232365 (61%)]\tLoss: 167.269592\n",
            "Train Epoch: 135 [143360/232365 (62%)]\tLoss: 172.294861\n",
            "Train Epoch: 135 [144640/232365 (62%)]\tLoss: 172.980255\n",
            "Train Epoch: 135 [145920/232365 (63%)]\tLoss: 165.696930\n",
            "Train Epoch: 135 [147200/232365 (63%)]\tLoss: 163.639069\n",
            "Train Epoch: 135 [148480/232365 (64%)]\tLoss: 171.279373\n",
            "Train Epoch: 135 [149760/232365 (64%)]\tLoss: 176.245850\n",
            "Train Epoch: 135 [151040/232365 (65%)]\tLoss: 168.561935\n",
            "Train Epoch: 135 [152320/232365 (66%)]\tLoss: 175.660202\n",
            "Train Epoch: 135 [153600/232365 (66%)]\tLoss: 180.831848\n",
            "Train Epoch: 135 [154880/232365 (67%)]\tLoss: 177.605408\n",
            "Train Epoch: 135 [156160/232365 (67%)]\tLoss: 167.283829\n",
            "Train Epoch: 135 [157440/232365 (68%)]\tLoss: 181.051483\n",
            "Train Epoch: 135 [158720/232365 (68%)]\tLoss: 173.541519\n",
            "Train Epoch: 135 [160000/232365 (69%)]\tLoss: 174.250900\n",
            "Train Epoch: 135 [161280/232365 (69%)]\tLoss: 173.309204\n",
            "Train Epoch: 135 [162560/232365 (70%)]\tLoss: 170.790375\n",
            "Train Epoch: 135 [163840/232365 (70%)]\tLoss: 174.162628\n",
            "Train Epoch: 135 [165120/232365 (71%)]\tLoss: 176.452438\n",
            "Train Epoch: 135 [166400/232365 (72%)]\tLoss: 184.037811\n",
            "Train Epoch: 135 [167680/232365 (72%)]\tLoss: 168.404175\n",
            "Train Epoch: 135 [168960/232365 (73%)]\tLoss: 172.239975\n",
            "Train Epoch: 135 [170240/232365 (73%)]\tLoss: 168.370514\n",
            "Train Epoch: 135 [171520/232365 (74%)]\tLoss: 172.149384\n",
            "Train Epoch: 135 [172800/232365 (74%)]\tLoss: 172.678284\n",
            "Train Epoch: 135 [174080/232365 (75%)]\tLoss: 168.269836\n",
            "Train Epoch: 135 [175360/232365 (75%)]\tLoss: 182.422272\n",
            "Train Epoch: 135 [176640/232365 (76%)]\tLoss: 175.648849\n",
            "Train Epoch: 135 [177920/232365 (77%)]\tLoss: 173.349945\n",
            "Train Epoch: 135 [179200/232365 (77%)]\tLoss: 174.900452\n",
            "Train Epoch: 135 [180480/232365 (78%)]\tLoss: 168.223190\n",
            "Train Epoch: 135 [181760/232365 (78%)]\tLoss: 170.776871\n",
            "Train Epoch: 135 [183040/232365 (79%)]\tLoss: 181.814178\n",
            "Train Epoch: 135 [184320/232365 (79%)]\tLoss: 172.640274\n",
            "Train Epoch: 135 [185600/232365 (80%)]\tLoss: 176.239594\n",
            "Train Epoch: 135 [186880/232365 (80%)]\tLoss: 173.276260\n",
            "Train Epoch: 135 [188160/232365 (81%)]\tLoss: 171.661972\n",
            "Train Epoch: 135 [189440/232365 (81%)]\tLoss: 161.914368\n",
            "Train Epoch: 135 [190720/232365 (82%)]\tLoss: 172.564728\n",
            "Train Epoch: 135 [192000/232365 (83%)]\tLoss: 166.530640\n",
            "Train Epoch: 135 [193280/232365 (83%)]\tLoss: 173.243378\n",
            "Train Epoch: 135 [194560/232365 (84%)]\tLoss: 166.182129\n",
            "Train Epoch: 135 [195840/232365 (84%)]\tLoss: 166.045761\n",
            "Train Epoch: 135 [197120/232365 (85%)]\tLoss: 181.436203\n",
            "Train Epoch: 135 [198400/232365 (85%)]\tLoss: 176.591553\n",
            "Train Epoch: 135 [199680/232365 (86%)]\tLoss: 172.901276\n",
            "Train Epoch: 135 [200960/232365 (86%)]\tLoss: 190.768875\n",
            "Train Epoch: 135 [202240/232365 (87%)]\tLoss: 170.433441\n",
            "Train Epoch: 135 [203520/232365 (88%)]\tLoss: 168.210754\n",
            "Train Epoch: 135 [204800/232365 (88%)]\tLoss: 162.201492\n",
            "Train Epoch: 135 [206080/232365 (89%)]\tLoss: 173.278870\n",
            "Train Epoch: 135 [207360/232365 (89%)]\tLoss: 170.405624\n",
            "Train Epoch: 135 [208640/232365 (90%)]\tLoss: 167.858643\n",
            "Train Epoch: 135 [209920/232365 (90%)]\tLoss: 170.390579\n",
            "Train Epoch: 135 [211200/232365 (91%)]\tLoss: 167.686279\n",
            "Train Epoch: 135 [212480/232365 (91%)]\tLoss: 180.570068\n",
            "Train Epoch: 135 [213760/232365 (92%)]\tLoss: 170.838333\n",
            "Train Epoch: 135 [215040/232365 (93%)]\tLoss: 171.730606\n",
            "Train Epoch: 135 [216320/232365 (93%)]\tLoss: 178.535065\n",
            "Train Epoch: 135 [217600/232365 (94%)]\tLoss: 175.380554\n",
            "Train Epoch: 135 [218880/232365 (94%)]\tLoss: 168.912003\n",
            "Train Epoch: 135 [220160/232365 (95%)]\tLoss: 177.660080\n",
            "Train Epoch: 135 [221440/232365 (95%)]\tLoss: 173.408188\n",
            "Train Epoch: 135 [222720/232365 (96%)]\tLoss: 173.591522\n",
            "Train Epoch: 135 [224000/232365 (96%)]\tLoss: 172.857208\n",
            "Train Epoch: 135 [225280/232365 (97%)]\tLoss: 173.712799\n",
            "Train Epoch: 135 [226560/232365 (97%)]\tLoss: 173.461563\n",
            "Train Epoch: 135 [227840/232365 (98%)]\tLoss: 173.863724\n",
            "Train Epoch: 135 [229120/232365 (99%)]\tLoss: 171.108734\n",
            "Train Epoch: 135 [230400/232365 (99%)]\tLoss: 175.831253\n",
            "Train Epoch: 135 [231680/232365 (100%)]\tLoss: 177.121506\n",
            "====> Epoch: 135 Average loss: 172.4795, Accuracy: 74.24%\n",
            "====> Test set loss: 183.5539, Accuracy: 74.12%\n",
            "Train Epoch: 136 [0/232365 (0%)]\tLoss: 178.106079\n",
            "Train Epoch: 136 [1280/232365 (1%)]\tLoss: 167.935959\n",
            "Train Epoch: 136 [2560/232365 (1%)]\tLoss: 171.467529\n",
            "Train Epoch: 136 [3840/232365 (2%)]\tLoss: 171.832397\n",
            "Train Epoch: 136 [5120/232365 (2%)]\tLoss: 187.642639\n",
            "Train Epoch: 136 [6400/232365 (3%)]\tLoss: 176.719482\n",
            "Train Epoch: 136 [7680/232365 (3%)]\tLoss: 168.885071\n",
            "Train Epoch: 136 [8960/232365 (4%)]\tLoss: 167.431671\n",
            "Train Epoch: 136 [10240/232365 (4%)]\tLoss: 163.733597\n",
            "Train Epoch: 136 [11520/232365 (5%)]\tLoss: 171.425110\n",
            "Train Epoch: 136 [12800/232365 (6%)]\tLoss: 165.756149\n",
            "Train Epoch: 136 [14080/232365 (6%)]\tLoss: 179.990967\n",
            "Train Epoch: 136 [15360/232365 (7%)]\tLoss: 172.888229\n",
            "Train Epoch: 136 [16640/232365 (7%)]\tLoss: 173.091949\n",
            "Train Epoch: 136 [17920/232365 (8%)]\tLoss: 181.003525\n",
            "Train Epoch: 136 [19200/232365 (8%)]\tLoss: 163.860733\n",
            "Train Epoch: 136 [20480/232365 (9%)]\tLoss: 173.040558\n",
            "Train Epoch: 136 [21760/232365 (9%)]\tLoss: 169.523346\n",
            "Train Epoch: 136 [23040/232365 (10%)]\tLoss: 158.780212\n",
            "Train Epoch: 136 [24320/232365 (10%)]\tLoss: 179.570786\n",
            "Train Epoch: 136 [25600/232365 (11%)]\tLoss: 168.154190\n",
            "Train Epoch: 136 [26880/232365 (12%)]\tLoss: 172.057449\n",
            "Train Epoch: 136 [28160/232365 (12%)]\tLoss: 171.041794\n",
            "Train Epoch: 136 [29440/232365 (13%)]\tLoss: 177.404907\n",
            "Train Epoch: 136 [30720/232365 (13%)]\tLoss: 164.171127\n",
            "Train Epoch: 136 [32000/232365 (14%)]\tLoss: 178.442169\n",
            "Train Epoch: 136 [33280/232365 (14%)]\tLoss: 175.620087\n",
            "Train Epoch: 136 [34560/232365 (15%)]\tLoss: 174.810272\n",
            "Train Epoch: 136 [35840/232365 (15%)]\tLoss: 179.466034\n",
            "Train Epoch: 136 [37120/232365 (16%)]\tLoss: 171.943848\n",
            "Train Epoch: 136 [38400/232365 (17%)]\tLoss: 176.632660\n",
            "Train Epoch: 136 [39680/232365 (17%)]\tLoss: 178.963562\n",
            "Train Epoch: 136 [40960/232365 (18%)]\tLoss: 172.152176\n",
            "Train Epoch: 136 [42240/232365 (18%)]\tLoss: 170.114197\n",
            "Train Epoch: 136 [43520/232365 (19%)]\tLoss: 178.665314\n",
            "Train Epoch: 136 [44800/232365 (19%)]\tLoss: 169.598251\n",
            "Train Epoch: 136 [46080/232365 (20%)]\tLoss: 163.269653\n",
            "Train Epoch: 136 [47360/232365 (20%)]\tLoss: 164.646133\n",
            "Train Epoch: 136 [48640/232365 (21%)]\tLoss: 175.951233\n",
            "Train Epoch: 136 [49920/232365 (21%)]\tLoss: 171.757416\n",
            "Train Epoch: 136 [51200/232365 (22%)]\tLoss: 180.681335\n",
            "Train Epoch: 136 [52480/232365 (23%)]\tLoss: 170.123260\n",
            "Train Epoch: 136 [53760/232365 (23%)]\tLoss: 182.241455\n",
            "Train Epoch: 136 [55040/232365 (24%)]\tLoss: 174.444656\n",
            "Train Epoch: 136 [56320/232365 (24%)]\tLoss: 175.880936\n",
            "Train Epoch: 136 [57600/232365 (25%)]\tLoss: 175.900757\n",
            "Train Epoch: 136 [58880/232365 (25%)]\tLoss: 175.299057\n",
            "Train Epoch: 136 [60160/232365 (26%)]\tLoss: 177.252441\n",
            "Train Epoch: 136 [61440/232365 (26%)]\tLoss: 176.593292\n",
            "Train Epoch: 136 [62720/232365 (27%)]\tLoss: 175.059433\n",
            "Train Epoch: 136 [64000/232365 (28%)]\tLoss: 171.926300\n",
            "Train Epoch: 136 [65280/232365 (28%)]\tLoss: 170.672272\n",
            "Train Epoch: 136 [66560/232365 (29%)]\tLoss: 169.554047\n",
            "Train Epoch: 136 [67840/232365 (29%)]\tLoss: 180.333099\n",
            "Train Epoch: 136 [69120/232365 (30%)]\tLoss: 174.900589\n",
            "Train Epoch: 136 [70400/232365 (30%)]\tLoss: 177.510422\n",
            "Train Epoch: 136 [71680/232365 (31%)]\tLoss: 174.470688\n",
            "Train Epoch: 136 [72960/232365 (31%)]\tLoss: 168.408066\n",
            "Train Epoch: 136 [74240/232365 (32%)]\tLoss: 166.993042\n",
            "Train Epoch: 136 [75520/232365 (32%)]\tLoss: 175.680511\n",
            "Train Epoch: 136 [76800/232365 (33%)]\tLoss: 161.764130\n",
            "Train Epoch: 136 [78080/232365 (34%)]\tLoss: 166.474319\n",
            "Train Epoch: 136 [79360/232365 (34%)]\tLoss: 168.136963\n",
            "Train Epoch: 136 [80640/232365 (35%)]\tLoss: 184.617828\n",
            "Train Epoch: 136 [81920/232365 (35%)]\tLoss: 169.636841\n",
            "Train Epoch: 136 [83200/232365 (36%)]\tLoss: 165.670807\n",
            "Train Epoch: 136 [84480/232365 (36%)]\tLoss: 175.622177\n",
            "Train Epoch: 136 [85760/232365 (37%)]\tLoss: 167.601501\n",
            "Train Epoch: 136 [87040/232365 (37%)]\tLoss: 174.723206\n",
            "Train Epoch: 136 [88320/232365 (38%)]\tLoss: 169.701431\n",
            "Train Epoch: 136 [89600/232365 (39%)]\tLoss: 172.266891\n",
            "Train Epoch: 136 [90880/232365 (39%)]\tLoss: 176.427856\n",
            "Train Epoch: 136 [92160/232365 (40%)]\tLoss: 166.613251\n",
            "Train Epoch: 136 [93440/232365 (40%)]\tLoss: 175.024963\n",
            "Train Epoch: 136 [94720/232365 (41%)]\tLoss: 174.758469\n",
            "Train Epoch: 136 [96000/232365 (41%)]\tLoss: 184.132675\n",
            "Train Epoch: 136 [97280/232365 (42%)]\tLoss: 177.591553\n",
            "Train Epoch: 136 [98560/232365 (42%)]\tLoss: 166.889084\n",
            "Train Epoch: 136 [99840/232365 (43%)]\tLoss: 174.066238\n",
            "Train Epoch: 136 [101120/232365 (44%)]\tLoss: 177.382599\n",
            "Train Epoch: 136 [102400/232365 (44%)]\tLoss: 174.556366\n",
            "Train Epoch: 136 [103680/232365 (45%)]\tLoss: 169.856995\n",
            "Train Epoch: 136 [104960/232365 (45%)]\tLoss: 175.334076\n",
            "Train Epoch: 136 [106240/232365 (46%)]\tLoss: 176.565094\n",
            "Train Epoch: 136 [107520/232365 (46%)]\tLoss: 172.143723\n",
            "Train Epoch: 136 [108800/232365 (47%)]\tLoss: 168.273651\n",
            "Train Epoch: 136 [110080/232365 (47%)]\tLoss: 166.207809\n",
            "Train Epoch: 136 [111360/232365 (48%)]\tLoss: 162.632797\n",
            "Train Epoch: 136 [112640/232365 (48%)]\tLoss: 167.461700\n",
            "Train Epoch: 136 [113920/232365 (49%)]\tLoss: 166.806885\n",
            "Train Epoch: 136 [115200/232365 (50%)]\tLoss: 161.814789\n",
            "Train Epoch: 136 [116480/232365 (50%)]\tLoss: 169.613129\n",
            "Train Epoch: 136 [117760/232365 (51%)]\tLoss: 170.483261\n",
            "Train Epoch: 136 [119040/232365 (51%)]\tLoss: 165.676849\n",
            "Train Epoch: 136 [120320/232365 (52%)]\tLoss: 164.228607\n",
            "Train Epoch: 136 [121600/232365 (52%)]\tLoss: 168.597366\n",
            "Train Epoch: 136 [122880/232365 (53%)]\tLoss: 180.631348\n",
            "Train Epoch: 136 [124160/232365 (53%)]\tLoss: 174.984299\n",
            "Train Epoch: 136 [125440/232365 (54%)]\tLoss: 172.068008\n",
            "Train Epoch: 136 [126720/232365 (55%)]\tLoss: 163.888367\n",
            "Train Epoch: 136 [128000/232365 (55%)]\tLoss: 171.344742\n",
            "Train Epoch: 136 [129280/232365 (56%)]\tLoss: 167.489853\n",
            "Train Epoch: 136 [130560/232365 (56%)]\tLoss: 171.080948\n",
            "Train Epoch: 136 [131840/232365 (57%)]\tLoss: 174.829056\n",
            "Train Epoch: 136 [133120/232365 (57%)]\tLoss: 172.607666\n",
            "Train Epoch: 136 [134400/232365 (58%)]\tLoss: 173.289413\n",
            "Train Epoch: 136 [135680/232365 (58%)]\tLoss: 168.907776\n",
            "Train Epoch: 136 [136960/232365 (59%)]\tLoss: 171.496628\n",
            "Train Epoch: 136 [138240/232365 (59%)]\tLoss: 170.818680\n",
            "Train Epoch: 136 [139520/232365 (60%)]\tLoss: 169.092163\n",
            "Train Epoch: 136 [140800/232365 (61%)]\tLoss: 175.196747\n",
            "Train Epoch: 136 [142080/232365 (61%)]\tLoss: 185.204590\n",
            "Train Epoch: 136 [143360/232365 (62%)]\tLoss: 169.987289\n",
            "Train Epoch: 136 [144640/232365 (62%)]\tLoss: 175.106888\n",
            "Train Epoch: 136 [145920/232365 (63%)]\tLoss: 168.713455\n",
            "Train Epoch: 136 [147200/232365 (63%)]\tLoss: 177.799606\n",
            "Train Epoch: 136 [148480/232365 (64%)]\tLoss: 170.071045\n",
            "Train Epoch: 136 [149760/232365 (64%)]\tLoss: 175.506195\n",
            "Train Epoch: 136 [151040/232365 (65%)]\tLoss: 163.786560\n",
            "Train Epoch: 136 [152320/232365 (66%)]\tLoss: 169.467773\n",
            "Train Epoch: 136 [153600/232365 (66%)]\tLoss: 174.165909\n",
            "Train Epoch: 136 [154880/232365 (67%)]\tLoss: 174.091034\n",
            "Train Epoch: 136 [156160/232365 (67%)]\tLoss: 164.879211\n",
            "Train Epoch: 136 [157440/232365 (68%)]\tLoss: 171.844833\n",
            "Train Epoch: 136 [158720/232365 (68%)]\tLoss: 171.043854\n",
            "Train Epoch: 136 [160000/232365 (69%)]\tLoss: 175.431168\n",
            "Train Epoch: 136 [161280/232365 (69%)]\tLoss: 165.799805\n",
            "Train Epoch: 136 [162560/232365 (70%)]\tLoss: 169.227386\n",
            "Train Epoch: 136 [163840/232365 (70%)]\tLoss: 163.952255\n",
            "Train Epoch: 136 [165120/232365 (71%)]\tLoss: 172.420090\n",
            "Train Epoch: 136 [166400/232365 (72%)]\tLoss: 177.564209\n",
            "Train Epoch: 136 [167680/232365 (72%)]\tLoss: 181.060577\n",
            "Train Epoch: 136 [168960/232365 (73%)]\tLoss: 175.846512\n",
            "Train Epoch: 136 [170240/232365 (73%)]\tLoss: 167.837936\n",
            "Train Epoch: 136 [171520/232365 (74%)]\tLoss: 178.808304\n",
            "Train Epoch: 136 [172800/232365 (74%)]\tLoss: 176.471161\n",
            "Train Epoch: 136 [174080/232365 (75%)]\tLoss: 179.586487\n",
            "Train Epoch: 136 [175360/232365 (75%)]\tLoss: 168.510071\n",
            "Train Epoch: 136 [176640/232365 (76%)]\tLoss: 165.666458\n",
            "Train Epoch: 136 [177920/232365 (77%)]\tLoss: 171.198654\n",
            "Train Epoch: 136 [179200/232365 (77%)]\tLoss: 165.551437\n",
            "Train Epoch: 136 [180480/232365 (78%)]\tLoss: 168.614029\n",
            "Train Epoch: 136 [181760/232365 (78%)]\tLoss: 165.710480\n",
            "Train Epoch: 136 [183040/232365 (79%)]\tLoss: 165.184845\n",
            "Train Epoch: 136 [184320/232365 (79%)]\tLoss: 164.220932\n",
            "Train Epoch: 136 [185600/232365 (80%)]\tLoss: 175.820709\n",
            "Train Epoch: 136 [186880/232365 (80%)]\tLoss: 177.220764\n",
            "Train Epoch: 136 [188160/232365 (81%)]\tLoss: 173.159668\n",
            "Train Epoch: 136 [189440/232365 (81%)]\tLoss: 177.775970\n",
            "Train Epoch: 136 [190720/232365 (82%)]\tLoss: 181.251862\n",
            "Train Epoch: 136 [192000/232365 (83%)]\tLoss: 160.587860\n",
            "Train Epoch: 136 [193280/232365 (83%)]\tLoss: 171.281067\n",
            "Train Epoch: 136 [194560/232365 (84%)]\tLoss: 163.812271\n",
            "Train Epoch: 136 [195840/232365 (84%)]\tLoss: 169.062866\n",
            "Train Epoch: 136 [197120/232365 (85%)]\tLoss: 170.422546\n",
            "Train Epoch: 136 [198400/232365 (85%)]\tLoss: 172.240723\n",
            "Train Epoch: 136 [199680/232365 (86%)]\tLoss: 173.677643\n",
            "Train Epoch: 136 [200960/232365 (86%)]\tLoss: 183.139389\n",
            "Train Epoch: 136 [202240/232365 (87%)]\tLoss: 166.375824\n",
            "Train Epoch: 136 [203520/232365 (88%)]\tLoss: 181.300659\n",
            "Train Epoch: 136 [204800/232365 (88%)]\tLoss: 165.679581\n",
            "Train Epoch: 136 [206080/232365 (89%)]\tLoss: 176.748657\n",
            "Train Epoch: 136 [207360/232365 (89%)]\tLoss: 177.599426\n",
            "Train Epoch: 136 [208640/232365 (90%)]\tLoss: 177.168060\n",
            "Train Epoch: 136 [209920/232365 (90%)]\tLoss: 176.947830\n",
            "Train Epoch: 136 [211200/232365 (91%)]\tLoss: 170.504532\n",
            "Train Epoch: 136 [212480/232365 (91%)]\tLoss: 173.547974\n",
            "Train Epoch: 136 [213760/232365 (92%)]\tLoss: 182.903717\n",
            "Train Epoch: 136 [215040/232365 (93%)]\tLoss: 169.664413\n",
            "Train Epoch: 136 [216320/232365 (93%)]\tLoss: 176.681335\n",
            "Train Epoch: 136 [217600/232365 (94%)]\tLoss: 179.825775\n",
            "Train Epoch: 136 [218880/232365 (94%)]\tLoss: 172.327271\n",
            "Train Epoch: 136 [220160/232365 (95%)]\tLoss: 183.250458\n",
            "Train Epoch: 136 [221440/232365 (95%)]\tLoss: 172.653839\n",
            "Train Epoch: 136 [222720/232365 (96%)]\tLoss: 175.747101\n",
            "Train Epoch: 136 [224000/232365 (96%)]\tLoss: 174.203796\n",
            "Train Epoch: 136 [225280/232365 (97%)]\tLoss: 170.754517\n",
            "Train Epoch: 136 [226560/232365 (97%)]\tLoss: 175.696930\n",
            "Train Epoch: 136 [227840/232365 (98%)]\tLoss: 160.334641\n",
            "Train Epoch: 136 [229120/232365 (99%)]\tLoss: 172.862686\n",
            "Train Epoch: 136 [230400/232365 (99%)]\tLoss: 168.026321\n",
            "Train Epoch: 136 [231680/232365 (100%)]\tLoss: 171.335678\n",
            "====> Epoch: 136 Average loss: 172.4844, Accuracy: 74.23%\n",
            "====> Test set loss: 183.5079, Accuracy: 74.11%\n",
            "Train Epoch: 137 [0/232365 (0%)]\tLoss: 171.891541\n",
            "Train Epoch: 137 [1280/232365 (1%)]\tLoss: 172.581406\n",
            "Train Epoch: 137 [2560/232365 (1%)]\tLoss: 165.450104\n",
            "Train Epoch: 137 [3840/232365 (2%)]\tLoss: 170.615356\n",
            "Train Epoch: 137 [5120/232365 (2%)]\tLoss: 166.684525\n",
            "Train Epoch: 137 [6400/232365 (3%)]\tLoss: 173.748047\n",
            "Train Epoch: 137 [7680/232365 (3%)]\tLoss: 177.460831\n",
            "Train Epoch: 137 [8960/232365 (4%)]\tLoss: 171.435196\n",
            "Train Epoch: 137 [10240/232365 (4%)]\tLoss: 174.181107\n",
            "Train Epoch: 137 [11520/232365 (5%)]\tLoss: 174.122421\n",
            "Train Epoch: 137 [12800/232365 (6%)]\tLoss: 177.413696\n",
            "Train Epoch: 137 [14080/232365 (6%)]\tLoss: 174.970795\n",
            "Train Epoch: 137 [15360/232365 (7%)]\tLoss: 168.139038\n",
            "Train Epoch: 137 [16640/232365 (7%)]\tLoss: 161.476227\n",
            "Train Epoch: 137 [17920/232365 (8%)]\tLoss: 175.986084\n",
            "Train Epoch: 137 [19200/232365 (8%)]\tLoss: 173.475296\n",
            "Train Epoch: 137 [20480/232365 (9%)]\tLoss: 172.335785\n",
            "Train Epoch: 137 [21760/232365 (9%)]\tLoss: 175.358078\n",
            "Train Epoch: 137 [23040/232365 (10%)]\tLoss: 171.961121\n",
            "Train Epoch: 137 [24320/232365 (10%)]\tLoss: 171.035049\n",
            "Train Epoch: 137 [25600/232365 (11%)]\tLoss: 172.062286\n",
            "Train Epoch: 137 [26880/232365 (12%)]\tLoss: 171.227631\n",
            "Train Epoch: 137 [28160/232365 (12%)]\tLoss: 173.973663\n",
            "Train Epoch: 137 [29440/232365 (13%)]\tLoss: 170.523422\n",
            "Train Epoch: 137 [30720/232365 (13%)]\tLoss: 177.146225\n",
            "Train Epoch: 137 [32000/232365 (14%)]\tLoss: 177.034348\n",
            "Train Epoch: 137 [33280/232365 (14%)]\tLoss: 175.017090\n",
            "Train Epoch: 137 [34560/232365 (15%)]\tLoss: 172.433868\n",
            "Train Epoch: 137 [35840/232365 (15%)]\tLoss: 183.139740\n",
            "Train Epoch: 137 [37120/232365 (16%)]\tLoss: 173.598358\n",
            "Train Epoch: 137 [38400/232365 (17%)]\tLoss: 172.891907\n",
            "Train Epoch: 137 [39680/232365 (17%)]\tLoss: 176.767288\n",
            "Train Epoch: 137 [40960/232365 (18%)]\tLoss: 175.338516\n",
            "Train Epoch: 137 [42240/232365 (18%)]\tLoss: 163.660385\n",
            "Train Epoch: 137 [43520/232365 (19%)]\tLoss: 182.254150\n",
            "Train Epoch: 137 [44800/232365 (19%)]\tLoss: 172.002487\n",
            "Train Epoch: 137 [46080/232365 (20%)]\tLoss: 176.700485\n",
            "Train Epoch: 137 [47360/232365 (20%)]\tLoss: 171.204605\n",
            "Train Epoch: 137 [48640/232365 (21%)]\tLoss: 175.501663\n",
            "Train Epoch: 137 [49920/232365 (21%)]\tLoss: 177.162796\n",
            "Train Epoch: 137 [51200/232365 (22%)]\tLoss: 171.790543\n",
            "Train Epoch: 137 [52480/232365 (23%)]\tLoss: 173.939926\n",
            "Train Epoch: 137 [53760/232365 (23%)]\tLoss: 169.793167\n",
            "Train Epoch: 137 [55040/232365 (24%)]\tLoss: 166.858170\n",
            "Train Epoch: 137 [56320/232365 (24%)]\tLoss: 178.278549\n",
            "Train Epoch: 137 [57600/232365 (25%)]\tLoss: 164.254501\n",
            "Train Epoch: 137 [58880/232365 (25%)]\tLoss: 168.262619\n",
            "Train Epoch: 137 [60160/232365 (26%)]\tLoss: 177.788101\n",
            "Train Epoch: 137 [61440/232365 (26%)]\tLoss: 172.478973\n",
            "Train Epoch: 137 [62720/232365 (27%)]\tLoss: 170.629959\n",
            "Train Epoch: 137 [64000/232365 (28%)]\tLoss: 170.117386\n",
            "Train Epoch: 137 [65280/232365 (28%)]\tLoss: 167.695404\n",
            "Train Epoch: 137 [66560/232365 (29%)]\tLoss: 166.054382\n",
            "Train Epoch: 137 [67840/232365 (29%)]\tLoss: 165.865189\n",
            "Train Epoch: 137 [69120/232365 (30%)]\tLoss: 174.892441\n",
            "Train Epoch: 137 [70400/232365 (30%)]\tLoss: 172.224579\n",
            "Train Epoch: 137 [71680/232365 (31%)]\tLoss: 164.516434\n",
            "Train Epoch: 137 [72960/232365 (31%)]\tLoss: 176.893036\n",
            "Train Epoch: 137 [74240/232365 (32%)]\tLoss: 180.203964\n",
            "Train Epoch: 137 [75520/232365 (32%)]\tLoss: 172.633499\n",
            "Train Epoch: 137 [76800/232365 (33%)]\tLoss: 167.678925\n",
            "Train Epoch: 137 [78080/232365 (34%)]\tLoss: 159.659958\n",
            "Train Epoch: 137 [79360/232365 (34%)]\tLoss: 176.631363\n",
            "Train Epoch: 137 [80640/232365 (35%)]\tLoss: 178.082306\n",
            "Train Epoch: 137 [81920/232365 (35%)]\tLoss: 173.010880\n",
            "Train Epoch: 137 [83200/232365 (36%)]\tLoss: 170.522369\n",
            "Train Epoch: 137 [84480/232365 (36%)]\tLoss: 171.406921\n",
            "Train Epoch: 137 [85760/232365 (37%)]\tLoss: 167.339630\n",
            "Train Epoch: 137 [87040/232365 (37%)]\tLoss: 182.772888\n",
            "Train Epoch: 137 [88320/232365 (38%)]\tLoss: 168.562897\n",
            "Train Epoch: 137 [89600/232365 (39%)]\tLoss: 170.753235\n",
            "Train Epoch: 137 [90880/232365 (39%)]\tLoss: 161.235840\n",
            "Train Epoch: 137 [92160/232365 (40%)]\tLoss: 177.648209\n",
            "Train Epoch: 137 [93440/232365 (40%)]\tLoss: 171.403381\n",
            "Train Epoch: 137 [94720/232365 (41%)]\tLoss: 175.354935\n",
            "Train Epoch: 137 [96000/232365 (41%)]\tLoss: 181.952087\n",
            "Train Epoch: 137 [97280/232365 (42%)]\tLoss: 173.347809\n",
            "Train Epoch: 137 [98560/232365 (42%)]\tLoss: 175.007324\n",
            "Train Epoch: 137 [99840/232365 (43%)]\tLoss: 174.877747\n",
            "Train Epoch: 137 [101120/232365 (44%)]\tLoss: 164.776016\n",
            "Train Epoch: 137 [102400/232365 (44%)]\tLoss: 164.313690\n",
            "Train Epoch: 137 [103680/232365 (45%)]\tLoss: 180.357620\n",
            "Train Epoch: 137 [104960/232365 (45%)]\tLoss: 166.697159\n",
            "Train Epoch: 137 [106240/232365 (46%)]\tLoss: 169.209015\n",
            "Train Epoch: 137 [107520/232365 (46%)]\tLoss: 175.277512\n",
            "Train Epoch: 137 [108800/232365 (47%)]\tLoss: 178.332214\n",
            "Train Epoch: 137 [110080/232365 (47%)]\tLoss: 180.053406\n",
            "Train Epoch: 137 [111360/232365 (48%)]\tLoss: 167.383911\n",
            "Train Epoch: 137 [112640/232365 (48%)]\tLoss: 165.181259\n",
            "Train Epoch: 137 [113920/232365 (49%)]\tLoss: 173.300217\n",
            "Train Epoch: 137 [115200/232365 (50%)]\tLoss: 182.385925\n",
            "Train Epoch: 137 [116480/232365 (50%)]\tLoss: 156.126755\n",
            "Train Epoch: 137 [117760/232365 (51%)]\tLoss: 172.018509\n",
            "Train Epoch: 137 [119040/232365 (51%)]\tLoss: 165.936874\n",
            "Train Epoch: 137 [120320/232365 (52%)]\tLoss: 178.377197\n",
            "Train Epoch: 137 [121600/232365 (52%)]\tLoss: 169.639938\n",
            "Train Epoch: 137 [122880/232365 (53%)]\tLoss: 172.614563\n",
            "Train Epoch: 137 [124160/232365 (53%)]\tLoss: 161.325150\n",
            "Train Epoch: 137 [125440/232365 (54%)]\tLoss: 171.754486\n",
            "Train Epoch: 137 [126720/232365 (55%)]\tLoss: 165.741348\n",
            "Train Epoch: 137 [128000/232365 (55%)]\tLoss: 171.646378\n",
            "Train Epoch: 137 [129280/232365 (56%)]\tLoss: 172.946686\n",
            "Train Epoch: 137 [130560/232365 (56%)]\tLoss: 173.575836\n",
            "Train Epoch: 137 [131840/232365 (57%)]\tLoss: 167.569427\n",
            "Train Epoch: 137 [133120/232365 (57%)]\tLoss: 177.266251\n",
            "Train Epoch: 137 [134400/232365 (58%)]\tLoss: 172.209381\n",
            "Train Epoch: 137 [135680/232365 (58%)]\tLoss: 175.526901\n",
            "Train Epoch: 137 [136960/232365 (59%)]\tLoss: 183.389435\n",
            "Train Epoch: 137 [138240/232365 (59%)]\tLoss: 176.875641\n",
            "Train Epoch: 137 [139520/232365 (60%)]\tLoss: 162.217453\n",
            "Train Epoch: 137 [140800/232365 (61%)]\tLoss: 170.021027\n",
            "Train Epoch: 137 [142080/232365 (61%)]\tLoss: 167.027740\n",
            "Train Epoch: 137 [143360/232365 (62%)]\tLoss: 168.274826\n",
            "Train Epoch: 137 [144640/232365 (62%)]\tLoss: 169.061554\n",
            "Train Epoch: 137 [145920/232365 (63%)]\tLoss: 181.644440\n",
            "Train Epoch: 137 [147200/232365 (63%)]\tLoss: 177.254868\n",
            "Train Epoch: 137 [148480/232365 (64%)]\tLoss: 164.783371\n",
            "Train Epoch: 137 [149760/232365 (64%)]\tLoss: 170.684082\n",
            "Train Epoch: 137 [151040/232365 (65%)]\tLoss: 170.200485\n",
            "Train Epoch: 137 [152320/232365 (66%)]\tLoss: 176.452896\n",
            "Train Epoch: 137 [153600/232365 (66%)]\tLoss: 176.851166\n",
            "Train Epoch: 137 [154880/232365 (67%)]\tLoss: 174.685547\n",
            "Train Epoch: 137 [156160/232365 (67%)]\tLoss: 178.097000\n",
            "Train Epoch: 137 [157440/232365 (68%)]\tLoss: 170.222031\n",
            "Train Epoch: 137 [158720/232365 (68%)]\tLoss: 181.953812\n",
            "Train Epoch: 137 [160000/232365 (69%)]\tLoss: 168.719269\n",
            "Train Epoch: 137 [161280/232365 (69%)]\tLoss: 169.976044\n",
            "Train Epoch: 137 [162560/232365 (70%)]\tLoss: 169.722031\n",
            "Train Epoch: 137 [163840/232365 (70%)]\tLoss: 168.391968\n",
            "Train Epoch: 137 [165120/232365 (71%)]\tLoss: 174.814194\n",
            "Train Epoch: 137 [166400/232365 (72%)]\tLoss: 173.597412\n",
            "Train Epoch: 137 [167680/232365 (72%)]\tLoss: 182.183746\n",
            "Train Epoch: 137 [168960/232365 (73%)]\tLoss: 177.082794\n",
            "Train Epoch: 137 [170240/232365 (73%)]\tLoss: 164.953094\n",
            "Train Epoch: 137 [171520/232365 (74%)]\tLoss: 174.214859\n",
            "Train Epoch: 137 [172800/232365 (74%)]\tLoss: 171.200607\n",
            "Train Epoch: 137 [174080/232365 (75%)]\tLoss: 170.859879\n",
            "Train Epoch: 137 [175360/232365 (75%)]\tLoss: 156.101929\n",
            "Train Epoch: 137 [176640/232365 (76%)]\tLoss: 169.921280\n",
            "Train Epoch: 137 [177920/232365 (77%)]\tLoss: 180.744263\n",
            "Train Epoch: 137 [179200/232365 (77%)]\tLoss: 177.552917\n",
            "Train Epoch: 137 [180480/232365 (78%)]\tLoss: 175.814819\n",
            "Train Epoch: 137 [181760/232365 (78%)]\tLoss: 174.660065\n",
            "Train Epoch: 137 [183040/232365 (79%)]\tLoss: 163.980728\n",
            "Train Epoch: 137 [184320/232365 (79%)]\tLoss: 167.141769\n",
            "Train Epoch: 137 [185600/232365 (80%)]\tLoss: 163.505859\n",
            "Train Epoch: 137 [186880/232365 (80%)]\tLoss: 171.060211\n",
            "Train Epoch: 137 [188160/232365 (81%)]\tLoss: 178.390656\n",
            "Train Epoch: 137 [189440/232365 (81%)]\tLoss: 169.110138\n",
            "Train Epoch: 137 [190720/232365 (82%)]\tLoss: 172.676956\n",
            "Train Epoch: 137 [192000/232365 (83%)]\tLoss: 176.643951\n",
            "Train Epoch: 137 [193280/232365 (83%)]\tLoss: 172.591736\n",
            "Train Epoch: 137 [194560/232365 (84%)]\tLoss: 178.296127\n",
            "Train Epoch: 137 [195840/232365 (84%)]\tLoss: 170.120270\n",
            "Train Epoch: 137 [197120/232365 (85%)]\tLoss: 165.354614\n",
            "Train Epoch: 137 [198400/232365 (85%)]\tLoss: 172.463394\n",
            "Train Epoch: 137 [199680/232365 (86%)]\tLoss: 169.070831\n",
            "Train Epoch: 137 [200960/232365 (86%)]\tLoss: 168.872742\n",
            "Train Epoch: 137 [202240/232365 (87%)]\tLoss: 166.749527\n",
            "Train Epoch: 137 [203520/232365 (88%)]\tLoss: 163.283386\n",
            "Train Epoch: 137 [204800/232365 (88%)]\tLoss: 172.324478\n",
            "Train Epoch: 137 [206080/232365 (89%)]\tLoss: 174.972092\n",
            "Train Epoch: 137 [207360/232365 (89%)]\tLoss: 166.136780\n",
            "Train Epoch: 137 [208640/232365 (90%)]\tLoss: 161.490158\n",
            "Train Epoch: 137 [209920/232365 (90%)]\tLoss: 178.393600\n",
            "Train Epoch: 137 [211200/232365 (91%)]\tLoss: 169.699310\n",
            "Train Epoch: 137 [212480/232365 (91%)]\tLoss: 167.299240\n",
            "Train Epoch: 137 [213760/232365 (92%)]\tLoss: 173.725983\n",
            "Train Epoch: 137 [215040/232365 (93%)]\tLoss: 175.840469\n",
            "Train Epoch: 137 [216320/232365 (93%)]\tLoss: 175.813660\n",
            "Train Epoch: 137 [217600/232365 (94%)]\tLoss: 172.171356\n",
            "Train Epoch: 137 [218880/232365 (94%)]\tLoss: 173.117813\n",
            "Train Epoch: 137 [220160/232365 (95%)]\tLoss: 162.358765\n",
            "Train Epoch: 137 [221440/232365 (95%)]\tLoss: 175.566467\n",
            "Train Epoch: 137 [222720/232365 (96%)]\tLoss: 173.303787\n",
            "Train Epoch: 137 [224000/232365 (96%)]\tLoss: 166.508133\n",
            "Train Epoch: 137 [225280/232365 (97%)]\tLoss: 171.925888\n",
            "Train Epoch: 137 [226560/232365 (97%)]\tLoss: 172.580414\n",
            "Train Epoch: 137 [227840/232365 (98%)]\tLoss: 176.492538\n",
            "Train Epoch: 137 [229120/232365 (99%)]\tLoss: 166.548370\n",
            "Train Epoch: 137 [230400/232365 (99%)]\tLoss: 174.654251\n",
            "Train Epoch: 137 [231680/232365 (100%)]\tLoss: 174.472992\n",
            "====> Epoch: 137 Average loss: 172.4686, Accuracy: 74.24%\n",
            "====> Test set loss: 183.3872, Accuracy: 74.12%\n",
            "Train Epoch: 138 [0/232365 (0%)]\tLoss: 170.583191\n",
            "Train Epoch: 138 [1280/232365 (1%)]\tLoss: 169.002655\n",
            "Train Epoch: 138 [2560/232365 (1%)]\tLoss: 175.857712\n",
            "Train Epoch: 138 [3840/232365 (2%)]\tLoss: 170.283691\n",
            "Train Epoch: 138 [5120/232365 (2%)]\tLoss: 187.932693\n",
            "Train Epoch: 138 [6400/232365 (3%)]\tLoss: 167.809753\n",
            "Train Epoch: 138 [7680/232365 (3%)]\tLoss: 174.297119\n",
            "Train Epoch: 138 [8960/232365 (4%)]\tLoss: 167.082397\n",
            "Train Epoch: 138 [10240/232365 (4%)]\tLoss: 171.330948\n",
            "Train Epoch: 138 [11520/232365 (5%)]\tLoss: 171.559067\n",
            "Train Epoch: 138 [12800/232365 (6%)]\tLoss: 177.541794\n",
            "Train Epoch: 138 [14080/232365 (6%)]\tLoss: 182.539993\n",
            "Train Epoch: 138 [15360/232365 (7%)]\tLoss: 173.515533\n",
            "Train Epoch: 138 [16640/232365 (7%)]\tLoss: 178.996231\n",
            "Train Epoch: 138 [17920/232365 (8%)]\tLoss: 181.136765\n",
            "Train Epoch: 138 [19200/232365 (8%)]\tLoss: 171.133392\n",
            "Train Epoch: 138 [20480/232365 (9%)]\tLoss: 168.575409\n",
            "Train Epoch: 138 [21760/232365 (9%)]\tLoss: 178.528885\n",
            "Train Epoch: 138 [23040/232365 (10%)]\tLoss: 166.629730\n",
            "Train Epoch: 138 [24320/232365 (10%)]\tLoss: 181.051941\n",
            "Train Epoch: 138 [25600/232365 (11%)]\tLoss: 170.674286\n",
            "Train Epoch: 138 [26880/232365 (12%)]\tLoss: 169.358704\n",
            "Train Epoch: 138 [28160/232365 (12%)]\tLoss: 168.350830\n",
            "Train Epoch: 138 [29440/232365 (13%)]\tLoss: 168.446655\n",
            "Train Epoch: 138 [30720/232365 (13%)]\tLoss: 184.876221\n",
            "Train Epoch: 138 [32000/232365 (14%)]\tLoss: 170.694565\n",
            "Train Epoch: 138 [33280/232365 (14%)]\tLoss: 172.575882\n",
            "Train Epoch: 138 [34560/232365 (15%)]\tLoss: 173.245544\n",
            "Train Epoch: 138 [35840/232365 (15%)]\tLoss: 176.576019\n",
            "Train Epoch: 138 [37120/232365 (16%)]\tLoss: 164.091049\n",
            "Train Epoch: 138 [38400/232365 (17%)]\tLoss: 168.941788\n",
            "Train Epoch: 138 [39680/232365 (17%)]\tLoss: 170.286179\n",
            "Train Epoch: 138 [40960/232365 (18%)]\tLoss: 163.108246\n",
            "Train Epoch: 138 [42240/232365 (18%)]\tLoss: 167.985809\n",
            "Train Epoch: 138 [43520/232365 (19%)]\tLoss: 171.156433\n",
            "Train Epoch: 138 [44800/232365 (19%)]\tLoss: 174.403809\n",
            "Train Epoch: 138 [46080/232365 (20%)]\tLoss: 174.054733\n",
            "Train Epoch: 138 [47360/232365 (20%)]\tLoss: 170.493896\n",
            "Train Epoch: 138 [48640/232365 (21%)]\tLoss: 169.634491\n",
            "Train Epoch: 138 [49920/232365 (21%)]\tLoss: 164.118073\n",
            "Train Epoch: 138 [51200/232365 (22%)]\tLoss: 182.559052\n",
            "Train Epoch: 138 [52480/232365 (23%)]\tLoss: 169.554642\n",
            "Train Epoch: 138 [53760/232365 (23%)]\tLoss: 167.531189\n",
            "Train Epoch: 138 [55040/232365 (24%)]\tLoss: 163.238998\n",
            "Train Epoch: 138 [56320/232365 (24%)]\tLoss: 181.925720\n",
            "Train Epoch: 138 [57600/232365 (25%)]\tLoss: 178.942261\n",
            "Train Epoch: 138 [58880/232365 (25%)]\tLoss: 170.516876\n",
            "Train Epoch: 138 [60160/232365 (26%)]\tLoss: 179.733215\n",
            "Train Epoch: 138 [61440/232365 (26%)]\tLoss: 176.021896\n",
            "Train Epoch: 138 [62720/232365 (27%)]\tLoss: 169.465332\n",
            "Train Epoch: 138 [64000/232365 (28%)]\tLoss: 173.025299\n",
            "Train Epoch: 138 [65280/232365 (28%)]\tLoss: 185.547302\n",
            "Train Epoch: 138 [66560/232365 (29%)]\tLoss: 173.497147\n",
            "Train Epoch: 138 [67840/232365 (29%)]\tLoss: 177.884750\n",
            "Train Epoch: 138 [69120/232365 (30%)]\tLoss: 168.994308\n",
            "Train Epoch: 138 [70400/232365 (30%)]\tLoss: 178.263641\n",
            "Train Epoch: 138 [71680/232365 (31%)]\tLoss: 158.493652\n",
            "Train Epoch: 138 [72960/232365 (31%)]\tLoss: 171.982391\n",
            "Train Epoch: 138 [74240/232365 (32%)]\tLoss: 167.492096\n",
            "Train Epoch: 138 [75520/232365 (32%)]\tLoss: 170.233490\n",
            "Train Epoch: 138 [76800/232365 (33%)]\tLoss: 178.375427\n",
            "Train Epoch: 138 [78080/232365 (34%)]\tLoss: 166.496475\n",
            "Train Epoch: 138 [79360/232365 (34%)]\tLoss: 175.423325\n",
            "Train Epoch: 138 [80640/232365 (35%)]\tLoss: 177.351944\n",
            "Train Epoch: 138 [81920/232365 (35%)]\tLoss: 170.647369\n",
            "Train Epoch: 138 [83200/232365 (36%)]\tLoss: 171.630005\n",
            "Train Epoch: 138 [84480/232365 (36%)]\tLoss: 172.322525\n",
            "Train Epoch: 138 [85760/232365 (37%)]\tLoss: 184.537888\n",
            "Train Epoch: 138 [87040/232365 (37%)]\tLoss: 170.361725\n",
            "Train Epoch: 138 [88320/232365 (38%)]\tLoss: 171.093887\n",
            "Train Epoch: 138 [89600/232365 (39%)]\tLoss: 184.836578\n",
            "Train Epoch: 138 [90880/232365 (39%)]\tLoss: 171.301468\n",
            "Train Epoch: 138 [92160/232365 (40%)]\tLoss: 161.864532\n",
            "Train Epoch: 138 [93440/232365 (40%)]\tLoss: 182.864563\n",
            "Train Epoch: 138 [94720/232365 (41%)]\tLoss: 178.757187\n",
            "Train Epoch: 138 [96000/232365 (41%)]\tLoss: 174.959534\n",
            "Train Epoch: 138 [97280/232365 (42%)]\tLoss: 173.922424\n",
            "Train Epoch: 138 [98560/232365 (42%)]\tLoss: 166.133011\n",
            "Train Epoch: 138 [99840/232365 (43%)]\tLoss: 172.986618\n",
            "Train Epoch: 138 [101120/232365 (44%)]\tLoss: 175.914612\n",
            "Train Epoch: 138 [102400/232365 (44%)]\tLoss: 176.886398\n",
            "Train Epoch: 138 [103680/232365 (45%)]\tLoss: 164.371063\n",
            "Train Epoch: 138 [104960/232365 (45%)]\tLoss: 170.075455\n",
            "Train Epoch: 138 [106240/232365 (46%)]\tLoss: 166.204010\n",
            "Train Epoch: 138 [107520/232365 (46%)]\tLoss: 171.442642\n",
            "Train Epoch: 138 [108800/232365 (47%)]\tLoss: 168.093491\n",
            "Train Epoch: 138 [110080/232365 (47%)]\tLoss: 167.274536\n",
            "Train Epoch: 138 [111360/232365 (48%)]\tLoss: 176.418411\n",
            "Train Epoch: 138 [112640/232365 (48%)]\tLoss: 165.778442\n",
            "Train Epoch: 138 [113920/232365 (49%)]\tLoss: 175.663132\n",
            "Train Epoch: 138 [115200/232365 (50%)]\tLoss: 177.048889\n",
            "Train Epoch: 138 [116480/232365 (50%)]\tLoss: 177.932953\n",
            "Train Epoch: 138 [117760/232365 (51%)]\tLoss: 173.535553\n",
            "Train Epoch: 138 [119040/232365 (51%)]\tLoss: 163.178024\n",
            "Train Epoch: 138 [120320/232365 (52%)]\tLoss: 171.052109\n",
            "Train Epoch: 138 [121600/232365 (52%)]\tLoss: 162.586563\n",
            "Train Epoch: 138 [122880/232365 (53%)]\tLoss: 173.814072\n",
            "Train Epoch: 138 [124160/232365 (53%)]\tLoss: 181.716919\n",
            "Train Epoch: 138 [125440/232365 (54%)]\tLoss: 164.737183\n",
            "Train Epoch: 138 [126720/232365 (55%)]\tLoss: 177.170471\n",
            "Train Epoch: 138 [128000/232365 (55%)]\tLoss: 178.049774\n",
            "Train Epoch: 138 [129280/232365 (56%)]\tLoss: 166.246857\n",
            "Train Epoch: 138 [130560/232365 (56%)]\tLoss: 175.761703\n",
            "Train Epoch: 138 [131840/232365 (57%)]\tLoss: 171.789444\n",
            "Train Epoch: 138 [133120/232365 (57%)]\tLoss: 166.780212\n",
            "Train Epoch: 138 [134400/232365 (58%)]\tLoss: 167.902954\n",
            "Train Epoch: 138 [135680/232365 (58%)]\tLoss: 183.605225\n",
            "Train Epoch: 138 [136960/232365 (59%)]\tLoss: 176.417068\n",
            "Train Epoch: 138 [138240/232365 (59%)]\tLoss: 173.468994\n",
            "Train Epoch: 138 [139520/232365 (60%)]\tLoss: 181.779312\n",
            "Train Epoch: 138 [140800/232365 (61%)]\tLoss: 178.558411\n",
            "Train Epoch: 138 [142080/232365 (61%)]\tLoss: 175.607025\n",
            "Train Epoch: 138 [143360/232365 (62%)]\tLoss: 179.828751\n",
            "Train Epoch: 138 [144640/232365 (62%)]\tLoss: 163.006042\n",
            "Train Epoch: 138 [145920/232365 (63%)]\tLoss: 173.624817\n",
            "Train Epoch: 138 [147200/232365 (63%)]\tLoss: 174.487244\n",
            "Train Epoch: 138 [148480/232365 (64%)]\tLoss: 170.393326\n",
            "Train Epoch: 138 [149760/232365 (64%)]\tLoss: 176.800201\n",
            "Train Epoch: 138 [151040/232365 (65%)]\tLoss: 173.074631\n",
            "Train Epoch: 138 [152320/232365 (66%)]\tLoss: 173.974518\n",
            "Train Epoch: 138 [153600/232365 (66%)]\tLoss: 165.646729\n",
            "Train Epoch: 138 [154880/232365 (67%)]\tLoss: 176.887527\n",
            "Train Epoch: 138 [156160/232365 (67%)]\tLoss: 180.646881\n",
            "Train Epoch: 138 [157440/232365 (68%)]\tLoss: 173.815399\n",
            "Train Epoch: 138 [158720/232365 (68%)]\tLoss: 178.818329\n",
            "Train Epoch: 138 [160000/232365 (69%)]\tLoss: 171.296432\n",
            "Train Epoch: 138 [161280/232365 (69%)]\tLoss: 165.606934\n",
            "Train Epoch: 138 [162560/232365 (70%)]\tLoss: 179.020203\n",
            "Train Epoch: 138 [163840/232365 (70%)]\tLoss: 175.282959\n",
            "Train Epoch: 138 [165120/232365 (71%)]\tLoss: 180.949997\n",
            "Train Epoch: 138 [166400/232365 (72%)]\tLoss: 184.063034\n",
            "Train Epoch: 138 [167680/232365 (72%)]\tLoss: 170.946976\n",
            "Train Epoch: 138 [168960/232365 (73%)]\tLoss: 178.949890\n",
            "Train Epoch: 138 [170240/232365 (73%)]\tLoss: 165.811264\n",
            "Train Epoch: 138 [171520/232365 (74%)]\tLoss: 176.944611\n",
            "Train Epoch: 138 [172800/232365 (74%)]\tLoss: 174.124619\n",
            "Train Epoch: 138 [174080/232365 (75%)]\tLoss: 181.042984\n",
            "Train Epoch: 138 [175360/232365 (75%)]\tLoss: 173.769104\n",
            "Train Epoch: 138 [176640/232365 (76%)]\tLoss: 173.562134\n",
            "Train Epoch: 138 [177920/232365 (77%)]\tLoss: 169.922302\n",
            "Train Epoch: 138 [179200/232365 (77%)]\tLoss: 178.831711\n",
            "Train Epoch: 138 [180480/232365 (78%)]\tLoss: 171.624405\n",
            "Train Epoch: 138 [181760/232365 (78%)]\tLoss: 164.605804\n",
            "Train Epoch: 138 [183040/232365 (79%)]\tLoss: 183.319046\n",
            "Train Epoch: 138 [184320/232365 (79%)]\tLoss: 167.874588\n",
            "Train Epoch: 138 [185600/232365 (80%)]\tLoss: 175.213898\n",
            "Train Epoch: 138 [186880/232365 (80%)]\tLoss: 175.085678\n",
            "Train Epoch: 138 [188160/232365 (81%)]\tLoss: 178.581131\n",
            "Train Epoch: 138 [189440/232365 (81%)]\tLoss: 173.890732\n",
            "Train Epoch: 138 [190720/232365 (82%)]\tLoss: 165.508316\n",
            "Train Epoch: 138 [192000/232365 (83%)]\tLoss: 173.205872\n",
            "Train Epoch: 138 [193280/232365 (83%)]\tLoss: 182.218079\n",
            "Train Epoch: 138 [194560/232365 (84%)]\tLoss: 172.367950\n",
            "Train Epoch: 138 [195840/232365 (84%)]\tLoss: 166.615021\n",
            "Train Epoch: 138 [197120/232365 (85%)]\tLoss: 179.998260\n",
            "Train Epoch: 138 [198400/232365 (85%)]\tLoss: 168.685501\n",
            "Train Epoch: 138 [199680/232365 (86%)]\tLoss: 163.578064\n",
            "Train Epoch: 138 [200960/232365 (86%)]\tLoss: 174.448425\n",
            "Train Epoch: 138 [202240/232365 (87%)]\tLoss: 173.009003\n",
            "Train Epoch: 138 [203520/232365 (88%)]\tLoss: 172.698441\n",
            "Train Epoch: 138 [204800/232365 (88%)]\tLoss: 168.090714\n",
            "Train Epoch: 138 [206080/232365 (89%)]\tLoss: 173.887344\n",
            "Train Epoch: 138 [207360/232365 (89%)]\tLoss: 176.310944\n",
            "Train Epoch: 138 [208640/232365 (90%)]\tLoss: 175.515427\n",
            "Train Epoch: 138 [209920/232365 (90%)]\tLoss: 168.103409\n",
            "Train Epoch: 138 [211200/232365 (91%)]\tLoss: 168.403961\n",
            "Train Epoch: 138 [212480/232365 (91%)]\tLoss: 169.998444\n",
            "Train Epoch: 138 [213760/232365 (92%)]\tLoss: 184.268356\n",
            "Train Epoch: 138 [215040/232365 (93%)]\tLoss: 171.810287\n",
            "Train Epoch: 138 [216320/232365 (93%)]\tLoss: 166.789398\n",
            "Train Epoch: 138 [217600/232365 (94%)]\tLoss: 171.720108\n",
            "Train Epoch: 138 [218880/232365 (94%)]\tLoss: 171.327286\n",
            "Train Epoch: 138 [220160/232365 (95%)]\tLoss: 172.640762\n",
            "Train Epoch: 138 [221440/232365 (95%)]\tLoss: 170.443497\n",
            "Train Epoch: 138 [222720/232365 (96%)]\tLoss: 164.346146\n",
            "Train Epoch: 138 [224000/232365 (96%)]\tLoss: 186.107162\n",
            "Train Epoch: 138 [225280/232365 (97%)]\tLoss: 176.893127\n",
            "Train Epoch: 138 [226560/232365 (97%)]\tLoss: 173.364838\n",
            "Train Epoch: 138 [227840/232365 (98%)]\tLoss: 165.375900\n",
            "Train Epoch: 138 [229120/232365 (99%)]\tLoss: 162.479462\n",
            "Train Epoch: 138 [230400/232365 (99%)]\tLoss: 176.993469\n",
            "Train Epoch: 138 [231680/232365 (100%)]\tLoss: 176.091934\n",
            "====> Epoch: 138 Average loss: 172.4611, Accuracy: 74.24%\n",
            "====> Test set loss: 183.3068, Accuracy: 74.12%\n",
            "Train Epoch: 139 [0/232365 (0%)]\tLoss: 181.163620\n",
            "Train Epoch: 139 [1280/232365 (1%)]\tLoss: 175.402512\n",
            "Train Epoch: 139 [2560/232365 (1%)]\tLoss: 161.008301\n",
            "Train Epoch: 139 [3840/232365 (2%)]\tLoss: 170.981766\n",
            "Train Epoch: 139 [5120/232365 (2%)]\tLoss: 168.816238\n",
            "Train Epoch: 139 [6400/232365 (3%)]\tLoss: 175.231491\n",
            "Train Epoch: 139 [7680/232365 (3%)]\tLoss: 171.755676\n",
            "Train Epoch: 139 [8960/232365 (4%)]\tLoss: 175.801208\n",
            "Train Epoch: 139 [10240/232365 (4%)]\tLoss: 179.544739\n",
            "Train Epoch: 139 [11520/232365 (5%)]\tLoss: 175.076294\n",
            "Train Epoch: 139 [12800/232365 (6%)]\tLoss: 173.146790\n",
            "Train Epoch: 139 [14080/232365 (6%)]\tLoss: 169.098343\n",
            "Train Epoch: 139 [15360/232365 (7%)]\tLoss: 175.883362\n",
            "Train Epoch: 139 [16640/232365 (7%)]\tLoss: 171.372467\n",
            "Train Epoch: 139 [17920/232365 (8%)]\tLoss: 170.854889\n",
            "Train Epoch: 139 [19200/232365 (8%)]\tLoss: 172.782700\n",
            "Train Epoch: 139 [20480/232365 (9%)]\tLoss: 166.783569\n",
            "Train Epoch: 139 [21760/232365 (9%)]\tLoss: 175.186569\n",
            "Train Epoch: 139 [23040/232365 (10%)]\tLoss: 175.025238\n",
            "Train Epoch: 139 [24320/232365 (10%)]\tLoss: 172.853943\n",
            "Train Epoch: 139 [25600/232365 (11%)]\tLoss: 157.738251\n",
            "Train Epoch: 139 [26880/232365 (12%)]\tLoss: 167.960403\n",
            "Train Epoch: 139 [28160/232365 (12%)]\tLoss: 181.411240\n",
            "Train Epoch: 139 [29440/232365 (13%)]\tLoss: 171.433578\n",
            "Train Epoch: 139 [30720/232365 (13%)]\tLoss: 181.666153\n",
            "Train Epoch: 139 [32000/232365 (14%)]\tLoss: 184.390533\n",
            "Train Epoch: 139 [33280/232365 (14%)]\tLoss: 167.698868\n",
            "Train Epoch: 139 [34560/232365 (15%)]\tLoss: 174.025757\n",
            "Train Epoch: 139 [35840/232365 (15%)]\tLoss: 175.289169\n",
            "Train Epoch: 139 [37120/232365 (16%)]\tLoss: 170.816956\n",
            "Train Epoch: 139 [38400/232365 (17%)]\tLoss: 176.893082\n",
            "Train Epoch: 139 [39680/232365 (17%)]\tLoss: 173.043381\n",
            "Train Epoch: 139 [40960/232365 (18%)]\tLoss: 181.589386\n",
            "Train Epoch: 139 [42240/232365 (18%)]\tLoss: 178.184570\n",
            "Train Epoch: 139 [43520/232365 (19%)]\tLoss: 180.015442\n",
            "Train Epoch: 139 [44800/232365 (19%)]\tLoss: 175.089920\n",
            "Train Epoch: 139 [46080/232365 (20%)]\tLoss: 166.052658\n",
            "Train Epoch: 139 [47360/232365 (20%)]\tLoss: 172.726715\n",
            "Train Epoch: 139 [48640/232365 (21%)]\tLoss: 177.324677\n",
            "Train Epoch: 139 [49920/232365 (21%)]\tLoss: 187.850800\n",
            "Train Epoch: 139 [51200/232365 (22%)]\tLoss: 179.312592\n",
            "Train Epoch: 139 [52480/232365 (23%)]\tLoss: 168.463287\n",
            "Train Epoch: 139 [53760/232365 (23%)]\tLoss: 169.563583\n",
            "Train Epoch: 139 [55040/232365 (24%)]\tLoss: 181.231476\n",
            "Train Epoch: 139 [56320/232365 (24%)]\tLoss: 171.136398\n",
            "Train Epoch: 139 [57600/232365 (25%)]\tLoss: 178.200165\n",
            "Train Epoch: 139 [58880/232365 (25%)]\tLoss: 167.768082\n",
            "Train Epoch: 139 [60160/232365 (26%)]\tLoss: 175.494385\n",
            "Train Epoch: 139 [61440/232365 (26%)]\tLoss: 170.189041\n",
            "Train Epoch: 139 [62720/232365 (27%)]\tLoss: 175.056732\n",
            "Train Epoch: 139 [64000/232365 (28%)]\tLoss: 173.177017\n",
            "Train Epoch: 139 [65280/232365 (28%)]\tLoss: 169.426727\n",
            "Train Epoch: 139 [66560/232365 (29%)]\tLoss: 169.407715\n",
            "Train Epoch: 139 [67840/232365 (29%)]\tLoss: 166.924255\n",
            "Train Epoch: 139 [69120/232365 (30%)]\tLoss: 174.609818\n",
            "Train Epoch: 139 [70400/232365 (30%)]\tLoss: 171.648895\n",
            "Train Epoch: 139 [71680/232365 (31%)]\tLoss: 178.178513\n",
            "Train Epoch: 139 [72960/232365 (31%)]\tLoss: 172.833511\n",
            "Train Epoch: 139 [74240/232365 (32%)]\tLoss: 173.608459\n",
            "Train Epoch: 139 [75520/232365 (32%)]\tLoss: 166.037079\n",
            "Train Epoch: 139 [76800/232365 (33%)]\tLoss: 175.017151\n",
            "Train Epoch: 139 [78080/232365 (34%)]\tLoss: 177.106308\n",
            "Train Epoch: 139 [79360/232365 (34%)]\tLoss: 161.069046\n",
            "Train Epoch: 139 [80640/232365 (35%)]\tLoss: 178.221344\n",
            "Train Epoch: 139 [81920/232365 (35%)]\tLoss: 174.810135\n",
            "Train Epoch: 139 [83200/232365 (36%)]\tLoss: 174.955490\n",
            "Train Epoch: 139 [84480/232365 (36%)]\tLoss: 177.826752\n",
            "Train Epoch: 139 [85760/232365 (37%)]\tLoss: 170.932602\n",
            "Train Epoch: 139 [87040/232365 (37%)]\tLoss: 174.924774\n",
            "Train Epoch: 139 [88320/232365 (38%)]\tLoss: 170.314590\n",
            "Train Epoch: 139 [89600/232365 (39%)]\tLoss: 168.542114\n",
            "Train Epoch: 139 [90880/232365 (39%)]\tLoss: 173.308838\n",
            "Train Epoch: 139 [92160/232365 (40%)]\tLoss: 167.934570\n",
            "Train Epoch: 139 [93440/232365 (40%)]\tLoss: 176.753098\n",
            "Train Epoch: 139 [94720/232365 (41%)]\tLoss: 171.070084\n",
            "Train Epoch: 139 [96000/232365 (41%)]\tLoss: 169.915344\n",
            "Train Epoch: 139 [97280/232365 (42%)]\tLoss: 169.381714\n",
            "Train Epoch: 139 [98560/232365 (42%)]\tLoss: 174.531448\n",
            "Train Epoch: 139 [99840/232365 (43%)]\tLoss: 177.984863\n",
            "Train Epoch: 139 [101120/232365 (44%)]\tLoss: 165.331375\n",
            "Train Epoch: 139 [102400/232365 (44%)]\tLoss: 167.384506\n",
            "Train Epoch: 139 [103680/232365 (45%)]\tLoss: 172.640320\n",
            "Train Epoch: 139 [104960/232365 (45%)]\tLoss: 174.422104\n",
            "Train Epoch: 139 [106240/232365 (46%)]\tLoss: 169.587097\n",
            "Train Epoch: 139 [107520/232365 (46%)]\tLoss: 178.240295\n",
            "Train Epoch: 139 [108800/232365 (47%)]\tLoss: 166.833176\n",
            "Train Epoch: 139 [110080/232365 (47%)]\tLoss: 175.343948\n",
            "Train Epoch: 139 [111360/232365 (48%)]\tLoss: 165.296295\n",
            "Train Epoch: 139 [112640/232365 (48%)]\tLoss: 168.039703\n",
            "Train Epoch: 139 [113920/232365 (49%)]\tLoss: 169.126999\n",
            "Train Epoch: 139 [115200/232365 (50%)]\tLoss: 170.510178\n",
            "Train Epoch: 139 [116480/232365 (50%)]\tLoss: 167.209885\n",
            "Train Epoch: 139 [117760/232365 (51%)]\tLoss: 166.113708\n",
            "Train Epoch: 139 [119040/232365 (51%)]\tLoss: 161.624634\n",
            "Train Epoch: 139 [120320/232365 (52%)]\tLoss: 173.956299\n",
            "Train Epoch: 139 [121600/232365 (52%)]\tLoss: 181.508392\n",
            "Train Epoch: 139 [122880/232365 (53%)]\tLoss: 169.346741\n",
            "Train Epoch: 139 [124160/232365 (53%)]\tLoss: 192.361984\n",
            "Train Epoch: 139 [125440/232365 (54%)]\tLoss: 176.003647\n",
            "Train Epoch: 139 [126720/232365 (55%)]\tLoss: 163.330658\n",
            "Train Epoch: 139 [128000/232365 (55%)]\tLoss: 162.566376\n",
            "Train Epoch: 139 [129280/232365 (56%)]\tLoss: 169.424240\n",
            "Train Epoch: 139 [130560/232365 (56%)]\tLoss: 176.898697\n",
            "Train Epoch: 139 [131840/232365 (57%)]\tLoss: 175.477844\n",
            "Train Epoch: 139 [133120/232365 (57%)]\tLoss: 169.731384\n",
            "Train Epoch: 139 [134400/232365 (58%)]\tLoss: 170.370255\n",
            "Train Epoch: 139 [135680/232365 (58%)]\tLoss: 165.247940\n",
            "Train Epoch: 139 [136960/232365 (59%)]\tLoss: 175.641342\n",
            "Train Epoch: 139 [138240/232365 (59%)]\tLoss: 175.289429\n",
            "Train Epoch: 139 [139520/232365 (60%)]\tLoss: 165.775406\n",
            "Train Epoch: 139 [140800/232365 (61%)]\tLoss: 171.397095\n",
            "Train Epoch: 139 [142080/232365 (61%)]\tLoss: 163.657715\n",
            "Train Epoch: 139 [143360/232365 (62%)]\tLoss: 172.256744\n",
            "Train Epoch: 139 [144640/232365 (62%)]\tLoss: 171.835037\n",
            "Train Epoch: 139 [145920/232365 (63%)]\tLoss: 171.664291\n",
            "Train Epoch: 139 [147200/232365 (63%)]\tLoss: 181.060242\n",
            "Train Epoch: 139 [148480/232365 (64%)]\tLoss: 167.355774\n",
            "Train Epoch: 139 [149760/232365 (64%)]\tLoss: 180.872406\n",
            "Train Epoch: 139 [151040/232365 (65%)]\tLoss: 170.394150\n",
            "Train Epoch: 139 [152320/232365 (66%)]\tLoss: 169.095688\n",
            "Train Epoch: 139 [153600/232365 (66%)]\tLoss: 165.771454\n",
            "Train Epoch: 139 [154880/232365 (67%)]\tLoss: 176.954712\n",
            "Train Epoch: 139 [156160/232365 (67%)]\tLoss: 169.596298\n",
            "Train Epoch: 139 [157440/232365 (68%)]\tLoss: 174.340027\n",
            "Train Epoch: 139 [158720/232365 (68%)]\tLoss: 160.445328\n",
            "Train Epoch: 139 [160000/232365 (69%)]\tLoss: 179.328629\n",
            "Train Epoch: 139 [161280/232365 (69%)]\tLoss: 165.818893\n",
            "Train Epoch: 139 [162560/232365 (70%)]\tLoss: 155.444107\n",
            "Train Epoch: 139 [163840/232365 (70%)]\tLoss: 159.203903\n",
            "Train Epoch: 139 [165120/232365 (71%)]\tLoss: 171.310638\n",
            "Train Epoch: 139 [166400/232365 (72%)]\tLoss: 176.916931\n",
            "Train Epoch: 139 [167680/232365 (72%)]\tLoss: 175.450317\n",
            "Train Epoch: 139 [168960/232365 (73%)]\tLoss: 172.689331\n",
            "Train Epoch: 139 [170240/232365 (73%)]\tLoss: 173.650513\n",
            "Train Epoch: 139 [171520/232365 (74%)]\tLoss: 177.643082\n",
            "Train Epoch: 139 [172800/232365 (74%)]\tLoss: 165.680740\n",
            "Train Epoch: 139 [174080/232365 (75%)]\tLoss: 165.372986\n",
            "Train Epoch: 139 [175360/232365 (75%)]\tLoss: 180.988907\n",
            "Train Epoch: 139 [176640/232365 (76%)]\tLoss: 178.579483\n",
            "Train Epoch: 139 [177920/232365 (77%)]\tLoss: 169.953949\n",
            "Train Epoch: 139 [179200/232365 (77%)]\tLoss: 175.745300\n",
            "Train Epoch: 139 [180480/232365 (78%)]\tLoss: 168.254623\n",
            "Train Epoch: 139 [181760/232365 (78%)]\tLoss: 163.161072\n",
            "Train Epoch: 139 [183040/232365 (79%)]\tLoss: 182.364151\n",
            "Train Epoch: 139 [184320/232365 (79%)]\tLoss: 173.280731\n",
            "Train Epoch: 139 [185600/232365 (80%)]\tLoss: 169.158600\n",
            "Train Epoch: 139 [186880/232365 (80%)]\tLoss: 176.671951\n",
            "Train Epoch: 139 [188160/232365 (81%)]\tLoss: 175.348419\n",
            "Train Epoch: 139 [189440/232365 (81%)]\tLoss: 167.536469\n",
            "Train Epoch: 139 [190720/232365 (82%)]\tLoss: 163.514313\n",
            "Train Epoch: 139 [192000/232365 (83%)]\tLoss: 163.717117\n",
            "Train Epoch: 139 [193280/232365 (83%)]\tLoss: 175.238144\n",
            "Train Epoch: 139 [194560/232365 (84%)]\tLoss: 174.634460\n",
            "Train Epoch: 139 [195840/232365 (84%)]\tLoss: 165.189468\n",
            "Train Epoch: 139 [197120/232365 (85%)]\tLoss: 168.043579\n",
            "Train Epoch: 139 [198400/232365 (85%)]\tLoss: 165.301712\n",
            "Train Epoch: 139 [199680/232365 (86%)]\tLoss: 177.906174\n",
            "Train Epoch: 139 [200960/232365 (86%)]\tLoss: 168.184052\n",
            "Train Epoch: 139 [202240/232365 (87%)]\tLoss: 168.873505\n",
            "Train Epoch: 139 [203520/232365 (88%)]\tLoss: 165.402390\n",
            "Train Epoch: 139 [204800/232365 (88%)]\tLoss: 171.384048\n",
            "Train Epoch: 139 [206080/232365 (89%)]\tLoss: 170.677582\n",
            "Train Epoch: 139 [207360/232365 (89%)]\tLoss: 167.831863\n",
            "Train Epoch: 139 [208640/232365 (90%)]\tLoss: 167.319946\n",
            "Train Epoch: 139 [209920/232365 (90%)]\tLoss: 177.628784\n",
            "Train Epoch: 139 [211200/232365 (91%)]\tLoss: 171.615845\n",
            "Train Epoch: 139 [212480/232365 (91%)]\tLoss: 172.008698\n",
            "Train Epoch: 139 [213760/232365 (92%)]\tLoss: 171.263443\n",
            "Train Epoch: 139 [215040/232365 (93%)]\tLoss: 169.740845\n",
            "Train Epoch: 139 [216320/232365 (93%)]\tLoss: 172.128021\n",
            "Train Epoch: 139 [217600/232365 (94%)]\tLoss: 170.301987\n",
            "Train Epoch: 139 [218880/232365 (94%)]\tLoss: 178.710251\n",
            "Train Epoch: 139 [220160/232365 (95%)]\tLoss: 170.540955\n",
            "Train Epoch: 139 [221440/232365 (95%)]\tLoss: 172.312073\n",
            "Train Epoch: 139 [222720/232365 (96%)]\tLoss: 181.579391\n",
            "Train Epoch: 139 [224000/232365 (96%)]\tLoss: 178.098434\n",
            "Train Epoch: 139 [225280/232365 (97%)]\tLoss: 180.529404\n",
            "Train Epoch: 139 [226560/232365 (97%)]\tLoss: 169.201584\n",
            "Train Epoch: 139 [227840/232365 (98%)]\tLoss: 178.411011\n",
            "Train Epoch: 139 [229120/232365 (99%)]\tLoss: 160.851776\n",
            "Train Epoch: 139 [230400/232365 (99%)]\tLoss: 179.081085\n",
            "Train Epoch: 139 [231680/232365 (100%)]\tLoss: 163.036163\n",
            "====> Epoch: 139 Average loss: 172.4784, Accuracy: 74.24%\n",
            "====> Test set loss: 183.3244, Accuracy: 74.11%\n",
            "Train Epoch: 140 [0/232365 (0%)]\tLoss: 180.254379\n",
            "Train Epoch: 140 [1280/232365 (1%)]\tLoss: 176.310959\n",
            "Train Epoch: 140 [2560/232365 (1%)]\tLoss: 177.634430\n",
            "Train Epoch: 140 [3840/232365 (2%)]\tLoss: 168.183960\n",
            "Train Epoch: 140 [5120/232365 (2%)]\tLoss: 170.058838\n",
            "Train Epoch: 140 [6400/232365 (3%)]\tLoss: 182.119232\n",
            "Train Epoch: 140 [7680/232365 (3%)]\tLoss: 177.186096\n",
            "Train Epoch: 140 [8960/232365 (4%)]\tLoss: 175.362411\n",
            "Train Epoch: 140 [10240/232365 (4%)]\tLoss: 172.728149\n",
            "Train Epoch: 140 [11520/232365 (5%)]\tLoss: 180.805023\n",
            "Train Epoch: 140 [12800/232365 (6%)]\tLoss: 177.845032\n",
            "Train Epoch: 140 [14080/232365 (6%)]\tLoss: 176.868622\n",
            "Train Epoch: 140 [15360/232365 (7%)]\tLoss: 173.411530\n",
            "Train Epoch: 140 [16640/232365 (7%)]\tLoss: 175.302856\n",
            "Train Epoch: 140 [17920/232365 (8%)]\tLoss: 166.104950\n",
            "Train Epoch: 140 [19200/232365 (8%)]\tLoss: 174.316193\n",
            "Train Epoch: 140 [20480/232365 (9%)]\tLoss: 176.923325\n",
            "Train Epoch: 140 [21760/232365 (9%)]\tLoss: 173.582520\n",
            "Train Epoch: 140 [23040/232365 (10%)]\tLoss: 174.897964\n",
            "Train Epoch: 140 [24320/232365 (10%)]\tLoss: 162.624405\n",
            "Train Epoch: 140 [25600/232365 (11%)]\tLoss: 177.266663\n",
            "Train Epoch: 140 [26880/232365 (12%)]\tLoss: 180.168640\n",
            "Train Epoch: 140 [28160/232365 (12%)]\tLoss: 161.844498\n",
            "Train Epoch: 140 [29440/232365 (13%)]\tLoss: 161.541641\n",
            "Train Epoch: 140 [30720/232365 (13%)]\tLoss: 170.172256\n",
            "Train Epoch: 140 [32000/232365 (14%)]\tLoss: 171.995926\n",
            "Train Epoch: 140 [33280/232365 (14%)]\tLoss: 163.334991\n",
            "Train Epoch: 140 [34560/232365 (15%)]\tLoss: 176.223236\n",
            "Train Epoch: 140 [35840/232365 (15%)]\tLoss: 173.904068\n",
            "Train Epoch: 140 [37120/232365 (16%)]\tLoss: 164.600754\n",
            "Train Epoch: 140 [38400/232365 (17%)]\tLoss: 165.654816\n",
            "Train Epoch: 140 [39680/232365 (17%)]\tLoss: 172.154282\n",
            "Train Epoch: 140 [40960/232365 (18%)]\tLoss: 164.076904\n",
            "Train Epoch: 140 [42240/232365 (18%)]\tLoss: 177.119934\n",
            "Train Epoch: 140 [43520/232365 (19%)]\tLoss: 172.454407\n",
            "Train Epoch: 140 [44800/232365 (19%)]\tLoss: 177.168304\n",
            "Train Epoch: 140 [46080/232365 (20%)]\tLoss: 184.180634\n",
            "Train Epoch: 140 [47360/232365 (20%)]\tLoss: 165.827347\n",
            "Train Epoch: 140 [48640/232365 (21%)]\tLoss: 174.892838\n",
            "Train Epoch: 140 [49920/232365 (21%)]\tLoss: 180.773178\n",
            "Train Epoch: 140 [51200/232365 (22%)]\tLoss: 165.357925\n",
            "Train Epoch: 140 [52480/232365 (23%)]\tLoss: 186.620316\n",
            "Train Epoch: 140 [53760/232365 (23%)]\tLoss: 164.190475\n",
            "Train Epoch: 140 [55040/232365 (24%)]\tLoss: 179.929688\n",
            "Train Epoch: 140 [56320/232365 (24%)]\tLoss: 175.009842\n",
            "Train Epoch: 140 [57600/232365 (25%)]\tLoss: 166.976379\n",
            "Train Epoch: 140 [58880/232365 (25%)]\tLoss: 170.480606\n",
            "Train Epoch: 140 [60160/232365 (26%)]\tLoss: 166.793640\n",
            "Train Epoch: 140 [61440/232365 (26%)]\tLoss: 166.765625\n",
            "Train Epoch: 140 [62720/232365 (27%)]\tLoss: 180.563599\n",
            "Train Epoch: 140 [64000/232365 (28%)]\tLoss: 173.723984\n",
            "Train Epoch: 140 [65280/232365 (28%)]\tLoss: 177.448730\n",
            "Train Epoch: 140 [66560/232365 (29%)]\tLoss: 172.597885\n",
            "Train Epoch: 140 [67840/232365 (29%)]\tLoss: 164.378311\n",
            "Train Epoch: 140 [69120/232365 (30%)]\tLoss: 174.577469\n",
            "Train Epoch: 140 [70400/232365 (30%)]\tLoss: 162.411758\n",
            "Train Epoch: 140 [71680/232365 (31%)]\tLoss: 164.354950\n",
            "Train Epoch: 140 [72960/232365 (31%)]\tLoss: 171.687332\n",
            "Train Epoch: 140 [74240/232365 (32%)]\tLoss: 177.007858\n",
            "Train Epoch: 140 [75520/232365 (32%)]\tLoss: 181.954468\n",
            "Train Epoch: 140 [76800/232365 (33%)]\tLoss: 167.402527\n",
            "Train Epoch: 140 [78080/232365 (34%)]\tLoss: 169.374084\n",
            "Train Epoch: 140 [79360/232365 (34%)]\tLoss: 166.564484\n",
            "Train Epoch: 140 [80640/232365 (35%)]\tLoss: 178.269424\n",
            "Train Epoch: 140 [81920/232365 (35%)]\tLoss: 169.913116\n",
            "Train Epoch: 140 [83200/232365 (36%)]\tLoss: 177.813644\n",
            "Train Epoch: 140 [84480/232365 (36%)]\tLoss: 164.689774\n",
            "Train Epoch: 140 [85760/232365 (37%)]\tLoss: 171.068863\n",
            "Train Epoch: 140 [87040/232365 (37%)]\tLoss: 172.786530\n",
            "Train Epoch: 140 [88320/232365 (38%)]\tLoss: 170.761200\n",
            "Train Epoch: 140 [89600/232365 (39%)]\tLoss: 167.265839\n",
            "Train Epoch: 140 [90880/232365 (39%)]\tLoss: 166.759781\n",
            "Train Epoch: 140 [92160/232365 (40%)]\tLoss: 186.020813\n",
            "Train Epoch: 140 [93440/232365 (40%)]\tLoss: 163.744843\n",
            "Train Epoch: 140 [94720/232365 (41%)]\tLoss: 176.331696\n",
            "Train Epoch: 140 [96000/232365 (41%)]\tLoss: 178.189392\n",
            "Train Epoch: 140 [97280/232365 (42%)]\tLoss: 167.787918\n",
            "Train Epoch: 140 [98560/232365 (42%)]\tLoss: 172.139709\n",
            "Train Epoch: 140 [99840/232365 (43%)]\tLoss: 165.845032\n",
            "Train Epoch: 140 [101120/232365 (44%)]\tLoss: 178.852692\n",
            "Train Epoch: 140 [102400/232365 (44%)]\tLoss: 178.384415\n",
            "Train Epoch: 140 [103680/232365 (45%)]\tLoss: 167.075882\n",
            "Train Epoch: 140 [104960/232365 (45%)]\tLoss: 160.291473\n",
            "Train Epoch: 140 [106240/232365 (46%)]\tLoss: 178.972153\n",
            "Train Epoch: 140 [107520/232365 (46%)]\tLoss: 171.558640\n",
            "Train Epoch: 140 [108800/232365 (47%)]\tLoss: 174.415131\n",
            "Train Epoch: 140 [110080/232365 (47%)]\tLoss: 168.465057\n",
            "Train Epoch: 140 [111360/232365 (48%)]\tLoss: 181.944656\n",
            "Train Epoch: 140 [112640/232365 (48%)]\tLoss: 167.374237\n",
            "Train Epoch: 140 [113920/232365 (49%)]\tLoss: 175.406616\n",
            "Train Epoch: 140 [115200/232365 (50%)]\tLoss: 179.161270\n",
            "Train Epoch: 140 [116480/232365 (50%)]\tLoss: 167.332352\n",
            "Train Epoch: 140 [117760/232365 (51%)]\tLoss: 191.979172\n",
            "Train Epoch: 140 [119040/232365 (51%)]\tLoss: 176.057022\n",
            "Train Epoch: 140 [120320/232365 (52%)]\tLoss: 174.806213\n",
            "Train Epoch: 140 [121600/232365 (52%)]\tLoss: 170.088654\n",
            "Train Epoch: 140 [122880/232365 (53%)]\tLoss: 171.632874\n",
            "Train Epoch: 140 [124160/232365 (53%)]\tLoss: 174.189026\n",
            "Train Epoch: 140 [125440/232365 (54%)]\tLoss: 179.874756\n",
            "Train Epoch: 140 [126720/232365 (55%)]\tLoss: 177.036499\n",
            "Train Epoch: 140 [128000/232365 (55%)]\tLoss: 168.883087\n",
            "Train Epoch: 140 [129280/232365 (56%)]\tLoss: 169.247055\n",
            "Train Epoch: 140 [130560/232365 (56%)]\tLoss: 168.056641\n",
            "Train Epoch: 140 [131840/232365 (57%)]\tLoss: 174.554047\n",
            "Train Epoch: 140 [133120/232365 (57%)]\tLoss: 172.041061\n",
            "Train Epoch: 140 [134400/232365 (58%)]\tLoss: 166.261139\n",
            "Train Epoch: 140 [135680/232365 (58%)]\tLoss: 173.282852\n",
            "Train Epoch: 140 [136960/232365 (59%)]\tLoss: 168.594879\n",
            "Train Epoch: 140 [138240/232365 (59%)]\tLoss: 163.290146\n",
            "Train Epoch: 140 [139520/232365 (60%)]\tLoss: 169.519989\n",
            "Train Epoch: 140 [140800/232365 (61%)]\tLoss: 179.219849\n",
            "Train Epoch: 140 [142080/232365 (61%)]\tLoss: 173.293579\n",
            "Train Epoch: 140 [143360/232365 (62%)]\tLoss: 173.017883\n",
            "Train Epoch: 140 [144640/232365 (62%)]\tLoss: 166.794769\n",
            "Train Epoch: 140 [145920/232365 (63%)]\tLoss: 163.128616\n",
            "Train Epoch: 140 [147200/232365 (63%)]\tLoss: 164.407669\n",
            "Train Epoch: 140 [148480/232365 (64%)]\tLoss: 169.667648\n",
            "Train Epoch: 140 [149760/232365 (64%)]\tLoss: 172.015259\n",
            "Train Epoch: 140 [151040/232365 (65%)]\tLoss: 174.762177\n",
            "Train Epoch: 140 [152320/232365 (66%)]\tLoss: 176.304535\n",
            "Train Epoch: 140 [153600/232365 (66%)]\tLoss: 170.509094\n",
            "Train Epoch: 140 [154880/232365 (67%)]\tLoss: 175.989563\n",
            "Train Epoch: 140 [156160/232365 (67%)]\tLoss: 167.410019\n",
            "Train Epoch: 140 [157440/232365 (68%)]\tLoss: 170.613419\n",
            "Train Epoch: 140 [158720/232365 (68%)]\tLoss: 162.223282\n",
            "Train Epoch: 140 [160000/232365 (69%)]\tLoss: 172.227478\n",
            "Train Epoch: 140 [161280/232365 (69%)]\tLoss: 173.241180\n",
            "Train Epoch: 140 [162560/232365 (70%)]\tLoss: 165.573502\n",
            "Train Epoch: 140 [163840/232365 (70%)]\tLoss: 168.940308\n",
            "Train Epoch: 140 [165120/232365 (71%)]\tLoss: 176.389160\n",
            "Train Epoch: 140 [166400/232365 (72%)]\tLoss: 166.557343\n",
            "Train Epoch: 140 [167680/232365 (72%)]\tLoss: 177.804108\n",
            "Train Epoch: 140 [168960/232365 (73%)]\tLoss: 165.121170\n",
            "Train Epoch: 140 [170240/232365 (73%)]\tLoss: 173.297913\n",
            "Train Epoch: 140 [171520/232365 (74%)]\tLoss: 175.702072\n",
            "Train Epoch: 140 [172800/232365 (74%)]\tLoss: 167.839996\n",
            "Train Epoch: 140 [174080/232365 (75%)]\tLoss: 168.428635\n",
            "Train Epoch: 140 [175360/232365 (75%)]\tLoss: 176.116119\n",
            "Train Epoch: 140 [176640/232365 (76%)]\tLoss: 177.910461\n",
            "Train Epoch: 140 [177920/232365 (77%)]\tLoss: 168.977509\n",
            "Train Epoch: 140 [179200/232365 (77%)]\tLoss: 159.921921\n",
            "Train Epoch: 140 [180480/232365 (78%)]\tLoss: 170.038849\n",
            "Train Epoch: 140 [181760/232365 (78%)]\tLoss: 169.452835\n",
            "Train Epoch: 140 [183040/232365 (79%)]\tLoss: 174.322098\n",
            "Train Epoch: 140 [184320/232365 (79%)]\tLoss: 168.929886\n",
            "Train Epoch: 140 [185600/232365 (80%)]\tLoss: 167.398422\n",
            "Train Epoch: 140 [186880/232365 (80%)]\tLoss: 182.124741\n",
            "Train Epoch: 140 [188160/232365 (81%)]\tLoss: 170.000153\n",
            "Train Epoch: 140 [189440/232365 (81%)]\tLoss: 170.180603\n",
            "Train Epoch: 140 [190720/232365 (82%)]\tLoss: 177.737839\n",
            "Train Epoch: 140 [192000/232365 (83%)]\tLoss: 173.788132\n",
            "Train Epoch: 140 [193280/232365 (83%)]\tLoss: 184.006531\n",
            "Train Epoch: 140 [194560/232365 (84%)]\tLoss: 171.290710\n",
            "Train Epoch: 140 [195840/232365 (84%)]\tLoss: 179.505249\n",
            "Train Epoch: 140 [197120/232365 (85%)]\tLoss: 174.624817\n",
            "Train Epoch: 140 [198400/232365 (85%)]\tLoss: 170.994171\n",
            "Train Epoch: 140 [199680/232365 (86%)]\tLoss: 176.577377\n",
            "Train Epoch: 140 [200960/232365 (86%)]\tLoss: 182.025269\n",
            "Train Epoch: 140 [202240/232365 (87%)]\tLoss: 177.235199\n",
            "Train Epoch: 140 [203520/232365 (88%)]\tLoss: 172.337921\n",
            "Train Epoch: 140 [204800/232365 (88%)]\tLoss: 172.263916\n",
            "Train Epoch: 140 [206080/232365 (89%)]\tLoss: 175.307953\n",
            "Train Epoch: 140 [207360/232365 (89%)]\tLoss: 170.509140\n",
            "Train Epoch: 140 [208640/232365 (90%)]\tLoss: 163.646469\n",
            "Train Epoch: 140 [209920/232365 (90%)]\tLoss: 174.184006\n",
            "Train Epoch: 140 [211200/232365 (91%)]\tLoss: 176.094528\n",
            "Train Epoch: 140 [212480/232365 (91%)]\tLoss: 177.571701\n",
            "Train Epoch: 140 [213760/232365 (92%)]\tLoss: 169.013046\n",
            "Train Epoch: 140 [215040/232365 (93%)]\tLoss: 184.314636\n",
            "Train Epoch: 140 [216320/232365 (93%)]\tLoss: 176.635315\n",
            "Train Epoch: 140 [217600/232365 (94%)]\tLoss: 180.204865\n",
            "Train Epoch: 140 [218880/232365 (94%)]\tLoss: 164.606873\n",
            "Train Epoch: 140 [220160/232365 (95%)]\tLoss: 171.752304\n",
            "Train Epoch: 140 [221440/232365 (95%)]\tLoss: 170.210526\n",
            "Train Epoch: 140 [222720/232365 (96%)]\tLoss: 177.015778\n",
            "Train Epoch: 140 [224000/232365 (96%)]\tLoss: 175.304550\n",
            "Train Epoch: 140 [225280/232365 (97%)]\tLoss: 170.454865\n",
            "Train Epoch: 140 [226560/232365 (97%)]\tLoss: 171.188263\n",
            "Train Epoch: 140 [227840/232365 (98%)]\tLoss: 165.559692\n",
            "Train Epoch: 140 [229120/232365 (99%)]\tLoss: 179.571121\n",
            "Train Epoch: 140 [230400/232365 (99%)]\tLoss: 175.704407\n",
            "Train Epoch: 140 [231680/232365 (100%)]\tLoss: 180.836609\n",
            "====> Epoch: 140 Average loss: 172.4925, Accuracy: 74.24%\n",
            "====> Test set loss: 183.3542, Accuracy: 74.11%\n",
            "Train Epoch: 141 [0/232365 (0%)]\tLoss: 181.604248\n",
            "Train Epoch: 141 [1280/232365 (1%)]\tLoss: 182.402740\n",
            "Train Epoch: 141 [2560/232365 (1%)]\tLoss: 175.831467\n",
            "Train Epoch: 141 [3840/232365 (2%)]\tLoss: 176.015625\n",
            "Train Epoch: 141 [5120/232365 (2%)]\tLoss: 166.544861\n",
            "Train Epoch: 141 [6400/232365 (3%)]\tLoss: 165.677444\n",
            "Train Epoch: 141 [7680/232365 (3%)]\tLoss: 174.975769\n",
            "Train Epoch: 141 [8960/232365 (4%)]\tLoss: 174.460068\n",
            "Train Epoch: 141 [10240/232365 (4%)]\tLoss: 173.275391\n",
            "Train Epoch: 141 [11520/232365 (5%)]\tLoss: 174.254532\n",
            "Train Epoch: 141 [12800/232365 (6%)]\tLoss: 168.267334\n",
            "Train Epoch: 141 [14080/232365 (6%)]\tLoss: 174.683685\n",
            "Train Epoch: 141 [15360/232365 (7%)]\tLoss: 180.183426\n",
            "Train Epoch: 141 [16640/232365 (7%)]\tLoss: 181.188889\n",
            "Train Epoch: 141 [17920/232365 (8%)]\tLoss: 172.153992\n",
            "Train Epoch: 141 [19200/232365 (8%)]\tLoss: 163.757782\n",
            "Train Epoch: 141 [20480/232365 (9%)]\tLoss: 168.853043\n",
            "Train Epoch: 141 [21760/232365 (9%)]\tLoss: 173.914124\n",
            "Train Epoch: 141 [23040/232365 (10%)]\tLoss: 180.437408\n",
            "Train Epoch: 141 [24320/232365 (10%)]\tLoss: 163.386719\n",
            "Train Epoch: 141 [25600/232365 (11%)]\tLoss: 171.947769\n",
            "Train Epoch: 141 [26880/232365 (12%)]\tLoss: 179.555145\n",
            "Train Epoch: 141 [28160/232365 (12%)]\tLoss: 173.849442\n",
            "Train Epoch: 141 [29440/232365 (13%)]\tLoss: 176.484665\n",
            "Train Epoch: 141 [30720/232365 (13%)]\tLoss: 171.891785\n",
            "Train Epoch: 141 [32000/232365 (14%)]\tLoss: 163.461411\n",
            "Train Epoch: 141 [33280/232365 (14%)]\tLoss: 178.956543\n",
            "Train Epoch: 141 [34560/232365 (15%)]\tLoss: 181.487488\n",
            "Train Epoch: 141 [35840/232365 (15%)]\tLoss: 170.412140\n",
            "Train Epoch: 141 [37120/232365 (16%)]\tLoss: 175.621872\n",
            "Train Epoch: 141 [38400/232365 (17%)]\tLoss: 171.496384\n",
            "Train Epoch: 141 [39680/232365 (17%)]\tLoss: 174.179001\n",
            "Train Epoch: 141 [40960/232365 (18%)]\tLoss: 176.066010\n",
            "Train Epoch: 141 [42240/232365 (18%)]\tLoss: 177.246262\n",
            "Train Epoch: 141 [43520/232365 (19%)]\tLoss: 163.349136\n",
            "Train Epoch: 141 [44800/232365 (19%)]\tLoss: 174.896713\n",
            "Train Epoch: 141 [46080/232365 (20%)]\tLoss: 173.591690\n",
            "Train Epoch: 141 [47360/232365 (20%)]\tLoss: 186.980316\n",
            "Train Epoch: 141 [48640/232365 (21%)]\tLoss: 171.361588\n",
            "Train Epoch: 141 [49920/232365 (21%)]\tLoss: 170.238739\n",
            "Train Epoch: 141 [51200/232365 (22%)]\tLoss: 177.495331\n",
            "Train Epoch: 141 [52480/232365 (23%)]\tLoss: 168.745880\n",
            "Train Epoch: 141 [53760/232365 (23%)]\tLoss: 184.139404\n",
            "Train Epoch: 141 [55040/232365 (24%)]\tLoss: 173.619659\n",
            "Train Epoch: 141 [56320/232365 (24%)]\tLoss: 175.167252\n",
            "Train Epoch: 141 [57600/232365 (25%)]\tLoss: 172.571075\n",
            "Train Epoch: 141 [58880/232365 (25%)]\tLoss: 181.456238\n",
            "Train Epoch: 141 [60160/232365 (26%)]\tLoss: 170.982941\n",
            "Train Epoch: 141 [61440/232365 (26%)]\tLoss: 166.281281\n",
            "Train Epoch: 141 [62720/232365 (27%)]\tLoss: 178.459320\n",
            "Train Epoch: 141 [64000/232365 (28%)]\tLoss: 177.552231\n",
            "Train Epoch: 141 [65280/232365 (28%)]\tLoss: 176.823883\n",
            "Train Epoch: 141 [66560/232365 (29%)]\tLoss: 176.349152\n",
            "Train Epoch: 141 [67840/232365 (29%)]\tLoss: 168.036697\n",
            "Train Epoch: 141 [69120/232365 (30%)]\tLoss: 161.869507\n",
            "Train Epoch: 141 [70400/232365 (30%)]\tLoss: 174.413605\n",
            "Train Epoch: 141 [71680/232365 (31%)]\tLoss: 173.055771\n",
            "Train Epoch: 141 [72960/232365 (31%)]\tLoss: 174.317566\n",
            "Train Epoch: 141 [74240/232365 (32%)]\tLoss: 172.929642\n",
            "Train Epoch: 141 [75520/232365 (32%)]\tLoss: 190.615051\n",
            "Train Epoch: 141 [76800/232365 (33%)]\tLoss: 162.614044\n",
            "Train Epoch: 141 [78080/232365 (34%)]\tLoss: 179.260223\n",
            "Train Epoch: 141 [79360/232365 (34%)]\tLoss: 171.337219\n",
            "Train Epoch: 141 [80640/232365 (35%)]\tLoss: 171.237427\n",
            "Train Epoch: 141 [81920/232365 (35%)]\tLoss: 177.538422\n",
            "Train Epoch: 141 [83200/232365 (36%)]\tLoss: 169.717560\n",
            "Train Epoch: 141 [84480/232365 (36%)]\tLoss: 170.264542\n",
            "Train Epoch: 141 [85760/232365 (37%)]\tLoss: 169.362503\n",
            "Train Epoch: 141 [87040/232365 (37%)]\tLoss: 171.887894\n",
            "Train Epoch: 141 [88320/232365 (38%)]\tLoss: 173.947220\n",
            "Train Epoch: 141 [89600/232365 (39%)]\tLoss: 171.046280\n",
            "Train Epoch: 141 [90880/232365 (39%)]\tLoss: 181.689102\n",
            "Train Epoch: 141 [92160/232365 (40%)]\tLoss: 179.156219\n",
            "Train Epoch: 141 [93440/232365 (40%)]\tLoss: 170.083450\n",
            "Train Epoch: 141 [94720/232365 (41%)]\tLoss: 181.244263\n",
            "Train Epoch: 141 [96000/232365 (41%)]\tLoss: 158.003876\n",
            "Train Epoch: 141 [97280/232365 (42%)]\tLoss: 174.614304\n",
            "Train Epoch: 141 [98560/232365 (42%)]\tLoss: 169.877899\n",
            "Train Epoch: 141 [99840/232365 (43%)]\tLoss: 177.313965\n",
            "Train Epoch: 141 [101120/232365 (44%)]\tLoss: 173.119537\n",
            "Train Epoch: 141 [102400/232365 (44%)]\tLoss: 169.856354\n",
            "Train Epoch: 141 [103680/232365 (45%)]\tLoss: 176.651505\n",
            "Train Epoch: 141 [104960/232365 (45%)]\tLoss: 173.077789\n",
            "Train Epoch: 141 [106240/232365 (46%)]\tLoss: 168.774231\n",
            "Train Epoch: 141 [107520/232365 (46%)]\tLoss: 174.289948\n",
            "Train Epoch: 141 [108800/232365 (47%)]\tLoss: 176.685532\n",
            "Train Epoch: 141 [110080/232365 (47%)]\tLoss: 176.788437\n",
            "Train Epoch: 141 [111360/232365 (48%)]\tLoss: 181.456055\n",
            "Train Epoch: 141 [112640/232365 (48%)]\tLoss: 167.043488\n",
            "Train Epoch: 141 [113920/232365 (49%)]\tLoss: 173.471970\n",
            "Train Epoch: 141 [115200/232365 (50%)]\tLoss: 164.080002\n",
            "Train Epoch: 141 [116480/232365 (50%)]\tLoss: 173.550339\n",
            "Train Epoch: 141 [117760/232365 (51%)]\tLoss: 174.639923\n",
            "Train Epoch: 141 [119040/232365 (51%)]\tLoss: 166.144211\n",
            "Train Epoch: 141 [120320/232365 (52%)]\tLoss: 172.739212\n",
            "Train Epoch: 141 [121600/232365 (52%)]\tLoss: 170.739868\n",
            "Train Epoch: 141 [122880/232365 (53%)]\tLoss: 168.021576\n",
            "Train Epoch: 141 [124160/232365 (53%)]\tLoss: 170.623047\n",
            "Train Epoch: 141 [125440/232365 (54%)]\tLoss: 168.853958\n",
            "Train Epoch: 141 [126720/232365 (55%)]\tLoss: 181.014221\n",
            "Train Epoch: 141 [128000/232365 (55%)]\tLoss: 170.887314\n",
            "Train Epoch: 141 [129280/232365 (56%)]\tLoss: 169.383224\n",
            "Train Epoch: 141 [130560/232365 (56%)]\tLoss: 173.263000\n",
            "Train Epoch: 141 [131840/232365 (57%)]\tLoss: 172.485519\n",
            "Train Epoch: 141 [133120/232365 (57%)]\tLoss: 172.061340\n",
            "Train Epoch: 141 [134400/232365 (58%)]\tLoss: 179.757675\n",
            "Train Epoch: 141 [135680/232365 (58%)]\tLoss: 165.241333\n",
            "Train Epoch: 141 [136960/232365 (59%)]\tLoss: 180.401688\n",
            "Train Epoch: 141 [138240/232365 (59%)]\tLoss: 171.354584\n",
            "Train Epoch: 141 [139520/232365 (60%)]\tLoss: 171.501144\n",
            "Train Epoch: 141 [140800/232365 (61%)]\tLoss: 176.665710\n",
            "Train Epoch: 141 [142080/232365 (61%)]\tLoss: 173.965240\n",
            "Train Epoch: 141 [143360/232365 (62%)]\tLoss: 173.981506\n",
            "Train Epoch: 141 [144640/232365 (62%)]\tLoss: 169.593491\n",
            "Train Epoch: 141 [145920/232365 (63%)]\tLoss: 163.447876\n",
            "Train Epoch: 141 [147200/232365 (63%)]\tLoss: 173.276596\n",
            "Train Epoch: 141 [148480/232365 (64%)]\tLoss: 167.468658\n",
            "Train Epoch: 141 [149760/232365 (64%)]\tLoss: 173.388336\n",
            "Train Epoch: 141 [151040/232365 (65%)]\tLoss: 190.060394\n",
            "Train Epoch: 141 [152320/232365 (66%)]\tLoss: 165.838821\n",
            "Train Epoch: 141 [153600/232365 (66%)]\tLoss: 174.988739\n",
            "Train Epoch: 141 [154880/232365 (67%)]\tLoss: 170.804596\n",
            "Train Epoch: 141 [156160/232365 (67%)]\tLoss: 161.867310\n",
            "Train Epoch: 141 [157440/232365 (68%)]\tLoss: 171.367477\n",
            "Train Epoch: 141 [158720/232365 (68%)]\tLoss: 167.618958\n",
            "Train Epoch: 141 [160000/232365 (69%)]\tLoss: 178.598724\n",
            "Train Epoch: 141 [161280/232365 (69%)]\tLoss: 173.102386\n",
            "Train Epoch: 141 [162560/232365 (70%)]\tLoss: 164.994492\n",
            "Train Epoch: 141 [163840/232365 (70%)]\tLoss: 180.975754\n",
            "Train Epoch: 141 [165120/232365 (71%)]\tLoss: 176.166534\n",
            "Train Epoch: 141 [166400/232365 (72%)]\tLoss: 161.686890\n",
            "Train Epoch: 141 [167680/232365 (72%)]\tLoss: 177.820908\n",
            "Train Epoch: 141 [168960/232365 (73%)]\tLoss: 183.913010\n",
            "Train Epoch: 141 [170240/232365 (73%)]\tLoss: 175.037506\n",
            "Train Epoch: 141 [171520/232365 (74%)]\tLoss: 170.868134\n",
            "Train Epoch: 141 [172800/232365 (74%)]\tLoss: 171.599686\n",
            "Train Epoch: 141 [174080/232365 (75%)]\tLoss: 179.295227\n",
            "Train Epoch: 141 [175360/232365 (75%)]\tLoss: 164.469086\n",
            "Train Epoch: 141 [176640/232365 (76%)]\tLoss: 173.407501\n",
            "Train Epoch: 141 [177920/232365 (77%)]\tLoss: 181.001434\n",
            "Train Epoch: 141 [179200/232365 (77%)]\tLoss: 159.209473\n",
            "Train Epoch: 141 [180480/232365 (78%)]\tLoss: 182.488617\n",
            "Train Epoch: 141 [181760/232365 (78%)]\tLoss: 175.630646\n",
            "Train Epoch: 141 [183040/232365 (79%)]\tLoss: 191.280518\n",
            "Train Epoch: 141 [184320/232365 (79%)]\tLoss: 175.109894\n",
            "Train Epoch: 141 [185600/232365 (80%)]\tLoss: 174.872559\n",
            "Train Epoch: 141 [186880/232365 (80%)]\tLoss: 166.695328\n",
            "Train Epoch: 141 [188160/232365 (81%)]\tLoss: 172.208328\n",
            "Train Epoch: 141 [189440/232365 (81%)]\tLoss: 166.790314\n",
            "Train Epoch: 141 [190720/232365 (82%)]\tLoss: 175.779449\n",
            "Train Epoch: 141 [192000/232365 (83%)]\tLoss: 165.254883\n",
            "Train Epoch: 141 [193280/232365 (83%)]\tLoss: 176.768875\n",
            "Train Epoch: 141 [194560/232365 (84%)]\tLoss: 183.760681\n",
            "Train Epoch: 141 [195840/232365 (84%)]\tLoss: 179.332169\n",
            "Train Epoch: 141 [197120/232365 (85%)]\tLoss: 177.948441\n",
            "Train Epoch: 141 [198400/232365 (85%)]\tLoss: 169.237793\n",
            "Train Epoch: 141 [199680/232365 (86%)]\tLoss: 177.836731\n",
            "Train Epoch: 141 [200960/232365 (86%)]\tLoss: 171.220062\n",
            "Train Epoch: 141 [202240/232365 (87%)]\tLoss: 180.877548\n",
            "Train Epoch: 141 [203520/232365 (88%)]\tLoss: 179.607040\n",
            "Train Epoch: 141 [204800/232365 (88%)]\tLoss: 170.994583\n",
            "Train Epoch: 141 [206080/232365 (89%)]\tLoss: 163.785461\n",
            "Train Epoch: 141 [207360/232365 (89%)]\tLoss: 172.026749\n",
            "Train Epoch: 141 [208640/232365 (90%)]\tLoss: 172.623550\n",
            "Train Epoch: 141 [209920/232365 (90%)]\tLoss: 172.526855\n",
            "Train Epoch: 141 [211200/232365 (91%)]\tLoss: 169.318787\n",
            "Train Epoch: 141 [212480/232365 (91%)]\tLoss: 164.397797\n",
            "Train Epoch: 141 [213760/232365 (92%)]\tLoss: 166.285904\n",
            "Train Epoch: 141 [215040/232365 (93%)]\tLoss: 167.923294\n",
            "Train Epoch: 141 [216320/232365 (93%)]\tLoss: 171.876617\n",
            "Train Epoch: 141 [217600/232365 (94%)]\tLoss: 179.905060\n",
            "Train Epoch: 141 [218880/232365 (94%)]\tLoss: 166.788086\n",
            "Train Epoch: 141 [220160/232365 (95%)]\tLoss: 176.515930\n",
            "Train Epoch: 141 [221440/232365 (95%)]\tLoss: 175.706116\n",
            "Train Epoch: 141 [222720/232365 (96%)]\tLoss: 171.946609\n",
            "Train Epoch: 141 [224000/232365 (96%)]\tLoss: 168.686844\n",
            "Train Epoch: 141 [225280/232365 (97%)]\tLoss: 167.283478\n",
            "Train Epoch: 141 [226560/232365 (97%)]\tLoss: 172.040512\n",
            "Train Epoch: 141 [227840/232365 (98%)]\tLoss: 179.897400\n",
            "Train Epoch: 141 [229120/232365 (99%)]\tLoss: 170.011932\n",
            "Train Epoch: 141 [230400/232365 (99%)]\tLoss: 166.566895\n",
            "Train Epoch: 141 [231680/232365 (100%)]\tLoss: 166.089645\n",
            "====> Epoch: 141 Average loss: 172.4889, Accuracy: 74.24%\n",
            "====> Test set loss: 183.1945, Accuracy: 74.12%\n",
            "Train Epoch: 142 [0/232365 (0%)]\tLoss: 172.377182\n",
            "Train Epoch: 142 [1280/232365 (1%)]\tLoss: 178.360779\n",
            "Train Epoch: 142 [2560/232365 (1%)]\tLoss: 169.050842\n",
            "Train Epoch: 142 [3840/232365 (2%)]\tLoss: 168.241989\n",
            "Train Epoch: 142 [5120/232365 (2%)]\tLoss: 176.757507\n",
            "Train Epoch: 142 [6400/232365 (3%)]\tLoss: 172.021622\n",
            "Train Epoch: 142 [7680/232365 (3%)]\tLoss: 179.204987\n",
            "Train Epoch: 142 [8960/232365 (4%)]\tLoss: 168.399521\n",
            "Train Epoch: 142 [10240/232365 (4%)]\tLoss: 177.027924\n",
            "Train Epoch: 142 [11520/232365 (5%)]\tLoss: 175.216980\n",
            "Train Epoch: 142 [12800/232365 (6%)]\tLoss: 172.270996\n",
            "Train Epoch: 142 [14080/232365 (6%)]\tLoss: 171.468262\n",
            "Train Epoch: 142 [15360/232365 (7%)]\tLoss: 168.076035\n",
            "Train Epoch: 142 [16640/232365 (7%)]\tLoss: 175.413010\n",
            "Train Epoch: 142 [17920/232365 (8%)]\tLoss: 165.787750\n",
            "Train Epoch: 142 [19200/232365 (8%)]\tLoss: 179.597488\n",
            "Train Epoch: 142 [20480/232365 (9%)]\tLoss: 178.699463\n",
            "Train Epoch: 142 [21760/232365 (9%)]\tLoss: 171.351379\n",
            "Train Epoch: 142 [23040/232365 (10%)]\tLoss: 171.171173\n",
            "Train Epoch: 142 [24320/232365 (10%)]\tLoss: 168.775681\n",
            "Train Epoch: 142 [25600/232365 (11%)]\tLoss: 172.034119\n",
            "Train Epoch: 142 [26880/232365 (12%)]\tLoss: 172.630264\n",
            "Train Epoch: 142 [28160/232365 (12%)]\tLoss: 173.652283\n",
            "Train Epoch: 142 [29440/232365 (13%)]\tLoss: 177.539200\n",
            "Train Epoch: 142 [30720/232365 (13%)]\tLoss: 171.212631\n",
            "Train Epoch: 142 [32000/232365 (14%)]\tLoss: 169.426239\n",
            "Train Epoch: 142 [33280/232365 (14%)]\tLoss: 162.667740\n",
            "Train Epoch: 142 [34560/232365 (15%)]\tLoss: 170.125595\n",
            "Train Epoch: 142 [35840/232365 (15%)]\tLoss: 178.152695\n",
            "Train Epoch: 142 [37120/232365 (16%)]\tLoss: 179.406586\n",
            "Train Epoch: 142 [38400/232365 (17%)]\tLoss: 175.865814\n",
            "Train Epoch: 142 [39680/232365 (17%)]\tLoss: 172.308807\n",
            "Train Epoch: 142 [40960/232365 (18%)]\tLoss: 170.332001\n",
            "Train Epoch: 142 [42240/232365 (18%)]\tLoss: 174.554520\n",
            "Train Epoch: 142 [43520/232365 (19%)]\tLoss: 172.815277\n",
            "Train Epoch: 142 [44800/232365 (19%)]\tLoss: 182.419556\n",
            "Train Epoch: 142 [46080/232365 (20%)]\tLoss: 179.962067\n",
            "Train Epoch: 142 [47360/232365 (20%)]\tLoss: 173.450348\n",
            "Train Epoch: 142 [48640/232365 (21%)]\tLoss: 175.035110\n",
            "Train Epoch: 142 [49920/232365 (21%)]\tLoss: 175.813370\n",
            "Train Epoch: 142 [51200/232365 (22%)]\tLoss: 169.338989\n",
            "Train Epoch: 142 [52480/232365 (23%)]\tLoss: 177.511612\n",
            "Train Epoch: 142 [53760/232365 (23%)]\tLoss: 181.795258\n",
            "Train Epoch: 142 [55040/232365 (24%)]\tLoss: 177.984482\n",
            "Train Epoch: 142 [56320/232365 (24%)]\tLoss: 176.933868\n",
            "Train Epoch: 142 [57600/232365 (25%)]\tLoss: 162.408020\n",
            "Train Epoch: 142 [58880/232365 (25%)]\tLoss: 176.596024\n",
            "Train Epoch: 142 [60160/232365 (26%)]\tLoss: 169.187256\n",
            "Train Epoch: 142 [61440/232365 (26%)]\tLoss: 166.790558\n",
            "Train Epoch: 142 [62720/232365 (27%)]\tLoss: 171.378723\n",
            "Train Epoch: 142 [64000/232365 (28%)]\tLoss: 180.184006\n",
            "Train Epoch: 142 [65280/232365 (28%)]\tLoss: 172.896881\n",
            "Train Epoch: 142 [66560/232365 (29%)]\tLoss: 158.542068\n",
            "Train Epoch: 142 [67840/232365 (29%)]\tLoss: 177.472122\n",
            "Train Epoch: 142 [69120/232365 (30%)]\tLoss: 178.461502\n",
            "Train Epoch: 142 [70400/232365 (30%)]\tLoss: 173.182693\n",
            "Train Epoch: 142 [71680/232365 (31%)]\tLoss: 169.659668\n",
            "Train Epoch: 142 [72960/232365 (31%)]\tLoss: 166.042725\n",
            "Train Epoch: 142 [74240/232365 (32%)]\tLoss: 170.145264\n",
            "Train Epoch: 142 [75520/232365 (32%)]\tLoss: 185.718704\n",
            "Train Epoch: 142 [76800/232365 (33%)]\tLoss: 169.799133\n",
            "Train Epoch: 142 [78080/232365 (34%)]\tLoss: 167.929260\n",
            "Train Epoch: 142 [79360/232365 (34%)]\tLoss: 178.436523\n",
            "Train Epoch: 142 [80640/232365 (35%)]\tLoss: 177.932785\n",
            "Train Epoch: 142 [81920/232365 (35%)]\tLoss: 167.071396\n",
            "Train Epoch: 142 [83200/232365 (36%)]\tLoss: 178.115570\n",
            "Train Epoch: 142 [84480/232365 (36%)]\tLoss: 177.834106\n",
            "Train Epoch: 142 [85760/232365 (37%)]\tLoss: 183.317215\n",
            "Train Epoch: 142 [87040/232365 (37%)]\tLoss: 178.323532\n",
            "Train Epoch: 142 [88320/232365 (38%)]\tLoss: 165.166061\n",
            "Train Epoch: 142 [89600/232365 (39%)]\tLoss: 182.147354\n",
            "Train Epoch: 142 [90880/232365 (39%)]\tLoss: 164.965622\n",
            "Train Epoch: 142 [92160/232365 (40%)]\tLoss: 172.786972\n",
            "Train Epoch: 142 [93440/232365 (40%)]\tLoss: 174.575821\n",
            "Train Epoch: 142 [94720/232365 (41%)]\tLoss: 173.571213\n",
            "Train Epoch: 142 [96000/232365 (41%)]\tLoss: 175.316986\n",
            "Train Epoch: 142 [97280/232365 (42%)]\tLoss: 175.032257\n",
            "Train Epoch: 142 [98560/232365 (42%)]\tLoss: 176.843414\n",
            "Train Epoch: 142 [99840/232365 (43%)]\tLoss: 169.815369\n",
            "Train Epoch: 142 [101120/232365 (44%)]\tLoss: 165.817886\n",
            "Train Epoch: 142 [102400/232365 (44%)]\tLoss: 169.416229\n",
            "Train Epoch: 142 [103680/232365 (45%)]\tLoss: 172.939911\n",
            "Train Epoch: 142 [104960/232365 (45%)]\tLoss: 178.590378\n",
            "Train Epoch: 142 [106240/232365 (46%)]\tLoss: 169.923859\n",
            "Train Epoch: 142 [107520/232365 (46%)]\tLoss: 167.098358\n",
            "Train Epoch: 142 [108800/232365 (47%)]\tLoss: 163.388901\n",
            "Train Epoch: 142 [110080/232365 (47%)]\tLoss: 185.575821\n",
            "Train Epoch: 142 [111360/232365 (48%)]\tLoss: 173.513779\n",
            "Train Epoch: 142 [112640/232365 (48%)]\tLoss: 177.688324\n",
            "Train Epoch: 142 [113920/232365 (49%)]\tLoss: 168.603699\n",
            "Train Epoch: 142 [115200/232365 (50%)]\tLoss: 169.425262\n",
            "Train Epoch: 142 [116480/232365 (50%)]\tLoss: 168.165070\n",
            "Train Epoch: 142 [117760/232365 (51%)]\tLoss: 168.703979\n",
            "Train Epoch: 142 [119040/232365 (51%)]\tLoss: 176.287048\n",
            "Train Epoch: 142 [120320/232365 (52%)]\tLoss: 175.676483\n",
            "Train Epoch: 142 [121600/232365 (52%)]\tLoss: 173.141678\n",
            "Train Epoch: 142 [122880/232365 (53%)]\tLoss: 177.601654\n",
            "Train Epoch: 142 [124160/232365 (53%)]\tLoss: 170.766098\n",
            "Train Epoch: 142 [125440/232365 (54%)]\tLoss: 171.917999\n",
            "Train Epoch: 142 [126720/232365 (55%)]\tLoss: 175.166748\n",
            "Train Epoch: 142 [128000/232365 (55%)]\tLoss: 174.418488\n",
            "Train Epoch: 142 [129280/232365 (56%)]\tLoss: 171.263565\n",
            "Train Epoch: 142 [130560/232365 (56%)]\tLoss: 189.641388\n",
            "Train Epoch: 142 [131840/232365 (57%)]\tLoss: 167.658966\n",
            "Train Epoch: 142 [133120/232365 (57%)]\tLoss: 173.821655\n",
            "Train Epoch: 142 [134400/232365 (58%)]\tLoss: 173.822708\n",
            "Train Epoch: 142 [135680/232365 (58%)]\tLoss: 172.631699\n",
            "Train Epoch: 142 [136960/232365 (59%)]\tLoss: 162.079849\n",
            "Train Epoch: 142 [138240/232365 (59%)]\tLoss: 176.480042\n",
            "Train Epoch: 142 [139520/232365 (60%)]\tLoss: 176.108795\n",
            "Train Epoch: 142 [140800/232365 (61%)]\tLoss: 175.777359\n",
            "Train Epoch: 142 [142080/232365 (61%)]\tLoss: 172.169220\n",
            "Train Epoch: 142 [143360/232365 (62%)]\tLoss: 177.141006\n",
            "Train Epoch: 142 [144640/232365 (62%)]\tLoss: 181.068695\n",
            "Train Epoch: 142 [145920/232365 (63%)]\tLoss: 172.439301\n",
            "Train Epoch: 142 [147200/232365 (63%)]\tLoss: 178.334595\n",
            "Train Epoch: 142 [148480/232365 (64%)]\tLoss: 163.883621\n",
            "Train Epoch: 142 [149760/232365 (64%)]\tLoss: 169.358780\n",
            "Train Epoch: 142 [151040/232365 (65%)]\tLoss: 176.351196\n",
            "Train Epoch: 142 [152320/232365 (66%)]\tLoss: 171.719406\n",
            "Train Epoch: 142 [153600/232365 (66%)]\tLoss: 171.906021\n",
            "Train Epoch: 142 [154880/232365 (67%)]\tLoss: 176.509796\n",
            "Train Epoch: 142 [156160/232365 (67%)]\tLoss: 164.174713\n",
            "Train Epoch: 142 [157440/232365 (68%)]\tLoss: 172.686310\n",
            "Train Epoch: 142 [158720/232365 (68%)]\tLoss: 169.515991\n",
            "Train Epoch: 142 [160000/232365 (69%)]\tLoss: 174.861572\n",
            "Train Epoch: 142 [161280/232365 (69%)]\tLoss: 174.420807\n",
            "Train Epoch: 142 [162560/232365 (70%)]\tLoss: 165.941711\n",
            "Train Epoch: 142 [163840/232365 (70%)]\tLoss: 172.519196\n",
            "Train Epoch: 142 [165120/232365 (71%)]\tLoss: 170.406067\n",
            "Train Epoch: 142 [166400/232365 (72%)]\tLoss: 177.426727\n",
            "Train Epoch: 142 [167680/232365 (72%)]\tLoss: 177.890976\n",
            "Train Epoch: 142 [168960/232365 (73%)]\tLoss: 170.856262\n",
            "Train Epoch: 142 [170240/232365 (73%)]\tLoss: 162.634888\n",
            "Train Epoch: 142 [171520/232365 (74%)]\tLoss: 166.851089\n",
            "Train Epoch: 142 [172800/232365 (74%)]\tLoss: 174.904419\n",
            "Train Epoch: 142 [174080/232365 (75%)]\tLoss: 171.710815\n",
            "Train Epoch: 142 [175360/232365 (75%)]\tLoss: 172.440979\n",
            "Train Epoch: 142 [176640/232365 (76%)]\tLoss: 172.414215\n",
            "Train Epoch: 142 [177920/232365 (77%)]\tLoss: 177.855820\n",
            "Train Epoch: 142 [179200/232365 (77%)]\tLoss: 172.151489\n",
            "Train Epoch: 142 [180480/232365 (78%)]\tLoss: 166.067383\n",
            "Train Epoch: 142 [181760/232365 (78%)]\tLoss: 170.250610\n",
            "Train Epoch: 142 [183040/232365 (79%)]\tLoss: 167.319855\n",
            "Train Epoch: 142 [184320/232365 (79%)]\tLoss: 164.719589\n",
            "Train Epoch: 142 [185600/232365 (80%)]\tLoss: 164.710052\n",
            "Train Epoch: 142 [186880/232365 (80%)]\tLoss: 175.897888\n",
            "Train Epoch: 142 [188160/232365 (81%)]\tLoss: 165.361832\n",
            "Train Epoch: 142 [189440/232365 (81%)]\tLoss: 174.552933\n",
            "Train Epoch: 142 [190720/232365 (82%)]\tLoss: 171.417297\n",
            "Train Epoch: 142 [192000/232365 (83%)]\tLoss: 170.450165\n",
            "Train Epoch: 142 [193280/232365 (83%)]\tLoss: 175.991486\n",
            "Train Epoch: 142 [194560/232365 (84%)]\tLoss: 168.994507\n",
            "Train Epoch: 142 [195840/232365 (84%)]\tLoss: 175.085632\n",
            "Train Epoch: 142 [197120/232365 (85%)]\tLoss: 173.220459\n",
            "Train Epoch: 142 [198400/232365 (85%)]\tLoss: 172.560089\n",
            "Train Epoch: 142 [199680/232365 (86%)]\tLoss: 177.429718\n",
            "Train Epoch: 142 [200960/232365 (86%)]\tLoss: 176.957214\n",
            "Train Epoch: 142 [202240/232365 (87%)]\tLoss: 175.480835\n",
            "Train Epoch: 142 [203520/232365 (88%)]\tLoss: 179.303833\n",
            "Train Epoch: 142 [204800/232365 (88%)]\tLoss: 180.577545\n",
            "Train Epoch: 142 [206080/232365 (89%)]\tLoss: 167.287872\n",
            "Train Epoch: 142 [207360/232365 (89%)]\tLoss: 174.175217\n",
            "Train Epoch: 142 [208640/232365 (90%)]\tLoss: 173.514343\n",
            "Train Epoch: 142 [209920/232365 (90%)]\tLoss: 173.428406\n",
            "Train Epoch: 142 [211200/232365 (91%)]\tLoss: 174.701935\n",
            "Train Epoch: 142 [212480/232365 (91%)]\tLoss: 171.720261\n",
            "Train Epoch: 142 [213760/232365 (92%)]\tLoss: 166.502121\n",
            "Train Epoch: 142 [215040/232365 (93%)]\tLoss: 168.030045\n",
            "Train Epoch: 142 [216320/232365 (93%)]\tLoss: 169.974228\n",
            "Train Epoch: 142 [217600/232365 (94%)]\tLoss: 165.807800\n",
            "Train Epoch: 142 [218880/232365 (94%)]\tLoss: 173.697723\n",
            "Train Epoch: 142 [220160/232365 (95%)]\tLoss: 167.100067\n",
            "Train Epoch: 142 [221440/232365 (95%)]\tLoss: 162.219727\n",
            "Train Epoch: 142 [222720/232365 (96%)]\tLoss: 172.507507\n",
            "Train Epoch: 142 [224000/232365 (96%)]\tLoss: 172.729858\n",
            "Train Epoch: 142 [225280/232365 (97%)]\tLoss: 168.916229\n",
            "Train Epoch: 142 [226560/232365 (97%)]\tLoss: 172.195770\n",
            "Train Epoch: 142 [227840/232365 (98%)]\tLoss: 164.687912\n",
            "Train Epoch: 142 [229120/232365 (99%)]\tLoss: 173.125366\n",
            "Train Epoch: 142 [230400/232365 (99%)]\tLoss: 182.023560\n",
            "Train Epoch: 142 [231680/232365 (100%)]\tLoss: 168.468872\n",
            "====> Epoch: 142 Average loss: 172.4440, Accuracy: 74.24%\n",
            "====> Test set loss: 183.3559, Accuracy: 74.12%\n",
            "Train Epoch: 143 [0/232365 (0%)]\tLoss: 173.957520\n",
            "Train Epoch: 143 [1280/232365 (1%)]\tLoss: 159.281723\n",
            "Train Epoch: 143 [2560/232365 (1%)]\tLoss: 162.670242\n",
            "Train Epoch: 143 [3840/232365 (2%)]\tLoss: 158.757187\n",
            "Train Epoch: 143 [5120/232365 (2%)]\tLoss: 178.939041\n",
            "Train Epoch: 143 [6400/232365 (3%)]\tLoss: 170.019958\n",
            "Train Epoch: 143 [7680/232365 (3%)]\tLoss: 171.663300\n",
            "Train Epoch: 143 [8960/232365 (4%)]\tLoss: 172.174454\n",
            "Train Epoch: 143 [10240/232365 (4%)]\tLoss: 164.391739\n",
            "Train Epoch: 143 [11520/232365 (5%)]\tLoss: 173.317734\n",
            "Train Epoch: 143 [12800/232365 (6%)]\tLoss: 170.065750\n",
            "Train Epoch: 143 [14080/232365 (6%)]\tLoss: 173.658829\n",
            "Train Epoch: 143 [15360/232365 (7%)]\tLoss: 171.712128\n",
            "Train Epoch: 143 [16640/232365 (7%)]\tLoss: 175.213806\n",
            "Train Epoch: 143 [17920/232365 (8%)]\tLoss: 177.177292\n",
            "Train Epoch: 143 [19200/232365 (8%)]\tLoss: 174.913315\n",
            "Train Epoch: 143 [20480/232365 (9%)]\tLoss: 173.210571\n",
            "Train Epoch: 143 [21760/232365 (9%)]\tLoss: 178.032486\n",
            "Train Epoch: 143 [23040/232365 (10%)]\tLoss: 175.559998\n",
            "Train Epoch: 143 [24320/232365 (10%)]\tLoss: 164.358841\n",
            "Train Epoch: 143 [25600/232365 (11%)]\tLoss: 180.392700\n",
            "Train Epoch: 143 [26880/232365 (12%)]\tLoss: 177.780411\n",
            "Train Epoch: 143 [28160/232365 (12%)]\tLoss: 163.184387\n",
            "Train Epoch: 143 [29440/232365 (13%)]\tLoss: 167.752106\n",
            "Train Epoch: 143 [30720/232365 (13%)]\tLoss: 171.805206\n",
            "Train Epoch: 143 [32000/232365 (14%)]\tLoss: 165.966599\n",
            "Train Epoch: 143 [33280/232365 (14%)]\tLoss: 164.880402\n",
            "Train Epoch: 143 [34560/232365 (15%)]\tLoss: 180.495743\n",
            "Train Epoch: 143 [35840/232365 (15%)]\tLoss: 176.271698\n",
            "Train Epoch: 143 [37120/232365 (16%)]\tLoss: 177.221191\n",
            "Train Epoch: 143 [38400/232365 (17%)]\tLoss: 177.517715\n",
            "Train Epoch: 143 [39680/232365 (17%)]\tLoss: 175.026688\n",
            "Train Epoch: 143 [40960/232365 (18%)]\tLoss: 171.137970\n",
            "Train Epoch: 143 [42240/232365 (18%)]\tLoss: 171.515915\n",
            "Train Epoch: 143 [43520/232365 (19%)]\tLoss: 174.773087\n",
            "Train Epoch: 143 [44800/232365 (19%)]\tLoss: 172.469803\n",
            "Train Epoch: 143 [46080/232365 (20%)]\tLoss: 181.574585\n",
            "Train Epoch: 143 [47360/232365 (20%)]\tLoss: 169.176926\n",
            "Train Epoch: 143 [48640/232365 (21%)]\tLoss: 173.734116\n",
            "Train Epoch: 143 [49920/232365 (21%)]\tLoss: 185.832153\n",
            "Train Epoch: 143 [51200/232365 (22%)]\tLoss: 177.094940\n",
            "Train Epoch: 143 [52480/232365 (23%)]\tLoss: 167.059509\n",
            "Train Epoch: 143 [53760/232365 (23%)]\tLoss: 173.036499\n",
            "Train Epoch: 143 [55040/232365 (24%)]\tLoss: 184.675232\n",
            "Train Epoch: 143 [56320/232365 (24%)]\tLoss: 182.786728\n",
            "Train Epoch: 143 [57600/232365 (25%)]\tLoss: 174.291168\n",
            "Train Epoch: 143 [58880/232365 (25%)]\tLoss: 169.058807\n",
            "Train Epoch: 143 [60160/232365 (26%)]\tLoss: 171.876495\n",
            "Train Epoch: 143 [61440/232365 (26%)]\tLoss: 176.732529\n",
            "Train Epoch: 143 [62720/232365 (27%)]\tLoss: 177.013794\n",
            "Train Epoch: 143 [64000/232365 (28%)]\tLoss: 168.480469\n",
            "Train Epoch: 143 [65280/232365 (28%)]\tLoss: 172.094391\n",
            "Train Epoch: 143 [66560/232365 (29%)]\tLoss: 173.292770\n",
            "Train Epoch: 143 [67840/232365 (29%)]\tLoss: 168.274429\n",
            "Train Epoch: 143 [69120/232365 (30%)]\tLoss: 176.694229\n",
            "Train Epoch: 143 [70400/232365 (30%)]\tLoss: 170.727692\n",
            "Train Epoch: 143 [71680/232365 (31%)]\tLoss: 175.400894\n",
            "Train Epoch: 143 [72960/232365 (31%)]\tLoss: 173.346649\n",
            "Train Epoch: 143 [74240/232365 (32%)]\tLoss: 172.821991\n",
            "Train Epoch: 143 [75520/232365 (32%)]\tLoss: 170.706650\n",
            "Train Epoch: 143 [76800/232365 (33%)]\tLoss: 177.595413\n",
            "Train Epoch: 143 [78080/232365 (34%)]\tLoss: 171.987091\n",
            "Train Epoch: 143 [79360/232365 (34%)]\tLoss: 170.625549\n",
            "Train Epoch: 143 [80640/232365 (35%)]\tLoss: 170.883926\n",
            "Train Epoch: 143 [81920/232365 (35%)]\tLoss: 179.335815\n",
            "Train Epoch: 143 [83200/232365 (36%)]\tLoss: 177.884659\n",
            "Train Epoch: 143 [84480/232365 (36%)]\tLoss: 168.019318\n",
            "Train Epoch: 143 [85760/232365 (37%)]\tLoss: 172.443039\n",
            "Train Epoch: 143 [87040/232365 (37%)]\tLoss: 183.531204\n",
            "Train Epoch: 143 [88320/232365 (38%)]\tLoss: 169.934265\n",
            "Train Epoch: 143 [89600/232365 (39%)]\tLoss: 174.348892\n",
            "Train Epoch: 143 [90880/232365 (39%)]\tLoss: 177.799362\n",
            "Train Epoch: 143 [92160/232365 (40%)]\tLoss: 174.845291\n",
            "Train Epoch: 143 [93440/232365 (40%)]\tLoss: 169.786240\n",
            "Train Epoch: 143 [94720/232365 (41%)]\tLoss: 183.082153\n",
            "Train Epoch: 143 [96000/232365 (41%)]\tLoss: 173.746353\n",
            "Train Epoch: 143 [97280/232365 (42%)]\tLoss: 171.989288\n",
            "Train Epoch: 143 [98560/232365 (42%)]\tLoss: 184.633911\n",
            "Train Epoch: 143 [99840/232365 (43%)]\tLoss: 163.290756\n",
            "Train Epoch: 143 [101120/232365 (44%)]\tLoss: 181.868149\n",
            "Train Epoch: 143 [102400/232365 (44%)]\tLoss: 172.922806\n",
            "Train Epoch: 143 [103680/232365 (45%)]\tLoss: 173.291016\n",
            "Train Epoch: 143 [104960/232365 (45%)]\tLoss: 172.116287\n",
            "Train Epoch: 143 [106240/232365 (46%)]\tLoss: 169.923462\n",
            "Train Epoch: 143 [107520/232365 (46%)]\tLoss: 172.359421\n",
            "Train Epoch: 143 [108800/232365 (47%)]\tLoss: 180.875656\n",
            "Train Epoch: 143 [110080/232365 (47%)]\tLoss: 165.979568\n",
            "Train Epoch: 143 [111360/232365 (48%)]\tLoss: 176.390411\n",
            "Train Epoch: 143 [112640/232365 (48%)]\tLoss: 166.666458\n",
            "Train Epoch: 143 [113920/232365 (49%)]\tLoss: 170.439133\n",
            "Train Epoch: 143 [115200/232365 (50%)]\tLoss: 170.090897\n",
            "Train Epoch: 143 [116480/232365 (50%)]\tLoss: 164.516663\n",
            "Train Epoch: 143 [117760/232365 (51%)]\tLoss: 164.506287\n",
            "Train Epoch: 143 [119040/232365 (51%)]\tLoss: 161.293747\n",
            "Train Epoch: 143 [120320/232365 (52%)]\tLoss: 177.816437\n",
            "Train Epoch: 143 [121600/232365 (52%)]\tLoss: 171.873947\n",
            "Train Epoch: 143 [122880/232365 (53%)]\tLoss: 172.718445\n",
            "Train Epoch: 143 [124160/232365 (53%)]\tLoss: 173.953873\n",
            "Train Epoch: 143 [125440/232365 (54%)]\tLoss: 177.994308\n",
            "Train Epoch: 143 [126720/232365 (55%)]\tLoss: 174.391479\n",
            "Train Epoch: 143 [128000/232365 (55%)]\tLoss: 174.575607\n",
            "Train Epoch: 143 [129280/232365 (56%)]\tLoss: 167.389267\n",
            "Train Epoch: 143 [130560/232365 (56%)]\tLoss: 156.804779\n",
            "Train Epoch: 143 [131840/232365 (57%)]\tLoss: 176.335159\n",
            "Train Epoch: 143 [133120/232365 (57%)]\tLoss: 174.791214\n",
            "Train Epoch: 143 [134400/232365 (58%)]\tLoss: 167.738403\n",
            "Train Epoch: 143 [135680/232365 (58%)]\tLoss: 169.884567\n",
            "Train Epoch: 143 [136960/232365 (59%)]\tLoss: 162.684204\n",
            "Train Epoch: 143 [138240/232365 (59%)]\tLoss: 169.382278\n",
            "Train Epoch: 143 [139520/232365 (60%)]\tLoss: 173.384521\n",
            "Train Epoch: 143 [140800/232365 (61%)]\tLoss: 166.063019\n",
            "Train Epoch: 143 [142080/232365 (61%)]\tLoss: 168.402954\n",
            "Train Epoch: 143 [143360/232365 (62%)]\tLoss: 167.488770\n",
            "Train Epoch: 143 [144640/232365 (62%)]\tLoss: 172.056625\n",
            "Train Epoch: 143 [145920/232365 (63%)]\tLoss: 173.700684\n",
            "Train Epoch: 143 [147200/232365 (63%)]\tLoss: 168.749832\n",
            "Train Epoch: 143 [148480/232365 (64%)]\tLoss: 187.491150\n",
            "Train Epoch: 143 [149760/232365 (64%)]\tLoss: 163.759552\n",
            "Train Epoch: 143 [151040/232365 (65%)]\tLoss: 178.085358\n",
            "Train Epoch: 143 [152320/232365 (66%)]\tLoss: 162.443039\n",
            "Train Epoch: 143 [153600/232365 (66%)]\tLoss: 170.673798\n",
            "Train Epoch: 143 [154880/232365 (67%)]\tLoss: 166.428757\n",
            "Train Epoch: 143 [156160/232365 (67%)]\tLoss: 176.313202\n",
            "Train Epoch: 143 [157440/232365 (68%)]\tLoss: 185.212875\n",
            "Train Epoch: 143 [158720/232365 (68%)]\tLoss: 176.646210\n",
            "Train Epoch: 143 [160000/232365 (69%)]\tLoss: 177.286057\n",
            "Train Epoch: 143 [161280/232365 (69%)]\tLoss: 177.679504\n",
            "Train Epoch: 143 [162560/232365 (70%)]\tLoss: 169.693985\n",
            "Train Epoch: 143 [163840/232365 (70%)]\tLoss: 171.766647\n",
            "Train Epoch: 143 [165120/232365 (71%)]\tLoss: 173.129196\n",
            "Train Epoch: 143 [166400/232365 (72%)]\tLoss: 172.594543\n",
            "Train Epoch: 143 [167680/232365 (72%)]\tLoss: 184.003784\n",
            "Train Epoch: 143 [168960/232365 (73%)]\tLoss: 173.055374\n",
            "Train Epoch: 143 [170240/232365 (73%)]\tLoss: 168.574066\n",
            "Train Epoch: 143 [171520/232365 (74%)]\tLoss: 164.445755\n",
            "Train Epoch: 143 [172800/232365 (74%)]\tLoss: 166.240494\n",
            "Train Epoch: 143 [174080/232365 (75%)]\tLoss: 163.517975\n",
            "Train Epoch: 143 [175360/232365 (75%)]\tLoss: 173.162338\n",
            "Train Epoch: 143 [176640/232365 (76%)]\tLoss: 169.833847\n",
            "Train Epoch: 143 [177920/232365 (77%)]\tLoss: 166.786774\n",
            "Train Epoch: 143 [179200/232365 (77%)]\tLoss: 166.786560\n",
            "Train Epoch: 143 [180480/232365 (78%)]\tLoss: 166.345169\n",
            "Train Epoch: 143 [181760/232365 (78%)]\tLoss: 172.458038\n",
            "Train Epoch: 143 [183040/232365 (79%)]\tLoss: 170.788101\n",
            "Train Epoch: 143 [184320/232365 (79%)]\tLoss: 192.006256\n",
            "Train Epoch: 143 [185600/232365 (80%)]\tLoss: 163.467621\n",
            "Train Epoch: 143 [186880/232365 (80%)]\tLoss: 175.531067\n",
            "Train Epoch: 143 [188160/232365 (81%)]\tLoss: 167.624039\n",
            "Train Epoch: 143 [189440/232365 (81%)]\tLoss: 174.944824\n",
            "Train Epoch: 143 [190720/232365 (82%)]\tLoss: 177.892319\n",
            "Train Epoch: 143 [192000/232365 (83%)]\tLoss: 186.776627\n",
            "Train Epoch: 143 [193280/232365 (83%)]\tLoss: 172.116501\n",
            "Train Epoch: 143 [194560/232365 (84%)]\tLoss: 169.287628\n",
            "Train Epoch: 143 [195840/232365 (84%)]\tLoss: 178.780975\n",
            "Train Epoch: 143 [197120/232365 (85%)]\tLoss: 167.137070\n",
            "Train Epoch: 143 [198400/232365 (85%)]\tLoss: 181.992615\n",
            "Train Epoch: 143 [199680/232365 (86%)]\tLoss: 171.645706\n",
            "Train Epoch: 143 [200960/232365 (86%)]\tLoss: 170.063461\n",
            "Train Epoch: 143 [202240/232365 (87%)]\tLoss: 170.258896\n",
            "Train Epoch: 143 [203520/232365 (88%)]\tLoss: 174.562820\n",
            "Train Epoch: 143 [204800/232365 (88%)]\tLoss: 174.448807\n",
            "Train Epoch: 143 [206080/232365 (89%)]\tLoss: 169.321030\n",
            "Train Epoch: 143 [207360/232365 (89%)]\tLoss: 174.434570\n",
            "Train Epoch: 143 [208640/232365 (90%)]\tLoss: 166.569717\n",
            "Train Epoch: 143 [209920/232365 (90%)]\tLoss: 172.113068\n",
            "Train Epoch: 143 [211200/232365 (91%)]\tLoss: 164.348083\n",
            "Train Epoch: 143 [212480/232365 (91%)]\tLoss: 170.188751\n",
            "Train Epoch: 143 [213760/232365 (92%)]\tLoss: 178.851730\n",
            "Train Epoch: 143 [215040/232365 (93%)]\tLoss: 175.026474\n",
            "Train Epoch: 143 [216320/232365 (93%)]\tLoss: 172.075394\n",
            "Train Epoch: 143 [217600/232365 (94%)]\tLoss: 172.675507\n",
            "Train Epoch: 143 [218880/232365 (94%)]\tLoss: 170.596588\n",
            "Train Epoch: 143 [220160/232365 (95%)]\tLoss: 174.919067\n",
            "Train Epoch: 143 [221440/232365 (95%)]\tLoss: 170.368195\n",
            "Train Epoch: 143 [222720/232365 (96%)]\tLoss: 170.847778\n",
            "Train Epoch: 143 [224000/232365 (96%)]\tLoss: 173.202362\n",
            "Train Epoch: 143 [225280/232365 (97%)]\tLoss: 175.364029\n",
            "Train Epoch: 143 [226560/232365 (97%)]\tLoss: 175.377228\n",
            "Train Epoch: 143 [227840/232365 (98%)]\tLoss: 170.879196\n",
            "Train Epoch: 143 [229120/232365 (99%)]\tLoss: 173.295685\n",
            "Train Epoch: 143 [230400/232365 (99%)]\tLoss: 173.206848\n",
            "Train Epoch: 143 [231680/232365 (100%)]\tLoss: 185.260468\n",
            "====> Epoch: 143 Average loss: 172.4438, Accuracy: 74.24%\n",
            "====> Test set loss: 183.6600, Accuracy: 74.13%\n",
            "Train Epoch: 144 [0/232365 (0%)]\tLoss: 165.876343\n",
            "Train Epoch: 144 [1280/232365 (1%)]\tLoss: 171.648499\n",
            "Train Epoch: 144 [2560/232365 (1%)]\tLoss: 177.886642\n",
            "Train Epoch: 144 [3840/232365 (2%)]\tLoss: 174.481308\n",
            "Train Epoch: 144 [5120/232365 (2%)]\tLoss: 174.652435\n",
            "Train Epoch: 144 [6400/232365 (3%)]\tLoss: 171.132202\n",
            "Train Epoch: 144 [7680/232365 (3%)]\tLoss: 171.360580\n",
            "Train Epoch: 144 [8960/232365 (4%)]\tLoss: 168.145523\n",
            "Train Epoch: 144 [10240/232365 (4%)]\tLoss: 165.617065\n",
            "Train Epoch: 144 [11520/232365 (5%)]\tLoss: 165.512238\n",
            "Train Epoch: 144 [12800/232365 (6%)]\tLoss: 173.918427\n",
            "Train Epoch: 144 [14080/232365 (6%)]\tLoss: 170.537933\n",
            "Train Epoch: 144 [15360/232365 (7%)]\tLoss: 175.120712\n",
            "Train Epoch: 144 [16640/232365 (7%)]\tLoss: 169.890305\n",
            "Train Epoch: 144 [17920/232365 (8%)]\tLoss: 164.572647\n",
            "Train Epoch: 144 [19200/232365 (8%)]\tLoss: 169.203552\n",
            "Train Epoch: 144 [20480/232365 (9%)]\tLoss: 186.972672\n",
            "Train Epoch: 144 [21760/232365 (9%)]\tLoss: 174.980438\n",
            "Train Epoch: 144 [23040/232365 (10%)]\tLoss: 176.777100\n",
            "Train Epoch: 144 [24320/232365 (10%)]\tLoss: 175.448502\n",
            "Train Epoch: 144 [25600/232365 (11%)]\tLoss: 169.511841\n",
            "Train Epoch: 144 [26880/232365 (12%)]\tLoss: 181.373291\n",
            "Train Epoch: 144 [28160/232365 (12%)]\tLoss: 168.959106\n",
            "Train Epoch: 144 [29440/232365 (13%)]\tLoss: 171.690201\n",
            "Train Epoch: 144 [30720/232365 (13%)]\tLoss: 175.458267\n",
            "Train Epoch: 144 [32000/232365 (14%)]\tLoss: 174.857971\n",
            "Train Epoch: 144 [33280/232365 (14%)]\tLoss: 168.250671\n",
            "Train Epoch: 144 [34560/232365 (15%)]\tLoss: 178.235718\n",
            "Train Epoch: 144 [35840/232365 (15%)]\tLoss: 173.891129\n",
            "Train Epoch: 144 [37120/232365 (16%)]\tLoss: 167.529739\n",
            "Train Epoch: 144 [38400/232365 (17%)]\tLoss: 174.735199\n",
            "Train Epoch: 144 [39680/232365 (17%)]\tLoss: 174.535721\n",
            "Train Epoch: 144 [40960/232365 (18%)]\tLoss: 172.201004\n",
            "Train Epoch: 144 [42240/232365 (18%)]\tLoss: 167.518646\n",
            "Train Epoch: 144 [43520/232365 (19%)]\tLoss: 181.281769\n",
            "Train Epoch: 144 [44800/232365 (19%)]\tLoss: 181.212296\n",
            "Train Epoch: 144 [46080/232365 (20%)]\tLoss: 171.239471\n",
            "Train Epoch: 144 [47360/232365 (20%)]\tLoss: 179.157898\n",
            "Train Epoch: 144 [48640/232365 (21%)]\tLoss: 167.926636\n",
            "Train Epoch: 144 [49920/232365 (21%)]\tLoss: 175.582748\n",
            "Train Epoch: 144 [51200/232365 (22%)]\tLoss: 168.902008\n",
            "Train Epoch: 144 [52480/232365 (23%)]\tLoss: 171.343887\n",
            "Train Epoch: 144 [53760/232365 (23%)]\tLoss: 176.595123\n",
            "Train Epoch: 144 [55040/232365 (24%)]\tLoss: 174.937790\n",
            "Train Epoch: 144 [56320/232365 (24%)]\tLoss: 175.100235\n",
            "Train Epoch: 144 [57600/232365 (25%)]\tLoss: 168.272263\n",
            "Train Epoch: 144 [58880/232365 (25%)]\tLoss: 172.925110\n",
            "Train Epoch: 144 [60160/232365 (26%)]\tLoss: 168.567566\n",
            "Train Epoch: 144 [61440/232365 (26%)]\tLoss: 176.585907\n",
            "Train Epoch: 144 [62720/232365 (27%)]\tLoss: 172.075531\n",
            "Train Epoch: 144 [64000/232365 (28%)]\tLoss: 165.328796\n",
            "Train Epoch: 144 [65280/232365 (28%)]\tLoss: 178.534592\n",
            "Train Epoch: 144 [66560/232365 (29%)]\tLoss: 172.615707\n",
            "Train Epoch: 144 [67840/232365 (29%)]\tLoss: 178.240494\n",
            "Train Epoch: 144 [69120/232365 (30%)]\tLoss: 168.896667\n",
            "Train Epoch: 144 [70400/232365 (30%)]\tLoss: 176.765656\n",
            "Train Epoch: 144 [71680/232365 (31%)]\tLoss: 169.163635\n",
            "Train Epoch: 144 [72960/232365 (31%)]\tLoss: 170.926712\n",
            "Train Epoch: 144 [74240/232365 (32%)]\tLoss: 176.739029\n",
            "Train Epoch: 144 [75520/232365 (32%)]\tLoss: 169.891037\n",
            "Train Epoch: 144 [76800/232365 (33%)]\tLoss: 173.052704\n",
            "Train Epoch: 144 [78080/232365 (34%)]\tLoss: 166.929977\n",
            "Train Epoch: 144 [79360/232365 (34%)]\tLoss: 170.364883\n",
            "Train Epoch: 144 [80640/232365 (35%)]\tLoss: 170.224121\n",
            "Train Epoch: 144 [81920/232365 (35%)]\tLoss: 170.769318\n",
            "Train Epoch: 144 [83200/232365 (36%)]\tLoss: 163.118607\n",
            "Train Epoch: 144 [84480/232365 (36%)]\tLoss: 179.993561\n",
            "Train Epoch: 144 [85760/232365 (37%)]\tLoss: 173.452835\n",
            "Train Epoch: 144 [87040/232365 (37%)]\tLoss: 176.555511\n",
            "Train Epoch: 144 [88320/232365 (38%)]\tLoss: 175.308990\n",
            "Train Epoch: 144 [89600/232365 (39%)]\tLoss: 175.339645\n",
            "Train Epoch: 144 [90880/232365 (39%)]\tLoss: 184.222488\n",
            "Train Epoch: 144 [92160/232365 (40%)]\tLoss: 171.272079\n",
            "Train Epoch: 144 [93440/232365 (40%)]\tLoss: 169.469193\n",
            "Train Epoch: 144 [94720/232365 (41%)]\tLoss: 174.225204\n",
            "Train Epoch: 144 [96000/232365 (41%)]\tLoss: 182.341263\n",
            "Train Epoch: 144 [97280/232365 (42%)]\tLoss: 168.644241\n",
            "Train Epoch: 144 [98560/232365 (42%)]\tLoss: 170.863388\n",
            "Train Epoch: 144 [99840/232365 (43%)]\tLoss: 158.850082\n",
            "Train Epoch: 144 [101120/232365 (44%)]\tLoss: 176.760223\n",
            "Train Epoch: 144 [102400/232365 (44%)]\tLoss: 176.437820\n",
            "Train Epoch: 144 [103680/232365 (45%)]\tLoss: 171.718689\n",
            "Train Epoch: 144 [104960/232365 (45%)]\tLoss: 174.656860\n",
            "Train Epoch: 144 [106240/232365 (46%)]\tLoss: 177.540771\n",
            "Train Epoch: 144 [107520/232365 (46%)]\tLoss: 173.020248\n",
            "Train Epoch: 144 [108800/232365 (47%)]\tLoss: 176.971817\n",
            "Train Epoch: 144 [110080/232365 (47%)]\tLoss: 174.615540\n",
            "Train Epoch: 144 [111360/232365 (48%)]\tLoss: 167.686340\n",
            "Train Epoch: 144 [112640/232365 (48%)]\tLoss: 177.150818\n",
            "Train Epoch: 144 [113920/232365 (49%)]\tLoss: 174.146881\n",
            "Train Epoch: 144 [115200/232365 (50%)]\tLoss: 171.549469\n",
            "Train Epoch: 144 [116480/232365 (50%)]\tLoss: 174.271561\n",
            "Train Epoch: 144 [117760/232365 (51%)]\tLoss: 174.405212\n",
            "Train Epoch: 144 [119040/232365 (51%)]\tLoss: 166.515869\n",
            "Train Epoch: 144 [120320/232365 (52%)]\tLoss: 173.695267\n",
            "Train Epoch: 144 [121600/232365 (52%)]\tLoss: 175.843948\n",
            "Train Epoch: 144 [122880/232365 (53%)]\tLoss: 170.765045\n",
            "Train Epoch: 144 [124160/232365 (53%)]\tLoss: 161.067810\n",
            "Train Epoch: 144 [125440/232365 (54%)]\tLoss: 166.593887\n",
            "Train Epoch: 144 [126720/232365 (55%)]\tLoss: 163.689117\n",
            "Train Epoch: 144 [128000/232365 (55%)]\tLoss: 164.779663\n",
            "Train Epoch: 144 [129280/232365 (56%)]\tLoss: 163.539825\n",
            "Train Epoch: 144 [130560/232365 (56%)]\tLoss: 171.143890\n",
            "Train Epoch: 144 [131840/232365 (57%)]\tLoss: 182.739868\n",
            "Train Epoch: 144 [133120/232365 (57%)]\tLoss: 165.645630\n",
            "Train Epoch: 144 [134400/232365 (58%)]\tLoss: 179.059860\n",
            "Train Epoch: 144 [135680/232365 (58%)]\tLoss: 188.967575\n",
            "Train Epoch: 144 [136960/232365 (59%)]\tLoss: 178.592346\n",
            "Train Epoch: 144 [138240/232365 (59%)]\tLoss: 167.829651\n",
            "Train Epoch: 144 [139520/232365 (60%)]\tLoss: 173.375229\n",
            "Train Epoch: 144 [140800/232365 (61%)]\tLoss: 173.920364\n",
            "Train Epoch: 144 [142080/232365 (61%)]\tLoss: 167.946213\n",
            "Train Epoch: 144 [143360/232365 (62%)]\tLoss: 178.300888\n",
            "Train Epoch: 144 [144640/232365 (62%)]\tLoss: 177.392197\n",
            "Train Epoch: 144 [145920/232365 (63%)]\tLoss: 168.523834\n",
            "Train Epoch: 144 [147200/232365 (63%)]\tLoss: 171.724655\n",
            "Train Epoch: 144 [148480/232365 (64%)]\tLoss: 169.606110\n",
            "Train Epoch: 144 [149760/232365 (64%)]\tLoss: 174.512848\n",
            "Train Epoch: 144 [151040/232365 (65%)]\tLoss: 177.455383\n",
            "Train Epoch: 144 [152320/232365 (66%)]\tLoss: 166.086273\n",
            "Train Epoch: 144 [153600/232365 (66%)]\tLoss: 165.237366\n",
            "Train Epoch: 144 [154880/232365 (67%)]\tLoss: 176.487137\n",
            "Train Epoch: 144 [156160/232365 (67%)]\tLoss: 164.616455\n",
            "Train Epoch: 144 [157440/232365 (68%)]\tLoss: 174.382401\n",
            "Train Epoch: 144 [158720/232365 (68%)]\tLoss: 173.954956\n",
            "Train Epoch: 144 [160000/232365 (69%)]\tLoss: 181.755035\n",
            "Train Epoch: 144 [161280/232365 (69%)]\tLoss: 162.626938\n",
            "Train Epoch: 144 [162560/232365 (70%)]\tLoss: 178.997559\n",
            "Train Epoch: 144 [163840/232365 (70%)]\tLoss: 173.872757\n",
            "Train Epoch: 144 [165120/232365 (71%)]\tLoss: 175.053223\n",
            "Train Epoch: 144 [166400/232365 (72%)]\tLoss: 165.778015\n",
            "Train Epoch: 144 [167680/232365 (72%)]\tLoss: 177.864517\n",
            "Train Epoch: 144 [168960/232365 (73%)]\tLoss: 166.174820\n",
            "Train Epoch: 144 [170240/232365 (73%)]\tLoss: 174.240845\n",
            "Train Epoch: 144 [171520/232365 (74%)]\tLoss: 182.092804\n",
            "Train Epoch: 144 [172800/232365 (74%)]\tLoss: 169.861725\n",
            "Train Epoch: 144 [174080/232365 (75%)]\tLoss: 176.419647\n",
            "Train Epoch: 144 [175360/232365 (75%)]\tLoss: 173.096100\n",
            "Train Epoch: 144 [176640/232365 (76%)]\tLoss: 176.513245\n",
            "Train Epoch: 144 [177920/232365 (77%)]\tLoss: 169.710129\n",
            "Train Epoch: 144 [179200/232365 (77%)]\tLoss: 174.274216\n",
            "Train Epoch: 144 [180480/232365 (78%)]\tLoss: 160.372879\n",
            "Train Epoch: 144 [181760/232365 (78%)]\tLoss: 167.113586\n",
            "Train Epoch: 144 [183040/232365 (79%)]\tLoss: 171.538635\n",
            "Train Epoch: 144 [184320/232365 (79%)]\tLoss: 172.789215\n",
            "Train Epoch: 144 [185600/232365 (80%)]\tLoss: 176.922684\n",
            "Train Epoch: 144 [186880/232365 (80%)]\tLoss: 176.182480\n",
            "Train Epoch: 144 [188160/232365 (81%)]\tLoss: 182.611252\n",
            "Train Epoch: 144 [189440/232365 (81%)]\tLoss: 173.253738\n",
            "Train Epoch: 144 [190720/232365 (82%)]\tLoss: 178.931961\n",
            "Train Epoch: 144 [192000/232365 (83%)]\tLoss: 167.727570\n",
            "Train Epoch: 144 [193280/232365 (83%)]\tLoss: 170.716125\n",
            "Train Epoch: 144 [194560/232365 (84%)]\tLoss: 175.956589\n",
            "Train Epoch: 144 [195840/232365 (84%)]\tLoss: 177.656891\n",
            "Train Epoch: 144 [197120/232365 (85%)]\tLoss: 182.600128\n",
            "Train Epoch: 144 [198400/232365 (85%)]\tLoss: 175.191010\n",
            "Train Epoch: 144 [199680/232365 (86%)]\tLoss: 178.577179\n",
            "Train Epoch: 144 [200960/232365 (86%)]\tLoss: 175.254730\n",
            "Train Epoch: 144 [202240/232365 (87%)]\tLoss: 168.460052\n",
            "Train Epoch: 144 [203520/232365 (88%)]\tLoss: 170.350510\n",
            "Train Epoch: 144 [204800/232365 (88%)]\tLoss: 171.286346\n",
            "Train Epoch: 144 [206080/232365 (89%)]\tLoss: 170.130630\n",
            "Train Epoch: 144 [207360/232365 (89%)]\tLoss: 175.342987\n",
            "Train Epoch: 144 [208640/232365 (90%)]\tLoss: 174.282440\n",
            "Train Epoch: 144 [209920/232365 (90%)]\tLoss: 169.322876\n",
            "Train Epoch: 144 [211200/232365 (91%)]\tLoss: 167.015793\n",
            "Train Epoch: 144 [212480/232365 (91%)]\tLoss: 177.011475\n",
            "Train Epoch: 144 [213760/232365 (92%)]\tLoss: 179.929657\n",
            "Train Epoch: 144 [215040/232365 (93%)]\tLoss: 171.632660\n",
            "Train Epoch: 144 [216320/232365 (93%)]\tLoss: 166.741180\n",
            "Train Epoch: 144 [217600/232365 (94%)]\tLoss: 174.897934\n",
            "Train Epoch: 144 [218880/232365 (94%)]\tLoss: 182.609116\n",
            "Train Epoch: 144 [220160/232365 (95%)]\tLoss: 170.902084\n",
            "Train Epoch: 144 [221440/232365 (95%)]\tLoss: 177.759628\n",
            "Train Epoch: 144 [222720/232365 (96%)]\tLoss: 163.935486\n",
            "Train Epoch: 144 [224000/232365 (96%)]\tLoss: 168.742935\n",
            "Train Epoch: 144 [225280/232365 (97%)]\tLoss: 179.169403\n",
            "Train Epoch: 144 [226560/232365 (97%)]\tLoss: 175.785110\n",
            "Train Epoch: 144 [227840/232365 (98%)]\tLoss: 178.723358\n",
            "Train Epoch: 144 [229120/232365 (99%)]\tLoss: 170.999527\n",
            "Train Epoch: 144 [230400/232365 (99%)]\tLoss: 167.041245\n",
            "Train Epoch: 144 [231680/232365 (100%)]\tLoss: 165.344345\n",
            "====> Epoch: 144 Average loss: 172.4268, Accuracy: 74.24%\n",
            "====> Test set loss: 183.1320, Accuracy: 74.13%\n",
            "Train Epoch: 145 [0/232365 (0%)]\tLoss: 168.317780\n",
            "Train Epoch: 145 [1280/232365 (1%)]\tLoss: 169.426651\n",
            "Train Epoch: 145 [2560/232365 (1%)]\tLoss: 172.195633\n",
            "Train Epoch: 145 [3840/232365 (2%)]\tLoss: 170.673080\n",
            "Train Epoch: 145 [5120/232365 (2%)]\tLoss: 165.843628\n",
            "Train Epoch: 145 [6400/232365 (3%)]\tLoss: 169.472534\n",
            "Train Epoch: 145 [7680/232365 (3%)]\tLoss: 175.631287\n",
            "Train Epoch: 145 [8960/232365 (4%)]\tLoss: 173.902985\n",
            "Train Epoch: 145 [10240/232365 (4%)]\tLoss: 172.500931\n",
            "Train Epoch: 145 [11520/232365 (5%)]\tLoss: 160.584747\n",
            "Train Epoch: 145 [12800/232365 (6%)]\tLoss: 179.542328\n",
            "Train Epoch: 145 [14080/232365 (6%)]\tLoss: 169.210373\n",
            "Train Epoch: 145 [15360/232365 (7%)]\tLoss: 177.749985\n",
            "Train Epoch: 145 [16640/232365 (7%)]\tLoss: 164.590118\n",
            "Train Epoch: 145 [17920/232365 (8%)]\tLoss: 175.149612\n",
            "Train Epoch: 145 [19200/232365 (8%)]\tLoss: 177.539139\n",
            "Train Epoch: 145 [20480/232365 (9%)]\tLoss: 171.870544\n",
            "Train Epoch: 145 [21760/232365 (9%)]\tLoss: 169.728989\n",
            "Train Epoch: 145 [23040/232365 (10%)]\tLoss: 184.013840\n",
            "Train Epoch: 145 [24320/232365 (10%)]\tLoss: 175.362244\n",
            "Train Epoch: 145 [25600/232365 (11%)]\tLoss: 177.753174\n",
            "Train Epoch: 145 [26880/232365 (12%)]\tLoss: 170.421906\n",
            "Train Epoch: 145 [28160/232365 (12%)]\tLoss: 176.818314\n",
            "Train Epoch: 145 [29440/232365 (13%)]\tLoss: 173.286301\n",
            "Train Epoch: 145 [30720/232365 (13%)]\tLoss: 173.772003\n",
            "Train Epoch: 145 [32000/232365 (14%)]\tLoss: 181.335495\n",
            "Train Epoch: 145 [33280/232365 (14%)]\tLoss: 174.994720\n",
            "Train Epoch: 145 [34560/232365 (15%)]\tLoss: 176.656342\n",
            "Train Epoch: 145 [35840/232365 (15%)]\tLoss: 175.549103\n",
            "Train Epoch: 145 [37120/232365 (16%)]\tLoss: 172.148743\n",
            "Train Epoch: 145 [38400/232365 (17%)]\tLoss: 171.435776\n",
            "Train Epoch: 145 [39680/232365 (17%)]\tLoss: 174.182190\n",
            "Train Epoch: 145 [40960/232365 (18%)]\tLoss: 169.411118\n",
            "Train Epoch: 145 [42240/232365 (18%)]\tLoss: 173.154175\n",
            "Train Epoch: 145 [43520/232365 (19%)]\tLoss: 177.334076\n",
            "Train Epoch: 145 [44800/232365 (19%)]\tLoss: 167.768372\n",
            "Train Epoch: 145 [46080/232365 (20%)]\tLoss: 169.086212\n",
            "Train Epoch: 145 [47360/232365 (20%)]\tLoss: 167.927322\n",
            "Train Epoch: 145 [48640/232365 (21%)]\tLoss: 163.620102\n",
            "Train Epoch: 145 [49920/232365 (21%)]\tLoss: 170.230164\n",
            "Train Epoch: 145 [51200/232365 (22%)]\tLoss: 173.393494\n",
            "Train Epoch: 145 [52480/232365 (23%)]\tLoss: 174.392944\n",
            "Train Epoch: 145 [53760/232365 (23%)]\tLoss: 172.064651\n",
            "Train Epoch: 145 [55040/232365 (24%)]\tLoss: 173.427307\n",
            "Train Epoch: 145 [56320/232365 (24%)]\tLoss: 173.632874\n",
            "Train Epoch: 145 [57600/232365 (25%)]\tLoss: 168.922623\n",
            "Train Epoch: 145 [58880/232365 (25%)]\tLoss: 161.752808\n",
            "Train Epoch: 145 [60160/232365 (26%)]\tLoss: 164.911407\n",
            "Train Epoch: 145 [61440/232365 (26%)]\tLoss: 165.549759\n",
            "Train Epoch: 145 [62720/232365 (27%)]\tLoss: 175.793640\n",
            "Train Epoch: 145 [64000/232365 (28%)]\tLoss: 168.396240\n",
            "Train Epoch: 145 [65280/232365 (28%)]\tLoss: 172.294266\n",
            "Train Epoch: 145 [66560/232365 (29%)]\tLoss: 173.242676\n",
            "Train Epoch: 145 [67840/232365 (29%)]\tLoss: 171.050781\n",
            "Train Epoch: 145 [69120/232365 (30%)]\tLoss: 166.648804\n",
            "Train Epoch: 145 [70400/232365 (30%)]\tLoss: 171.329742\n",
            "Train Epoch: 145 [71680/232365 (31%)]\tLoss: 167.937256\n",
            "Train Epoch: 145 [72960/232365 (31%)]\tLoss: 167.711075\n",
            "Train Epoch: 145 [74240/232365 (32%)]\tLoss: 176.916733\n",
            "Train Epoch: 145 [75520/232365 (32%)]\tLoss: 176.907104\n",
            "Train Epoch: 145 [76800/232365 (33%)]\tLoss: 173.377777\n",
            "Train Epoch: 145 [78080/232365 (34%)]\tLoss: 178.519302\n",
            "Train Epoch: 145 [79360/232365 (34%)]\tLoss: 174.713379\n",
            "Train Epoch: 145 [80640/232365 (35%)]\tLoss: 167.927109\n",
            "Train Epoch: 145 [81920/232365 (35%)]\tLoss: 178.830215\n",
            "Train Epoch: 145 [83200/232365 (36%)]\tLoss: 169.626099\n",
            "Train Epoch: 145 [84480/232365 (36%)]\tLoss: 171.032104\n",
            "Train Epoch: 145 [85760/232365 (37%)]\tLoss: 175.632248\n",
            "Train Epoch: 145 [87040/232365 (37%)]\tLoss: 176.862167\n",
            "Train Epoch: 145 [88320/232365 (38%)]\tLoss: 167.217575\n",
            "Train Epoch: 145 [89600/232365 (39%)]\tLoss: 167.710815\n",
            "Train Epoch: 145 [90880/232365 (39%)]\tLoss: 174.253143\n",
            "Train Epoch: 145 [92160/232365 (40%)]\tLoss: 176.424332\n",
            "Train Epoch: 145 [93440/232365 (40%)]\tLoss: 167.397827\n",
            "Train Epoch: 145 [94720/232365 (41%)]\tLoss: 166.789993\n",
            "Train Epoch: 145 [96000/232365 (41%)]\tLoss: 181.262802\n",
            "Train Epoch: 145 [97280/232365 (42%)]\tLoss: 171.445450\n",
            "Train Epoch: 145 [98560/232365 (42%)]\tLoss: 164.700302\n",
            "Train Epoch: 145 [99840/232365 (43%)]\tLoss: 164.079239\n",
            "Train Epoch: 145 [101120/232365 (44%)]\tLoss: 179.753220\n",
            "Train Epoch: 145 [102400/232365 (44%)]\tLoss: 170.051056\n",
            "Train Epoch: 145 [103680/232365 (45%)]\tLoss: 179.883698\n",
            "Train Epoch: 145 [104960/232365 (45%)]\tLoss: 181.366730\n",
            "Train Epoch: 145 [106240/232365 (46%)]\tLoss: 178.109192\n",
            "Train Epoch: 145 [107520/232365 (46%)]\tLoss: 172.335388\n",
            "Train Epoch: 145 [108800/232365 (47%)]\tLoss: 173.928299\n",
            "Train Epoch: 145 [110080/232365 (47%)]\tLoss: 176.907349\n",
            "Train Epoch: 145 [111360/232365 (48%)]\tLoss: 175.038239\n",
            "Train Epoch: 145 [112640/232365 (48%)]\tLoss: 180.758240\n",
            "Train Epoch: 145 [113920/232365 (49%)]\tLoss: 172.379974\n",
            "Train Epoch: 145 [115200/232365 (50%)]\tLoss: 172.931946\n",
            "Train Epoch: 145 [116480/232365 (50%)]\tLoss: 178.888916\n",
            "Train Epoch: 145 [117760/232365 (51%)]\tLoss: 169.686554\n",
            "Train Epoch: 145 [119040/232365 (51%)]\tLoss: 167.359940\n",
            "Train Epoch: 145 [120320/232365 (52%)]\tLoss: 180.474960\n",
            "Train Epoch: 145 [121600/232365 (52%)]\tLoss: 168.752609\n",
            "Train Epoch: 145 [122880/232365 (53%)]\tLoss: 171.309860\n",
            "Train Epoch: 145 [124160/232365 (53%)]\tLoss: 172.194168\n",
            "Train Epoch: 145 [125440/232365 (54%)]\tLoss: 166.527420\n",
            "Train Epoch: 145 [126720/232365 (55%)]\tLoss: 172.139069\n",
            "Train Epoch: 145 [128000/232365 (55%)]\tLoss: 165.557495\n",
            "Train Epoch: 145 [129280/232365 (56%)]\tLoss: 167.968338\n",
            "Train Epoch: 145 [130560/232365 (56%)]\tLoss: 163.572861\n",
            "Train Epoch: 145 [131840/232365 (57%)]\tLoss: 169.381653\n",
            "Train Epoch: 145 [133120/232365 (57%)]\tLoss: 180.849991\n",
            "Train Epoch: 145 [134400/232365 (58%)]\tLoss: 163.430222\n",
            "Train Epoch: 145 [135680/232365 (58%)]\tLoss: 172.557663\n",
            "Train Epoch: 145 [136960/232365 (59%)]\tLoss: 166.722931\n",
            "Train Epoch: 145 [138240/232365 (59%)]\tLoss: 172.242950\n",
            "Train Epoch: 145 [139520/232365 (60%)]\tLoss: 175.445740\n",
            "Train Epoch: 145 [140800/232365 (61%)]\tLoss: 180.370728\n",
            "Train Epoch: 145 [142080/232365 (61%)]\tLoss: 169.784348\n",
            "Train Epoch: 145 [143360/232365 (62%)]\tLoss: 179.852676\n",
            "Train Epoch: 145 [144640/232365 (62%)]\tLoss: 169.830414\n",
            "Train Epoch: 145 [145920/232365 (63%)]\tLoss: 171.527100\n",
            "Train Epoch: 145 [147200/232365 (63%)]\tLoss: 174.338821\n",
            "Train Epoch: 145 [148480/232365 (64%)]\tLoss: 173.533493\n",
            "Train Epoch: 145 [149760/232365 (64%)]\tLoss: 170.031372\n",
            "Train Epoch: 145 [151040/232365 (65%)]\tLoss: 162.871780\n",
            "Train Epoch: 145 [152320/232365 (66%)]\tLoss: 175.276123\n",
            "Train Epoch: 145 [153600/232365 (66%)]\tLoss: 168.752441\n",
            "Train Epoch: 145 [154880/232365 (67%)]\tLoss: 169.613342\n",
            "Train Epoch: 145 [156160/232365 (67%)]\tLoss: 169.925644\n",
            "Train Epoch: 145 [157440/232365 (68%)]\tLoss: 166.081680\n",
            "Train Epoch: 145 [158720/232365 (68%)]\tLoss: 165.573837\n",
            "Train Epoch: 145 [160000/232365 (69%)]\tLoss: 172.508759\n",
            "Train Epoch: 145 [161280/232365 (69%)]\tLoss: 182.436874\n",
            "Train Epoch: 145 [162560/232365 (70%)]\tLoss: 185.782257\n",
            "Train Epoch: 145 [163840/232365 (70%)]\tLoss: 171.174332\n",
            "Train Epoch: 145 [165120/232365 (71%)]\tLoss: 171.821991\n",
            "Train Epoch: 145 [166400/232365 (72%)]\tLoss: 176.086395\n",
            "Train Epoch: 145 [167680/232365 (72%)]\tLoss: 168.887650\n",
            "Train Epoch: 145 [168960/232365 (73%)]\tLoss: 161.409927\n",
            "Train Epoch: 145 [170240/232365 (73%)]\tLoss: 168.953934\n",
            "Train Epoch: 145 [171520/232365 (74%)]\tLoss: 169.171234\n",
            "Train Epoch: 145 [172800/232365 (74%)]\tLoss: 168.984985\n",
            "Train Epoch: 145 [174080/232365 (75%)]\tLoss: 177.612671\n",
            "Train Epoch: 145 [175360/232365 (75%)]\tLoss: 178.409515\n",
            "Train Epoch: 145 [176640/232365 (76%)]\tLoss: 167.881317\n",
            "Train Epoch: 145 [177920/232365 (77%)]\tLoss: 176.965637\n",
            "Train Epoch: 145 [179200/232365 (77%)]\tLoss: 176.424698\n",
            "Train Epoch: 145 [180480/232365 (78%)]\tLoss: 165.839783\n",
            "Train Epoch: 145 [181760/232365 (78%)]\tLoss: 168.970551\n",
            "Train Epoch: 145 [183040/232365 (79%)]\tLoss: 166.284973\n",
            "Train Epoch: 145 [184320/232365 (79%)]\tLoss: 160.308716\n",
            "Train Epoch: 145 [185600/232365 (80%)]\tLoss: 175.113831\n",
            "Train Epoch: 145 [186880/232365 (80%)]\tLoss: 169.580780\n",
            "Train Epoch: 145 [188160/232365 (81%)]\tLoss: 173.344330\n",
            "Train Epoch: 145 [189440/232365 (81%)]\tLoss: 175.925858\n",
            "Train Epoch: 145 [190720/232365 (82%)]\tLoss: 178.414246\n",
            "Train Epoch: 145 [192000/232365 (83%)]\tLoss: 178.973358\n",
            "Train Epoch: 145 [193280/232365 (83%)]\tLoss: 174.517365\n",
            "Train Epoch: 145 [194560/232365 (84%)]\tLoss: 160.471130\n",
            "Train Epoch: 145 [195840/232365 (84%)]\tLoss: 170.088806\n",
            "Train Epoch: 145 [197120/232365 (85%)]\tLoss: 167.068253\n",
            "Train Epoch: 145 [198400/232365 (85%)]\tLoss: 170.780136\n",
            "Train Epoch: 145 [199680/232365 (86%)]\tLoss: 179.514740\n",
            "Train Epoch: 145 [200960/232365 (86%)]\tLoss: 174.930832\n",
            "Train Epoch: 145 [202240/232365 (87%)]\tLoss: 181.334229\n",
            "Train Epoch: 145 [203520/232365 (88%)]\tLoss: 171.270966\n",
            "Train Epoch: 145 [204800/232365 (88%)]\tLoss: 171.262283\n",
            "Train Epoch: 145 [206080/232365 (89%)]\tLoss: 167.427734\n",
            "Train Epoch: 145 [207360/232365 (89%)]\tLoss: 177.847809\n",
            "Train Epoch: 145 [208640/232365 (90%)]\tLoss: 171.137756\n",
            "Train Epoch: 145 [209920/232365 (90%)]\tLoss: 179.141739\n",
            "Train Epoch: 145 [211200/232365 (91%)]\tLoss: 170.882156\n",
            "Train Epoch: 145 [212480/232365 (91%)]\tLoss: 171.017471\n",
            "Train Epoch: 145 [213760/232365 (92%)]\tLoss: 169.345154\n",
            "Train Epoch: 145 [215040/232365 (93%)]\tLoss: 175.481155\n",
            "Train Epoch: 145 [216320/232365 (93%)]\tLoss: 171.330994\n",
            "Train Epoch: 145 [217600/232365 (94%)]\tLoss: 176.500626\n",
            "Train Epoch: 145 [218880/232365 (94%)]\tLoss: 177.079498\n",
            "Train Epoch: 145 [220160/232365 (95%)]\tLoss: 171.265671\n",
            "Train Epoch: 145 [221440/232365 (95%)]\tLoss: 170.554794\n",
            "Train Epoch: 145 [222720/232365 (96%)]\tLoss: 173.444366\n",
            "Train Epoch: 145 [224000/232365 (96%)]\tLoss: 169.636017\n",
            "Train Epoch: 145 [225280/232365 (97%)]\tLoss: 167.011765\n",
            "Train Epoch: 145 [226560/232365 (97%)]\tLoss: 171.002167\n",
            "Train Epoch: 145 [227840/232365 (98%)]\tLoss: 166.350677\n",
            "Train Epoch: 145 [229120/232365 (99%)]\tLoss: 168.284317\n",
            "Train Epoch: 145 [230400/232365 (99%)]\tLoss: 172.461655\n",
            "Train Epoch: 145 [231680/232365 (100%)]\tLoss: 175.518173\n",
            "====> Epoch: 145 Average loss: 172.4314, Accuracy: 74.24%\n",
            "====> Test set loss: 183.6217, Accuracy: 74.11%\n",
            "Train Epoch: 146 [0/232365 (0%)]\tLoss: 176.315491\n",
            "Train Epoch: 146 [1280/232365 (1%)]\tLoss: 177.781357\n",
            "Train Epoch: 146 [2560/232365 (1%)]\tLoss: 177.181732\n",
            "Train Epoch: 146 [3840/232365 (2%)]\tLoss: 165.323380\n",
            "Train Epoch: 146 [5120/232365 (2%)]\tLoss: 180.338394\n",
            "Train Epoch: 146 [6400/232365 (3%)]\tLoss: 174.240936\n",
            "Train Epoch: 146 [7680/232365 (3%)]\tLoss: 165.632019\n",
            "Train Epoch: 146 [8960/232365 (4%)]\tLoss: 174.674133\n",
            "Train Epoch: 146 [10240/232365 (4%)]\tLoss: 170.461197\n",
            "Train Epoch: 146 [11520/232365 (5%)]\tLoss: 175.331924\n",
            "Train Epoch: 146 [12800/232365 (6%)]\tLoss: 176.143265\n",
            "Train Epoch: 146 [14080/232365 (6%)]\tLoss: 169.630692\n",
            "Train Epoch: 146 [15360/232365 (7%)]\tLoss: 171.083572\n",
            "Train Epoch: 146 [16640/232365 (7%)]\tLoss: 171.922668\n",
            "Train Epoch: 146 [17920/232365 (8%)]\tLoss: 172.114487\n",
            "Train Epoch: 146 [19200/232365 (8%)]\tLoss: 171.835480\n",
            "Train Epoch: 146 [20480/232365 (9%)]\tLoss: 182.365692\n",
            "Train Epoch: 146 [21760/232365 (9%)]\tLoss: 170.086838\n",
            "Train Epoch: 146 [23040/232365 (10%)]\tLoss: 174.017075\n",
            "Train Epoch: 146 [24320/232365 (10%)]\tLoss: 169.474030\n",
            "Train Epoch: 146 [25600/232365 (11%)]\tLoss: 171.502167\n",
            "Train Epoch: 146 [26880/232365 (12%)]\tLoss: 181.508667\n",
            "Train Epoch: 146 [28160/232365 (12%)]\tLoss: 173.786545\n",
            "Train Epoch: 146 [29440/232365 (13%)]\tLoss: 174.035965\n",
            "Train Epoch: 146 [30720/232365 (13%)]\tLoss: 170.891266\n",
            "Train Epoch: 146 [32000/232365 (14%)]\tLoss: 165.585709\n",
            "Train Epoch: 146 [33280/232365 (14%)]\tLoss: 177.016388\n",
            "Train Epoch: 146 [34560/232365 (15%)]\tLoss: 171.949860\n",
            "Train Epoch: 146 [35840/232365 (15%)]\tLoss: 158.630386\n",
            "Train Epoch: 146 [37120/232365 (16%)]\tLoss: 169.129883\n",
            "Train Epoch: 146 [38400/232365 (17%)]\tLoss: 169.841843\n",
            "Train Epoch: 146 [39680/232365 (17%)]\tLoss: 160.383835\n",
            "Train Epoch: 146 [40960/232365 (18%)]\tLoss: 178.475739\n",
            "Train Epoch: 146 [42240/232365 (18%)]\tLoss: 168.137314\n",
            "Train Epoch: 146 [43520/232365 (19%)]\tLoss: 171.760330\n",
            "Train Epoch: 146 [44800/232365 (19%)]\tLoss: 169.874100\n",
            "Train Epoch: 146 [46080/232365 (20%)]\tLoss: 169.945557\n",
            "Train Epoch: 146 [47360/232365 (20%)]\tLoss: 168.727554\n",
            "Train Epoch: 146 [48640/232365 (21%)]\tLoss: 171.081604\n",
            "Train Epoch: 146 [49920/232365 (21%)]\tLoss: 175.235443\n",
            "Train Epoch: 146 [51200/232365 (22%)]\tLoss: 173.451935\n",
            "Train Epoch: 146 [52480/232365 (23%)]\tLoss: 176.458588\n",
            "Train Epoch: 146 [53760/232365 (23%)]\tLoss: 182.481796\n",
            "Train Epoch: 146 [55040/232365 (24%)]\tLoss: 175.566864\n",
            "Train Epoch: 146 [56320/232365 (24%)]\tLoss: 182.085571\n",
            "Train Epoch: 146 [57600/232365 (25%)]\tLoss: 165.915771\n",
            "Train Epoch: 146 [58880/232365 (25%)]\tLoss: 171.764359\n",
            "Train Epoch: 146 [60160/232365 (26%)]\tLoss: 167.633606\n",
            "Train Epoch: 146 [61440/232365 (26%)]\tLoss: 169.494781\n",
            "Train Epoch: 146 [62720/232365 (27%)]\tLoss: 173.748627\n",
            "Train Epoch: 146 [64000/232365 (28%)]\tLoss: 167.556274\n",
            "Train Epoch: 146 [65280/232365 (28%)]\tLoss: 178.034210\n",
            "Train Epoch: 146 [66560/232365 (29%)]\tLoss: 173.173309\n",
            "Train Epoch: 146 [67840/232365 (29%)]\tLoss: 172.063202\n",
            "Train Epoch: 146 [69120/232365 (30%)]\tLoss: 172.311829\n",
            "Train Epoch: 146 [70400/232365 (30%)]\tLoss: 177.369217\n",
            "Train Epoch: 146 [71680/232365 (31%)]\tLoss: 168.504761\n",
            "Train Epoch: 146 [72960/232365 (31%)]\tLoss: 170.026764\n",
            "Train Epoch: 146 [74240/232365 (32%)]\tLoss: 177.202026\n",
            "Train Epoch: 146 [75520/232365 (32%)]\tLoss: 171.446304\n",
            "Train Epoch: 146 [76800/232365 (33%)]\tLoss: 179.780121\n",
            "Train Epoch: 146 [78080/232365 (34%)]\tLoss: 175.949661\n",
            "Train Epoch: 146 [79360/232365 (34%)]\tLoss: 169.375214\n",
            "Train Epoch: 146 [80640/232365 (35%)]\tLoss: 171.860565\n",
            "Train Epoch: 146 [81920/232365 (35%)]\tLoss: 175.484497\n",
            "Train Epoch: 146 [83200/232365 (36%)]\tLoss: 172.356171\n",
            "Train Epoch: 146 [84480/232365 (36%)]\tLoss: 173.593048\n",
            "Train Epoch: 146 [85760/232365 (37%)]\tLoss: 160.573517\n",
            "Train Epoch: 146 [87040/232365 (37%)]\tLoss: 169.174728\n",
            "Train Epoch: 146 [88320/232365 (38%)]\tLoss: 172.006958\n",
            "Train Epoch: 146 [89600/232365 (39%)]\tLoss: 160.624878\n",
            "Train Epoch: 146 [90880/232365 (39%)]\tLoss: 162.324585\n",
            "Train Epoch: 146 [92160/232365 (40%)]\tLoss: 168.960342\n",
            "Train Epoch: 146 [93440/232365 (40%)]\tLoss: 163.633453\n",
            "Train Epoch: 146 [94720/232365 (41%)]\tLoss: 177.310593\n",
            "Train Epoch: 146 [96000/232365 (41%)]\tLoss: 169.199463\n",
            "Train Epoch: 146 [97280/232365 (42%)]\tLoss: 165.921463\n",
            "Train Epoch: 146 [98560/232365 (42%)]\tLoss: 176.551865\n",
            "Train Epoch: 146 [99840/232365 (43%)]\tLoss: 170.711884\n",
            "Train Epoch: 146 [101120/232365 (44%)]\tLoss: 169.024277\n",
            "Train Epoch: 146 [102400/232365 (44%)]\tLoss: 172.348602\n",
            "Train Epoch: 146 [103680/232365 (45%)]\tLoss: 167.723389\n",
            "Train Epoch: 146 [104960/232365 (45%)]\tLoss: 168.304993\n",
            "Train Epoch: 146 [106240/232365 (46%)]\tLoss: 166.818878\n",
            "Train Epoch: 146 [107520/232365 (46%)]\tLoss: 171.352371\n",
            "Train Epoch: 146 [108800/232365 (47%)]\tLoss: 184.066483\n",
            "Train Epoch: 146 [110080/232365 (47%)]\tLoss: 173.063202\n",
            "Train Epoch: 146 [111360/232365 (48%)]\tLoss: 169.005402\n",
            "Train Epoch: 146 [112640/232365 (48%)]\tLoss: 171.707108\n",
            "Train Epoch: 146 [113920/232365 (49%)]\tLoss: 176.460495\n",
            "Train Epoch: 146 [115200/232365 (50%)]\tLoss: 183.770355\n",
            "Train Epoch: 146 [116480/232365 (50%)]\tLoss: 177.572021\n",
            "Train Epoch: 146 [117760/232365 (51%)]\tLoss: 171.340820\n",
            "Train Epoch: 146 [119040/232365 (51%)]\tLoss: 185.547943\n",
            "Train Epoch: 146 [120320/232365 (52%)]\tLoss: 171.547592\n",
            "Train Epoch: 146 [121600/232365 (52%)]\tLoss: 176.808212\n",
            "Train Epoch: 146 [122880/232365 (53%)]\tLoss: 185.632355\n",
            "Train Epoch: 146 [124160/232365 (53%)]\tLoss: 178.498077\n",
            "Train Epoch: 146 [125440/232365 (54%)]\tLoss: 174.155273\n",
            "Train Epoch: 146 [126720/232365 (55%)]\tLoss: 170.504440\n",
            "Train Epoch: 146 [128000/232365 (55%)]\tLoss: 175.233139\n",
            "Train Epoch: 146 [129280/232365 (56%)]\tLoss: 178.050705\n",
            "Train Epoch: 146 [130560/232365 (56%)]\tLoss: 169.295105\n",
            "Train Epoch: 146 [131840/232365 (57%)]\tLoss: 172.471893\n",
            "Train Epoch: 146 [133120/232365 (57%)]\tLoss: 175.528427\n",
            "Train Epoch: 146 [134400/232365 (58%)]\tLoss: 173.419281\n",
            "Train Epoch: 146 [135680/232365 (58%)]\tLoss: 181.642242\n",
            "Train Epoch: 146 [136960/232365 (59%)]\tLoss: 175.924072\n",
            "Train Epoch: 146 [138240/232365 (59%)]\tLoss: 174.592194\n",
            "Train Epoch: 146 [139520/232365 (60%)]\tLoss: 167.767181\n",
            "Train Epoch: 146 [140800/232365 (61%)]\tLoss: 166.794037\n",
            "Train Epoch: 146 [142080/232365 (61%)]\tLoss: 172.635971\n",
            "Train Epoch: 146 [143360/232365 (62%)]\tLoss: 172.255066\n",
            "Train Epoch: 146 [144640/232365 (62%)]\tLoss: 169.329285\n",
            "Train Epoch: 146 [145920/232365 (63%)]\tLoss: 178.546524\n",
            "Train Epoch: 146 [147200/232365 (63%)]\tLoss: 171.195129\n",
            "Train Epoch: 146 [148480/232365 (64%)]\tLoss: 177.900909\n",
            "Train Epoch: 146 [149760/232365 (64%)]\tLoss: 171.588242\n",
            "Train Epoch: 146 [151040/232365 (65%)]\tLoss: 188.751862\n",
            "Train Epoch: 146 [152320/232365 (66%)]\tLoss: 159.650314\n",
            "Train Epoch: 146 [153600/232365 (66%)]\tLoss: 166.028534\n",
            "Train Epoch: 146 [154880/232365 (67%)]\tLoss: 169.053635\n",
            "Train Epoch: 146 [156160/232365 (67%)]\tLoss: 164.307388\n",
            "Train Epoch: 146 [157440/232365 (68%)]\tLoss: 180.903595\n",
            "Train Epoch: 146 [158720/232365 (68%)]\tLoss: 167.358444\n",
            "Train Epoch: 146 [160000/232365 (69%)]\tLoss: 169.093094\n",
            "Train Epoch: 146 [161280/232365 (69%)]\tLoss: 171.750534\n",
            "Train Epoch: 146 [162560/232365 (70%)]\tLoss: 177.543594\n",
            "Train Epoch: 146 [163840/232365 (70%)]\tLoss: 175.994720\n",
            "Train Epoch: 146 [165120/232365 (71%)]\tLoss: 172.519989\n",
            "Train Epoch: 146 [166400/232365 (72%)]\tLoss: 178.126053\n",
            "Train Epoch: 146 [167680/232365 (72%)]\tLoss: 164.439438\n",
            "Train Epoch: 146 [168960/232365 (73%)]\tLoss: 159.038635\n",
            "Train Epoch: 146 [170240/232365 (73%)]\tLoss: 170.074097\n",
            "Train Epoch: 146 [171520/232365 (74%)]\tLoss: 165.192795\n",
            "Train Epoch: 146 [172800/232365 (74%)]\tLoss: 168.219437\n",
            "Train Epoch: 146 [174080/232365 (75%)]\tLoss: 182.492264\n",
            "Train Epoch: 146 [175360/232365 (75%)]\tLoss: 164.665024\n",
            "Train Epoch: 146 [176640/232365 (76%)]\tLoss: 177.167130\n",
            "Train Epoch: 146 [177920/232365 (77%)]\tLoss: 170.019577\n",
            "Train Epoch: 146 [179200/232365 (77%)]\tLoss: 166.767258\n",
            "Train Epoch: 146 [180480/232365 (78%)]\tLoss: 176.556351\n",
            "Train Epoch: 146 [181760/232365 (78%)]\tLoss: 170.821976\n",
            "Train Epoch: 146 [183040/232365 (79%)]\tLoss: 163.908661\n",
            "Train Epoch: 146 [184320/232365 (79%)]\tLoss: 173.894836\n",
            "Train Epoch: 146 [185600/232365 (80%)]\tLoss: 167.768936\n",
            "Train Epoch: 146 [186880/232365 (80%)]\tLoss: 173.113922\n",
            "Train Epoch: 146 [188160/232365 (81%)]\tLoss: 171.851089\n",
            "Train Epoch: 146 [189440/232365 (81%)]\tLoss: 176.567505\n",
            "Train Epoch: 146 [190720/232365 (82%)]\tLoss: 177.410080\n",
            "Train Epoch: 146 [192000/232365 (83%)]\tLoss: 176.144119\n",
            "Train Epoch: 146 [193280/232365 (83%)]\tLoss: 178.351624\n",
            "Train Epoch: 146 [194560/232365 (84%)]\tLoss: 179.443573\n",
            "Train Epoch: 146 [195840/232365 (84%)]\tLoss: 174.531158\n",
            "Train Epoch: 146 [197120/232365 (85%)]\tLoss: 172.506332\n",
            "Train Epoch: 146 [198400/232365 (85%)]\tLoss: 175.469208\n",
            "Train Epoch: 146 [199680/232365 (86%)]\tLoss: 181.385345\n",
            "Train Epoch: 146 [200960/232365 (86%)]\tLoss: 174.128525\n",
            "Train Epoch: 146 [202240/232365 (87%)]\tLoss: 172.276688\n",
            "Train Epoch: 146 [203520/232365 (88%)]\tLoss: 171.180389\n",
            "Train Epoch: 146 [204800/232365 (88%)]\tLoss: 176.800308\n",
            "Train Epoch: 146 [206080/232365 (89%)]\tLoss: 177.872238\n",
            "Train Epoch: 146 [207360/232365 (89%)]\tLoss: 179.976974\n",
            "Train Epoch: 146 [208640/232365 (90%)]\tLoss: 178.553864\n",
            "Train Epoch: 146 [209920/232365 (90%)]\tLoss: 170.777664\n",
            "Train Epoch: 146 [211200/232365 (91%)]\tLoss: 170.380081\n",
            "Train Epoch: 146 [212480/232365 (91%)]\tLoss: 180.858826\n",
            "Train Epoch: 146 [213760/232365 (92%)]\tLoss: 168.621780\n",
            "Train Epoch: 146 [215040/232365 (93%)]\tLoss: 166.853241\n",
            "Train Epoch: 146 [216320/232365 (93%)]\tLoss: 171.922043\n",
            "Train Epoch: 146 [217600/232365 (94%)]\tLoss: 172.109634\n",
            "Train Epoch: 146 [218880/232365 (94%)]\tLoss: 176.264847\n",
            "Train Epoch: 146 [220160/232365 (95%)]\tLoss: 163.825790\n",
            "Train Epoch: 146 [221440/232365 (95%)]\tLoss: 170.905945\n",
            "Train Epoch: 146 [222720/232365 (96%)]\tLoss: 172.357483\n",
            "Train Epoch: 146 [224000/232365 (96%)]\tLoss: 169.591522\n",
            "Train Epoch: 146 [225280/232365 (97%)]\tLoss: 168.756424\n",
            "Train Epoch: 146 [226560/232365 (97%)]\tLoss: 177.111969\n",
            "Train Epoch: 146 [227840/232365 (98%)]\tLoss: 179.213226\n",
            "Train Epoch: 146 [229120/232365 (99%)]\tLoss: 177.462677\n",
            "Train Epoch: 146 [230400/232365 (99%)]\tLoss: 164.697586\n",
            "Train Epoch: 146 [231680/232365 (100%)]\tLoss: 178.133301\n",
            "====> Epoch: 146 Average loss: 172.4068, Accuracy: 74.24%\n",
            "====> Test set loss: 183.5299, Accuracy: 74.13%\n",
            "Train Epoch: 147 [0/232365 (0%)]\tLoss: 176.365295\n",
            "Train Epoch: 147 [1280/232365 (1%)]\tLoss: 174.875946\n",
            "Train Epoch: 147 [2560/232365 (1%)]\tLoss: 167.398682\n",
            "Train Epoch: 147 [3840/232365 (2%)]\tLoss: 178.466827\n",
            "Train Epoch: 147 [5120/232365 (2%)]\tLoss: 169.276245\n",
            "Train Epoch: 147 [6400/232365 (3%)]\tLoss: 173.473053\n",
            "Train Epoch: 147 [7680/232365 (3%)]\tLoss: 159.826477\n",
            "Train Epoch: 147 [8960/232365 (4%)]\tLoss: 173.679749\n",
            "Train Epoch: 147 [10240/232365 (4%)]\tLoss: 171.432129\n",
            "Train Epoch: 147 [11520/232365 (5%)]\tLoss: 168.921951\n",
            "Train Epoch: 147 [12800/232365 (6%)]\tLoss: 175.301147\n",
            "Train Epoch: 147 [14080/232365 (6%)]\tLoss: 163.800354\n",
            "Train Epoch: 147 [15360/232365 (7%)]\tLoss: 165.209305\n",
            "Train Epoch: 147 [16640/232365 (7%)]\tLoss: 166.106812\n",
            "Train Epoch: 147 [17920/232365 (8%)]\tLoss: 173.580994\n",
            "Train Epoch: 147 [19200/232365 (8%)]\tLoss: 177.963074\n",
            "Train Epoch: 147 [20480/232365 (9%)]\tLoss: 167.818726\n",
            "Train Epoch: 147 [21760/232365 (9%)]\tLoss: 165.691452\n",
            "Train Epoch: 147 [23040/232365 (10%)]\tLoss: 161.874329\n",
            "Train Epoch: 147 [24320/232365 (10%)]\tLoss: 180.330704\n",
            "Train Epoch: 147 [25600/232365 (11%)]\tLoss: 174.131561\n",
            "Train Epoch: 147 [26880/232365 (12%)]\tLoss: 176.196930\n",
            "Train Epoch: 147 [28160/232365 (12%)]\tLoss: 166.569229\n",
            "Train Epoch: 147 [29440/232365 (13%)]\tLoss: 172.397034\n",
            "Train Epoch: 147 [30720/232365 (13%)]\tLoss: 176.740509\n",
            "Train Epoch: 147 [32000/232365 (14%)]\tLoss: 173.873932\n",
            "Train Epoch: 147 [33280/232365 (14%)]\tLoss: 180.793991\n",
            "Train Epoch: 147 [34560/232365 (15%)]\tLoss: 169.718246\n",
            "Train Epoch: 147 [35840/232365 (15%)]\tLoss: 169.181686\n",
            "Train Epoch: 147 [37120/232365 (16%)]\tLoss: 165.966232\n",
            "Train Epoch: 147 [38400/232365 (17%)]\tLoss: 176.233307\n",
            "Train Epoch: 147 [39680/232365 (17%)]\tLoss: 172.372665\n",
            "Train Epoch: 147 [40960/232365 (18%)]\tLoss: 170.237183\n",
            "Train Epoch: 147 [42240/232365 (18%)]\tLoss: 170.684906\n",
            "Train Epoch: 147 [43520/232365 (19%)]\tLoss: 175.458862\n",
            "Train Epoch: 147 [44800/232365 (19%)]\tLoss: 165.210678\n",
            "Train Epoch: 147 [46080/232365 (20%)]\tLoss: 169.565399\n",
            "Train Epoch: 147 [47360/232365 (20%)]\tLoss: 175.291122\n",
            "Train Epoch: 147 [48640/232365 (21%)]\tLoss: 174.977356\n",
            "Train Epoch: 147 [49920/232365 (21%)]\tLoss: 170.149628\n",
            "Train Epoch: 147 [51200/232365 (22%)]\tLoss: 168.697861\n",
            "Train Epoch: 147 [52480/232365 (23%)]\tLoss: 172.838043\n",
            "Train Epoch: 147 [53760/232365 (23%)]\tLoss: 166.919373\n",
            "Train Epoch: 147 [55040/232365 (24%)]\tLoss: 172.921600\n",
            "Train Epoch: 147 [56320/232365 (24%)]\tLoss: 172.117737\n",
            "Train Epoch: 147 [57600/232365 (25%)]\tLoss: 165.167328\n",
            "Train Epoch: 147 [58880/232365 (25%)]\tLoss: 161.397659\n",
            "Train Epoch: 147 [60160/232365 (26%)]\tLoss: 164.477234\n",
            "Train Epoch: 147 [61440/232365 (26%)]\tLoss: 171.601776\n",
            "Train Epoch: 147 [62720/232365 (27%)]\tLoss: 169.782288\n",
            "Train Epoch: 147 [64000/232365 (28%)]\tLoss: 163.618164\n",
            "Train Epoch: 147 [65280/232365 (28%)]\tLoss: 178.347260\n",
            "Train Epoch: 147 [66560/232365 (29%)]\tLoss: 166.171082\n",
            "Train Epoch: 147 [67840/232365 (29%)]\tLoss: 175.454224\n",
            "Train Epoch: 147 [69120/232365 (30%)]\tLoss: 165.824280\n",
            "Train Epoch: 147 [70400/232365 (30%)]\tLoss: 176.942169\n",
            "Train Epoch: 147 [71680/232365 (31%)]\tLoss: 164.819702\n",
            "Train Epoch: 147 [72960/232365 (31%)]\tLoss: 169.047684\n",
            "Train Epoch: 147 [74240/232365 (32%)]\tLoss: 174.199493\n",
            "Train Epoch: 147 [75520/232365 (32%)]\tLoss: 174.257339\n",
            "Train Epoch: 147 [76800/232365 (33%)]\tLoss: 173.398041\n",
            "Train Epoch: 147 [78080/232365 (34%)]\tLoss: 171.398438\n",
            "Train Epoch: 147 [79360/232365 (34%)]\tLoss: 176.007767\n",
            "Train Epoch: 147 [80640/232365 (35%)]\tLoss: 178.085663\n",
            "Train Epoch: 147 [81920/232365 (35%)]\tLoss: 175.580505\n",
            "Train Epoch: 147 [83200/232365 (36%)]\tLoss: 167.490875\n",
            "Train Epoch: 147 [84480/232365 (36%)]\tLoss: 170.584671\n",
            "Train Epoch: 147 [85760/232365 (37%)]\tLoss: 176.366440\n",
            "Train Epoch: 147 [87040/232365 (37%)]\tLoss: 171.108261\n",
            "Train Epoch: 147 [88320/232365 (38%)]\tLoss: 175.483093\n",
            "Train Epoch: 147 [89600/232365 (39%)]\tLoss: 175.474838\n",
            "Train Epoch: 147 [90880/232365 (39%)]\tLoss: 166.181549\n",
            "Train Epoch: 147 [92160/232365 (40%)]\tLoss: 176.317413\n",
            "Train Epoch: 147 [93440/232365 (40%)]\tLoss: 169.171509\n",
            "Train Epoch: 147 [94720/232365 (41%)]\tLoss: 171.088562\n",
            "Train Epoch: 147 [96000/232365 (41%)]\tLoss: 170.481873\n",
            "Train Epoch: 147 [97280/232365 (42%)]\tLoss: 173.907837\n",
            "Train Epoch: 147 [98560/232365 (42%)]\tLoss: 179.772522\n",
            "Train Epoch: 147 [99840/232365 (43%)]\tLoss: 186.762817\n",
            "Train Epoch: 147 [101120/232365 (44%)]\tLoss: 167.636917\n",
            "Train Epoch: 147 [102400/232365 (44%)]\tLoss: 167.534332\n",
            "Train Epoch: 147 [103680/232365 (45%)]\tLoss: 165.633575\n",
            "Train Epoch: 147 [104960/232365 (45%)]\tLoss: 177.063217\n",
            "Train Epoch: 147 [106240/232365 (46%)]\tLoss: 171.279572\n",
            "Train Epoch: 147 [107520/232365 (46%)]\tLoss: 176.984726\n",
            "Train Epoch: 147 [108800/232365 (47%)]\tLoss: 171.068726\n",
            "Train Epoch: 147 [110080/232365 (47%)]\tLoss: 175.704803\n",
            "Train Epoch: 147 [111360/232365 (48%)]\tLoss: 164.304932\n",
            "Train Epoch: 147 [112640/232365 (48%)]\tLoss: 170.259552\n",
            "Train Epoch: 147 [113920/232365 (49%)]\tLoss: 171.472977\n",
            "Train Epoch: 147 [115200/232365 (50%)]\tLoss: 177.924088\n",
            "Train Epoch: 147 [116480/232365 (50%)]\tLoss: 172.438477\n",
            "Train Epoch: 147 [117760/232365 (51%)]\tLoss: 160.549911\n",
            "Train Epoch: 147 [119040/232365 (51%)]\tLoss: 173.994690\n",
            "Train Epoch: 147 [120320/232365 (52%)]\tLoss: 172.803864\n",
            "Train Epoch: 147 [121600/232365 (52%)]\tLoss: 177.526947\n",
            "Train Epoch: 147 [122880/232365 (53%)]\tLoss: 171.881516\n",
            "Train Epoch: 147 [124160/232365 (53%)]\tLoss: 175.942093\n",
            "Train Epoch: 147 [125440/232365 (54%)]\tLoss: 174.942429\n",
            "Train Epoch: 147 [126720/232365 (55%)]\tLoss: 171.981201\n",
            "Train Epoch: 147 [128000/232365 (55%)]\tLoss: 165.469284\n",
            "Train Epoch: 147 [129280/232365 (56%)]\tLoss: 171.403137\n",
            "Train Epoch: 147 [130560/232365 (56%)]\tLoss: 181.446930\n",
            "Train Epoch: 147 [131840/232365 (57%)]\tLoss: 178.724884\n",
            "Train Epoch: 147 [133120/232365 (57%)]\tLoss: 180.288361\n",
            "Train Epoch: 147 [134400/232365 (58%)]\tLoss: 173.667587\n",
            "Train Epoch: 147 [135680/232365 (58%)]\tLoss: 173.415222\n",
            "Train Epoch: 147 [136960/232365 (59%)]\tLoss: 178.804489\n",
            "Train Epoch: 147 [138240/232365 (59%)]\tLoss: 173.823639\n",
            "Train Epoch: 147 [139520/232365 (60%)]\tLoss: 180.866562\n",
            "Train Epoch: 147 [140800/232365 (61%)]\tLoss: 160.324478\n",
            "Train Epoch: 147 [142080/232365 (61%)]\tLoss: 164.475571\n",
            "Train Epoch: 147 [143360/232365 (62%)]\tLoss: 168.503052\n",
            "Train Epoch: 147 [144640/232365 (62%)]\tLoss: 178.714966\n",
            "Train Epoch: 147 [145920/232365 (63%)]\tLoss: 166.194122\n",
            "Train Epoch: 147 [147200/232365 (63%)]\tLoss: 185.015900\n",
            "Train Epoch: 147 [148480/232365 (64%)]\tLoss: 177.652985\n",
            "Train Epoch: 147 [149760/232365 (64%)]\tLoss: 173.427368\n",
            "Train Epoch: 147 [151040/232365 (65%)]\tLoss: 181.230652\n",
            "Train Epoch: 147 [152320/232365 (66%)]\tLoss: 175.425430\n",
            "Train Epoch: 147 [153600/232365 (66%)]\tLoss: 176.069336\n",
            "Train Epoch: 147 [154880/232365 (67%)]\tLoss: 168.730011\n",
            "Train Epoch: 147 [156160/232365 (67%)]\tLoss: 172.096497\n",
            "Train Epoch: 147 [157440/232365 (68%)]\tLoss: 173.897446\n",
            "Train Epoch: 147 [158720/232365 (68%)]\tLoss: 175.520355\n",
            "Train Epoch: 147 [160000/232365 (69%)]\tLoss: 175.515640\n",
            "Train Epoch: 147 [161280/232365 (69%)]\tLoss: 164.148804\n",
            "Train Epoch: 147 [162560/232365 (70%)]\tLoss: 169.249268\n",
            "Train Epoch: 147 [163840/232365 (70%)]\tLoss: 183.146866\n",
            "Train Epoch: 147 [165120/232365 (71%)]\tLoss: 171.953766\n",
            "Train Epoch: 147 [166400/232365 (72%)]\tLoss: 180.247467\n",
            "Train Epoch: 147 [167680/232365 (72%)]\tLoss: 175.522903\n",
            "Train Epoch: 147 [168960/232365 (73%)]\tLoss: 162.549896\n",
            "Train Epoch: 147 [170240/232365 (73%)]\tLoss: 166.916901\n",
            "Train Epoch: 147 [171520/232365 (74%)]\tLoss: 169.750198\n",
            "Train Epoch: 147 [172800/232365 (74%)]\tLoss: 170.200974\n",
            "Train Epoch: 147 [174080/232365 (75%)]\tLoss: 181.582794\n",
            "Train Epoch: 147 [175360/232365 (75%)]\tLoss: 166.721115\n",
            "Train Epoch: 147 [176640/232365 (76%)]\tLoss: 177.837234\n",
            "Train Epoch: 147 [177920/232365 (77%)]\tLoss: 168.542374\n",
            "Train Epoch: 147 [179200/232365 (77%)]\tLoss: 170.133102\n",
            "Train Epoch: 147 [180480/232365 (78%)]\tLoss: 173.262680\n",
            "Train Epoch: 147 [181760/232365 (78%)]\tLoss: 183.450775\n",
            "Train Epoch: 147 [183040/232365 (79%)]\tLoss: 169.577942\n",
            "Train Epoch: 147 [184320/232365 (79%)]\tLoss: 172.517868\n",
            "Train Epoch: 147 [185600/232365 (80%)]\tLoss: 180.245331\n",
            "Train Epoch: 147 [186880/232365 (80%)]\tLoss: 174.396576\n",
            "Train Epoch: 147 [188160/232365 (81%)]\tLoss: 164.566040\n",
            "Train Epoch: 147 [189440/232365 (81%)]\tLoss: 174.718460\n",
            "Train Epoch: 147 [190720/232365 (82%)]\tLoss: 166.535187\n",
            "Train Epoch: 147 [192000/232365 (83%)]\tLoss: 172.231888\n",
            "Train Epoch: 147 [193280/232365 (83%)]\tLoss: 175.405579\n",
            "Train Epoch: 147 [194560/232365 (84%)]\tLoss: 187.684525\n",
            "Train Epoch: 147 [195840/232365 (84%)]\tLoss: 166.203918\n",
            "Train Epoch: 147 [197120/232365 (85%)]\tLoss: 174.358643\n",
            "Train Epoch: 147 [198400/232365 (85%)]\tLoss: 163.718781\n",
            "Train Epoch: 147 [199680/232365 (86%)]\tLoss: 179.428024\n",
            "Train Epoch: 147 [200960/232365 (86%)]\tLoss: 174.860245\n",
            "Train Epoch: 147 [202240/232365 (87%)]\tLoss: 173.049606\n",
            "Train Epoch: 147 [203520/232365 (88%)]\tLoss: 174.286469\n",
            "Train Epoch: 147 [204800/232365 (88%)]\tLoss: 170.568237\n",
            "Train Epoch: 147 [206080/232365 (89%)]\tLoss: 162.726547\n",
            "Train Epoch: 147 [207360/232365 (89%)]\tLoss: 172.655762\n",
            "Train Epoch: 147 [208640/232365 (90%)]\tLoss: 177.593231\n",
            "Train Epoch: 147 [209920/232365 (90%)]\tLoss: 165.070755\n",
            "Train Epoch: 147 [211200/232365 (91%)]\tLoss: 176.675171\n",
            "Train Epoch: 147 [212480/232365 (91%)]\tLoss: 185.806992\n",
            "Train Epoch: 147 [213760/232365 (92%)]\tLoss: 163.420837\n",
            "Train Epoch: 147 [215040/232365 (93%)]\tLoss: 173.874008\n",
            "Train Epoch: 147 [216320/232365 (93%)]\tLoss: 172.389099\n",
            "Train Epoch: 147 [217600/232365 (94%)]\tLoss: 168.740646\n",
            "Train Epoch: 147 [218880/232365 (94%)]\tLoss: 166.004181\n",
            "Train Epoch: 147 [220160/232365 (95%)]\tLoss: 174.038406\n",
            "Train Epoch: 147 [221440/232365 (95%)]\tLoss: 182.713455\n",
            "Train Epoch: 147 [222720/232365 (96%)]\tLoss: 181.886398\n",
            "Train Epoch: 147 [224000/232365 (96%)]\tLoss: 172.761368\n",
            "Train Epoch: 147 [225280/232365 (97%)]\tLoss: 167.441132\n",
            "Train Epoch: 147 [226560/232365 (97%)]\tLoss: 172.590240\n",
            "Train Epoch: 147 [227840/232365 (98%)]\tLoss: 171.784592\n",
            "Train Epoch: 147 [229120/232365 (99%)]\tLoss: 161.275986\n",
            "Train Epoch: 147 [230400/232365 (99%)]\tLoss: 169.323090\n",
            "Train Epoch: 147 [231680/232365 (100%)]\tLoss: 171.936615\n",
            "====> Epoch: 147 Average loss: 172.4032, Accuracy: 74.24%\n",
            "====> Test set loss: 183.6211, Accuracy: 74.12%\n",
            "Train Epoch: 148 [0/232365 (0%)]\tLoss: 165.064072\n",
            "Train Epoch: 148 [1280/232365 (1%)]\tLoss: 171.950760\n",
            "Train Epoch: 148 [2560/232365 (1%)]\tLoss: 168.036224\n",
            "Train Epoch: 148 [3840/232365 (2%)]\tLoss: 172.465836\n",
            "Train Epoch: 148 [5120/232365 (2%)]\tLoss: 174.054276\n",
            "Train Epoch: 148 [6400/232365 (3%)]\tLoss: 174.506454\n",
            "Train Epoch: 148 [7680/232365 (3%)]\tLoss: 176.690659\n",
            "Train Epoch: 148 [8960/232365 (4%)]\tLoss: 172.310196\n",
            "Train Epoch: 148 [10240/232365 (4%)]\tLoss: 177.367722\n",
            "Train Epoch: 148 [11520/232365 (5%)]\tLoss: 162.114868\n",
            "Train Epoch: 148 [12800/232365 (6%)]\tLoss: 174.235382\n",
            "Train Epoch: 148 [14080/232365 (6%)]\tLoss: 172.169907\n",
            "Train Epoch: 148 [15360/232365 (7%)]\tLoss: 172.490921\n",
            "Train Epoch: 148 [16640/232365 (7%)]\tLoss: 178.501022\n",
            "Train Epoch: 148 [17920/232365 (8%)]\tLoss: 170.493713\n",
            "Train Epoch: 148 [19200/232365 (8%)]\tLoss: 159.739685\n",
            "Train Epoch: 148 [20480/232365 (9%)]\tLoss: 165.838730\n",
            "Train Epoch: 148 [21760/232365 (9%)]\tLoss: 169.394913\n",
            "Train Epoch: 148 [23040/232365 (10%)]\tLoss: 165.999756\n",
            "Train Epoch: 148 [24320/232365 (10%)]\tLoss: 168.096664\n",
            "Train Epoch: 148 [25600/232365 (11%)]\tLoss: 177.070862\n",
            "Train Epoch: 148 [26880/232365 (12%)]\tLoss: 173.429138\n",
            "Train Epoch: 148 [28160/232365 (12%)]\tLoss: 175.033447\n",
            "Train Epoch: 148 [29440/232365 (13%)]\tLoss: 171.854645\n",
            "Train Epoch: 148 [30720/232365 (13%)]\tLoss: 174.271454\n",
            "Train Epoch: 148 [32000/232365 (14%)]\tLoss: 170.050583\n",
            "Train Epoch: 148 [33280/232365 (14%)]\tLoss: 165.642639\n",
            "Train Epoch: 148 [34560/232365 (15%)]\tLoss: 176.519775\n",
            "Train Epoch: 148 [35840/232365 (15%)]\tLoss: 169.504242\n",
            "Train Epoch: 148 [37120/232365 (16%)]\tLoss: 173.859192\n",
            "Train Epoch: 148 [38400/232365 (17%)]\tLoss: 172.151260\n",
            "Train Epoch: 148 [39680/232365 (17%)]\tLoss: 171.746628\n",
            "Train Epoch: 148 [40960/232365 (18%)]\tLoss: 171.689728\n",
            "Train Epoch: 148 [42240/232365 (18%)]\tLoss: 176.004227\n",
            "Train Epoch: 148 [43520/232365 (19%)]\tLoss: 174.919876\n",
            "Train Epoch: 148 [44800/232365 (19%)]\tLoss: 178.164490\n",
            "Train Epoch: 148 [46080/232365 (20%)]\tLoss: 176.753143\n",
            "Train Epoch: 148 [47360/232365 (20%)]\tLoss: 171.416626\n",
            "Train Epoch: 148 [48640/232365 (21%)]\tLoss: 169.798157\n",
            "Train Epoch: 148 [49920/232365 (21%)]\tLoss: 166.722092\n",
            "Train Epoch: 148 [51200/232365 (22%)]\tLoss: 171.387100\n",
            "Train Epoch: 148 [52480/232365 (23%)]\tLoss: 180.461014\n",
            "Train Epoch: 148 [53760/232365 (23%)]\tLoss: 167.465286\n",
            "Train Epoch: 148 [55040/232365 (24%)]\tLoss: 175.258667\n",
            "Train Epoch: 148 [56320/232365 (24%)]\tLoss: 161.774002\n",
            "Train Epoch: 148 [57600/232365 (25%)]\tLoss: 167.727051\n",
            "Train Epoch: 148 [58880/232365 (25%)]\tLoss: 180.444962\n",
            "Train Epoch: 148 [60160/232365 (26%)]\tLoss: 175.210876\n",
            "Train Epoch: 148 [61440/232365 (26%)]\tLoss: 181.454468\n",
            "Train Epoch: 148 [62720/232365 (27%)]\tLoss: 168.170624\n",
            "Train Epoch: 148 [64000/232365 (28%)]\tLoss: 170.865479\n",
            "Train Epoch: 148 [65280/232365 (28%)]\tLoss: 167.175125\n",
            "Train Epoch: 148 [66560/232365 (29%)]\tLoss: 173.115768\n",
            "Train Epoch: 148 [67840/232365 (29%)]\tLoss: 178.325974\n",
            "Train Epoch: 148 [69120/232365 (30%)]\tLoss: 171.215836\n",
            "Train Epoch: 148 [70400/232365 (30%)]\tLoss: 178.554352\n",
            "Train Epoch: 148 [71680/232365 (31%)]\tLoss: 176.599075\n",
            "Train Epoch: 148 [72960/232365 (31%)]\tLoss: 172.048538\n",
            "Train Epoch: 148 [74240/232365 (32%)]\tLoss: 166.327866\n",
            "Train Epoch: 148 [75520/232365 (32%)]\tLoss: 173.567795\n",
            "Train Epoch: 148 [76800/232365 (33%)]\tLoss: 166.454880\n",
            "Train Epoch: 148 [78080/232365 (34%)]\tLoss: 171.604446\n",
            "Train Epoch: 148 [79360/232365 (34%)]\tLoss: 172.126709\n",
            "Train Epoch: 148 [80640/232365 (35%)]\tLoss: 172.525330\n",
            "Train Epoch: 148 [81920/232365 (35%)]\tLoss: 176.716980\n",
            "Train Epoch: 148 [83200/232365 (36%)]\tLoss: 173.861786\n",
            "Train Epoch: 148 [84480/232365 (36%)]\tLoss: 175.977249\n",
            "Train Epoch: 148 [85760/232365 (37%)]\tLoss: 179.507950\n",
            "Train Epoch: 148 [87040/232365 (37%)]\tLoss: 176.148148\n",
            "Train Epoch: 148 [88320/232365 (38%)]\tLoss: 165.212372\n",
            "Train Epoch: 148 [89600/232365 (39%)]\tLoss: 178.049835\n",
            "Train Epoch: 148 [90880/232365 (39%)]\tLoss: 176.359833\n",
            "Train Epoch: 148 [92160/232365 (40%)]\tLoss: 181.368027\n",
            "Train Epoch: 148 [93440/232365 (40%)]\tLoss: 180.077637\n",
            "Train Epoch: 148 [94720/232365 (41%)]\tLoss: 173.331757\n",
            "Train Epoch: 148 [96000/232365 (41%)]\tLoss: 175.081329\n",
            "Train Epoch: 148 [97280/232365 (42%)]\tLoss: 182.401047\n",
            "Train Epoch: 148 [98560/232365 (42%)]\tLoss: 170.926819\n",
            "Train Epoch: 148 [99840/232365 (43%)]\tLoss: 173.274323\n",
            "Train Epoch: 148 [101120/232365 (44%)]\tLoss: 165.353287\n",
            "Train Epoch: 148 [102400/232365 (44%)]\tLoss: 166.858383\n",
            "Train Epoch: 148 [103680/232365 (45%)]\tLoss: 168.910446\n",
            "Train Epoch: 148 [104960/232365 (45%)]\tLoss: 168.979401\n",
            "Train Epoch: 148 [106240/232365 (46%)]\tLoss: 169.551300\n",
            "Train Epoch: 148 [107520/232365 (46%)]\tLoss: 178.886841\n",
            "Train Epoch: 148 [108800/232365 (47%)]\tLoss: 166.762085\n",
            "Train Epoch: 148 [110080/232365 (47%)]\tLoss: 165.663803\n",
            "Train Epoch: 148 [111360/232365 (48%)]\tLoss: 175.667435\n",
            "Train Epoch: 148 [112640/232365 (48%)]\tLoss: 177.313812\n",
            "Train Epoch: 148 [113920/232365 (49%)]\tLoss: 175.579880\n",
            "Train Epoch: 148 [115200/232365 (50%)]\tLoss: 170.480286\n",
            "Train Epoch: 148 [116480/232365 (50%)]\tLoss: 166.519043\n",
            "Train Epoch: 148 [117760/232365 (51%)]\tLoss: 166.602295\n",
            "Train Epoch: 148 [119040/232365 (51%)]\tLoss: 173.272324\n",
            "Train Epoch: 148 [120320/232365 (52%)]\tLoss: 162.919830\n",
            "Train Epoch: 148 [121600/232365 (52%)]\tLoss: 173.228241\n",
            "Train Epoch: 148 [122880/232365 (53%)]\tLoss: 164.140137\n",
            "Train Epoch: 148 [124160/232365 (53%)]\tLoss: 169.385910\n",
            "Train Epoch: 148 [125440/232365 (54%)]\tLoss: 173.341858\n",
            "Train Epoch: 148 [126720/232365 (55%)]\tLoss: 173.517563\n",
            "Train Epoch: 148 [128000/232365 (55%)]\tLoss: 169.813095\n",
            "Train Epoch: 148 [129280/232365 (56%)]\tLoss: 183.650513\n",
            "Train Epoch: 148 [130560/232365 (56%)]\tLoss: 182.709122\n",
            "Train Epoch: 148 [131840/232365 (57%)]\tLoss: 172.649521\n",
            "Train Epoch: 148 [133120/232365 (57%)]\tLoss: 176.721878\n",
            "Train Epoch: 148 [134400/232365 (58%)]\tLoss: 172.413422\n",
            "Train Epoch: 148 [135680/232365 (58%)]\tLoss: 171.671524\n",
            "Train Epoch: 148 [136960/232365 (59%)]\tLoss: 170.275040\n",
            "Train Epoch: 148 [138240/232365 (59%)]\tLoss: 171.852539\n",
            "Train Epoch: 148 [139520/232365 (60%)]\tLoss: 167.681015\n",
            "Train Epoch: 148 [140800/232365 (61%)]\tLoss: 174.441406\n",
            "Train Epoch: 148 [142080/232365 (61%)]\tLoss: 179.950394\n",
            "Train Epoch: 148 [143360/232365 (62%)]\tLoss: 165.497192\n",
            "Train Epoch: 148 [144640/232365 (62%)]\tLoss: 165.776794\n",
            "Train Epoch: 148 [145920/232365 (63%)]\tLoss: 172.395584\n",
            "Train Epoch: 148 [147200/232365 (63%)]\tLoss: 171.403122\n",
            "Train Epoch: 148 [148480/232365 (64%)]\tLoss: 182.063080\n",
            "Train Epoch: 148 [149760/232365 (64%)]\tLoss: 173.918625\n",
            "Train Epoch: 148 [151040/232365 (65%)]\tLoss: 174.117798\n",
            "Train Epoch: 148 [152320/232365 (66%)]\tLoss: 172.495377\n",
            "Train Epoch: 148 [153600/232365 (66%)]\tLoss: 168.566528\n",
            "Train Epoch: 148 [154880/232365 (67%)]\tLoss: 168.981873\n",
            "Train Epoch: 148 [156160/232365 (67%)]\tLoss: 182.192261\n",
            "Train Epoch: 148 [157440/232365 (68%)]\tLoss: 173.874115\n",
            "Train Epoch: 148 [158720/232365 (68%)]\tLoss: 181.109756\n",
            "Train Epoch: 148 [160000/232365 (69%)]\tLoss: 182.128693\n",
            "Train Epoch: 148 [161280/232365 (69%)]\tLoss: 169.187088\n",
            "Train Epoch: 148 [162560/232365 (70%)]\tLoss: 170.154846\n",
            "Train Epoch: 148 [163840/232365 (70%)]\tLoss: 176.842529\n",
            "Train Epoch: 148 [165120/232365 (71%)]\tLoss: 168.844513\n",
            "Train Epoch: 148 [166400/232365 (72%)]\tLoss: 173.612015\n",
            "Train Epoch: 148 [167680/232365 (72%)]\tLoss: 168.182022\n",
            "Train Epoch: 148 [168960/232365 (73%)]\tLoss: 171.262924\n",
            "Train Epoch: 148 [170240/232365 (73%)]\tLoss: 175.883209\n",
            "Train Epoch: 148 [171520/232365 (74%)]\tLoss: 172.848450\n",
            "Train Epoch: 148 [172800/232365 (74%)]\tLoss: 171.616119\n",
            "Train Epoch: 148 [174080/232365 (75%)]\tLoss: 172.969940\n",
            "Train Epoch: 148 [175360/232365 (75%)]\tLoss: 179.314255\n",
            "Train Epoch: 148 [176640/232365 (76%)]\tLoss: 177.512238\n",
            "Train Epoch: 148 [177920/232365 (77%)]\tLoss: 168.498276\n",
            "Train Epoch: 148 [179200/232365 (77%)]\tLoss: 169.746857\n",
            "Train Epoch: 148 [180480/232365 (78%)]\tLoss: 175.680939\n",
            "Train Epoch: 148 [181760/232365 (78%)]\tLoss: 173.286148\n",
            "Train Epoch: 148 [183040/232365 (79%)]\tLoss: 171.655212\n",
            "Train Epoch: 148 [184320/232365 (79%)]\tLoss: 164.176132\n",
            "Train Epoch: 148 [185600/232365 (80%)]\tLoss: 170.877533\n",
            "Train Epoch: 148 [186880/232365 (80%)]\tLoss: 170.626541\n",
            "Train Epoch: 148 [188160/232365 (81%)]\tLoss: 175.515808\n",
            "Train Epoch: 148 [189440/232365 (81%)]\tLoss: 172.194229\n",
            "Train Epoch: 148 [190720/232365 (82%)]\tLoss: 170.527435\n",
            "Train Epoch: 148 [192000/232365 (83%)]\tLoss: 170.189362\n",
            "Train Epoch: 148 [193280/232365 (83%)]\tLoss: 168.342163\n",
            "Train Epoch: 148 [194560/232365 (84%)]\tLoss: 161.556137\n",
            "Train Epoch: 148 [195840/232365 (84%)]\tLoss: 174.048645\n",
            "Train Epoch: 148 [197120/232365 (85%)]\tLoss: 170.808807\n",
            "Train Epoch: 148 [198400/232365 (85%)]\tLoss: 172.146713\n",
            "Train Epoch: 148 [199680/232365 (86%)]\tLoss: 172.235352\n",
            "Train Epoch: 148 [200960/232365 (86%)]\tLoss: 175.632462\n",
            "Train Epoch: 148 [202240/232365 (87%)]\tLoss: 178.849167\n",
            "Train Epoch: 148 [203520/232365 (88%)]\tLoss: 175.659302\n",
            "Train Epoch: 148 [204800/232365 (88%)]\tLoss: 174.546982\n",
            "Train Epoch: 148 [206080/232365 (89%)]\tLoss: 177.647202\n",
            "Train Epoch: 148 [207360/232365 (89%)]\tLoss: 176.448898\n",
            "Train Epoch: 148 [208640/232365 (90%)]\tLoss: 166.049973\n",
            "Train Epoch: 148 [209920/232365 (90%)]\tLoss: 171.891785\n",
            "Train Epoch: 148 [211200/232365 (91%)]\tLoss: 166.631317\n",
            "Train Epoch: 148 [212480/232365 (91%)]\tLoss: 180.617310\n",
            "Train Epoch: 148 [213760/232365 (92%)]\tLoss: 171.660080\n",
            "Train Epoch: 148 [215040/232365 (93%)]\tLoss: 162.900986\n",
            "Train Epoch: 148 [216320/232365 (93%)]\tLoss: 169.147690\n",
            "Train Epoch: 148 [217600/232365 (94%)]\tLoss: 168.501923\n",
            "Train Epoch: 148 [218880/232365 (94%)]\tLoss: 173.723694\n",
            "Train Epoch: 148 [220160/232365 (95%)]\tLoss: 168.669952\n",
            "Train Epoch: 148 [221440/232365 (95%)]\tLoss: 173.511963\n",
            "Train Epoch: 148 [222720/232365 (96%)]\tLoss: 178.241806\n",
            "Train Epoch: 148 [224000/232365 (96%)]\tLoss: 180.065125\n",
            "Train Epoch: 148 [225280/232365 (97%)]\tLoss: 173.785522\n",
            "Train Epoch: 148 [226560/232365 (97%)]\tLoss: 164.525070\n",
            "Train Epoch: 148 [227840/232365 (98%)]\tLoss: 176.621094\n",
            "Train Epoch: 148 [229120/232365 (99%)]\tLoss: 171.989105\n",
            "Train Epoch: 148 [230400/232365 (99%)]\tLoss: 169.500580\n",
            "Train Epoch: 148 [231680/232365 (100%)]\tLoss: 171.332581\n",
            "====> Epoch: 148 Average loss: 172.4153, Accuracy: 74.24%\n",
            "====> Test set loss: 183.2861, Accuracy: 74.13%\n",
            "Train Epoch: 149 [0/232365 (0%)]\tLoss: 177.270782\n",
            "Train Epoch: 149 [1280/232365 (1%)]\tLoss: 168.859879\n",
            "Train Epoch: 149 [2560/232365 (1%)]\tLoss: 170.641968\n",
            "Train Epoch: 149 [3840/232365 (2%)]\tLoss: 178.676468\n",
            "Train Epoch: 149 [5120/232365 (2%)]\tLoss: 177.272034\n",
            "Train Epoch: 149 [6400/232365 (3%)]\tLoss: 181.969528\n",
            "Train Epoch: 149 [7680/232365 (3%)]\tLoss: 174.055847\n",
            "Train Epoch: 149 [8960/232365 (4%)]\tLoss: 166.842102\n",
            "Train Epoch: 149 [10240/232365 (4%)]\tLoss: 174.877411\n",
            "Train Epoch: 149 [11520/232365 (5%)]\tLoss: 175.772400\n",
            "Train Epoch: 149 [12800/232365 (6%)]\tLoss: 182.074341\n",
            "Train Epoch: 149 [14080/232365 (6%)]\tLoss: 170.766922\n",
            "Train Epoch: 149 [15360/232365 (7%)]\tLoss: 170.947632\n",
            "Train Epoch: 149 [16640/232365 (7%)]\tLoss: 170.986115\n",
            "Train Epoch: 149 [17920/232365 (8%)]\tLoss: 180.180756\n",
            "Train Epoch: 149 [19200/232365 (8%)]\tLoss: 165.411133\n",
            "Train Epoch: 149 [20480/232365 (9%)]\tLoss: 179.472076\n",
            "Train Epoch: 149 [21760/232365 (9%)]\tLoss: 170.022247\n",
            "Train Epoch: 149 [23040/232365 (10%)]\tLoss: 173.170410\n",
            "Train Epoch: 149 [24320/232365 (10%)]\tLoss: 174.899582\n",
            "Train Epoch: 149 [25600/232365 (11%)]\tLoss: 168.591095\n",
            "Train Epoch: 149 [26880/232365 (12%)]\tLoss: 175.178101\n",
            "Train Epoch: 149 [28160/232365 (12%)]\tLoss: 172.742218\n",
            "Train Epoch: 149 [29440/232365 (13%)]\tLoss: 180.969849\n",
            "Train Epoch: 149 [30720/232365 (13%)]\tLoss: 167.256668\n",
            "Train Epoch: 149 [32000/232365 (14%)]\tLoss: 181.691498\n",
            "Train Epoch: 149 [33280/232365 (14%)]\tLoss: 167.156784\n",
            "Train Epoch: 149 [34560/232365 (15%)]\tLoss: 167.977875\n",
            "Train Epoch: 149 [35840/232365 (15%)]\tLoss: 172.569305\n",
            "Train Epoch: 149 [37120/232365 (16%)]\tLoss: 169.750824\n",
            "Train Epoch: 149 [38400/232365 (17%)]\tLoss: 174.092316\n",
            "Train Epoch: 149 [39680/232365 (17%)]\tLoss: 173.673401\n",
            "Train Epoch: 149 [40960/232365 (18%)]\tLoss: 166.202087\n",
            "Train Epoch: 149 [42240/232365 (18%)]\tLoss: 163.650711\n",
            "Train Epoch: 149 [43520/232365 (19%)]\tLoss: 169.685242\n",
            "Train Epoch: 149 [44800/232365 (19%)]\tLoss: 173.838394\n",
            "Train Epoch: 149 [46080/232365 (20%)]\tLoss: 177.838364\n",
            "Train Epoch: 149 [47360/232365 (20%)]\tLoss: 171.198624\n",
            "Train Epoch: 149 [48640/232365 (21%)]\tLoss: 157.061691\n",
            "Train Epoch: 149 [49920/232365 (21%)]\tLoss: 160.532013\n",
            "Train Epoch: 149 [51200/232365 (22%)]\tLoss: 167.445694\n",
            "Train Epoch: 149 [52480/232365 (23%)]\tLoss: 165.065796\n",
            "Train Epoch: 149 [53760/232365 (23%)]\tLoss: 178.396133\n",
            "Train Epoch: 149 [55040/232365 (24%)]\tLoss: 174.135620\n",
            "Train Epoch: 149 [56320/232365 (24%)]\tLoss: 173.241379\n",
            "Train Epoch: 149 [57600/232365 (25%)]\tLoss: 181.070999\n",
            "Train Epoch: 149 [58880/232365 (25%)]\tLoss: 176.546371\n",
            "Train Epoch: 149 [60160/232365 (26%)]\tLoss: 172.093811\n",
            "Train Epoch: 149 [61440/232365 (26%)]\tLoss: 172.251770\n",
            "Train Epoch: 149 [62720/232365 (27%)]\tLoss: 176.538239\n",
            "Train Epoch: 149 [64000/232365 (28%)]\tLoss: 179.728317\n",
            "Train Epoch: 149 [65280/232365 (28%)]\tLoss: 170.528564\n",
            "Train Epoch: 149 [66560/232365 (29%)]\tLoss: 162.280884\n",
            "Train Epoch: 149 [67840/232365 (29%)]\tLoss: 174.053024\n",
            "Train Epoch: 149 [69120/232365 (30%)]\tLoss: 176.825363\n",
            "Train Epoch: 149 [70400/232365 (30%)]\tLoss: 175.853897\n",
            "Train Epoch: 149 [71680/232365 (31%)]\tLoss: 174.114929\n",
            "Train Epoch: 149 [72960/232365 (31%)]\tLoss: 179.039551\n",
            "Train Epoch: 149 [74240/232365 (32%)]\tLoss: 179.132660\n",
            "Train Epoch: 149 [75520/232365 (32%)]\tLoss: 176.284042\n",
            "Train Epoch: 149 [76800/232365 (33%)]\tLoss: 182.049530\n",
            "Train Epoch: 149 [78080/232365 (34%)]\tLoss: 166.907776\n",
            "Train Epoch: 149 [79360/232365 (34%)]\tLoss: 179.702744\n",
            "Train Epoch: 149 [80640/232365 (35%)]\tLoss: 167.006134\n",
            "Train Epoch: 149 [81920/232365 (35%)]\tLoss: 174.225281\n",
            "Train Epoch: 149 [83200/232365 (36%)]\tLoss: 174.676208\n",
            "Train Epoch: 149 [84480/232365 (36%)]\tLoss: 178.725342\n",
            "Train Epoch: 149 [85760/232365 (37%)]\tLoss: 168.271484\n",
            "Train Epoch: 149 [87040/232365 (37%)]\tLoss: 176.748535\n",
            "Train Epoch: 149 [88320/232365 (38%)]\tLoss: 178.981216\n",
            "Train Epoch: 149 [89600/232365 (39%)]\tLoss: 176.032410\n",
            "Train Epoch: 149 [90880/232365 (39%)]\tLoss: 174.930435\n",
            "Train Epoch: 149 [92160/232365 (40%)]\tLoss: 165.803802\n",
            "Train Epoch: 149 [93440/232365 (40%)]\tLoss: 168.087524\n",
            "Train Epoch: 149 [94720/232365 (41%)]\tLoss: 158.080612\n",
            "Train Epoch: 149 [96000/232365 (41%)]\tLoss: 164.470474\n",
            "Train Epoch: 149 [97280/232365 (42%)]\tLoss: 181.103302\n",
            "Train Epoch: 149 [98560/232365 (42%)]\tLoss: 178.484711\n",
            "Train Epoch: 149 [99840/232365 (43%)]\tLoss: 173.526855\n",
            "Train Epoch: 149 [101120/232365 (44%)]\tLoss: 171.532684\n",
            "Train Epoch: 149 [102400/232365 (44%)]\tLoss: 177.055771\n",
            "Train Epoch: 149 [103680/232365 (45%)]\tLoss: 166.152084\n",
            "Train Epoch: 149 [104960/232365 (45%)]\tLoss: 178.802078\n",
            "Train Epoch: 149 [106240/232365 (46%)]\tLoss: 164.640121\n",
            "Train Epoch: 149 [107520/232365 (46%)]\tLoss: 164.912170\n",
            "Train Epoch: 149 [108800/232365 (47%)]\tLoss: 174.200623\n",
            "Train Epoch: 149 [110080/232365 (47%)]\tLoss: 178.653992\n",
            "Train Epoch: 149 [111360/232365 (48%)]\tLoss: 169.009735\n",
            "Train Epoch: 149 [112640/232365 (48%)]\tLoss: 175.387970\n",
            "Train Epoch: 149 [113920/232365 (49%)]\tLoss: 167.002029\n",
            "Train Epoch: 149 [115200/232365 (50%)]\tLoss: 166.150574\n",
            "Train Epoch: 149 [116480/232365 (50%)]\tLoss: 171.769608\n",
            "Train Epoch: 149 [117760/232365 (51%)]\tLoss: 165.008530\n",
            "Train Epoch: 149 [119040/232365 (51%)]\tLoss: 170.737640\n",
            "Train Epoch: 149 [120320/232365 (52%)]\tLoss: 171.543564\n",
            "Train Epoch: 149 [121600/232365 (52%)]\tLoss: 165.336594\n",
            "Train Epoch: 149 [122880/232365 (53%)]\tLoss: 179.820694\n",
            "Train Epoch: 149 [124160/232365 (53%)]\tLoss: 173.743973\n",
            "Train Epoch: 149 [125440/232365 (54%)]\tLoss: 172.250259\n",
            "Train Epoch: 149 [126720/232365 (55%)]\tLoss: 161.365952\n",
            "Train Epoch: 149 [128000/232365 (55%)]\tLoss: 168.748764\n",
            "Train Epoch: 149 [129280/232365 (56%)]\tLoss: 167.073761\n",
            "Train Epoch: 149 [130560/232365 (56%)]\tLoss: 170.490631\n",
            "Train Epoch: 149 [131840/232365 (57%)]\tLoss: 174.134247\n",
            "Train Epoch: 149 [133120/232365 (57%)]\tLoss: 164.004883\n",
            "Train Epoch: 149 [134400/232365 (58%)]\tLoss: 172.384598\n",
            "Train Epoch: 149 [135680/232365 (58%)]\tLoss: 175.653152\n",
            "Train Epoch: 149 [136960/232365 (59%)]\tLoss: 170.603455\n",
            "Train Epoch: 149 [138240/232365 (59%)]\tLoss: 167.927414\n",
            "Train Epoch: 149 [139520/232365 (60%)]\tLoss: 170.522919\n",
            "Train Epoch: 149 [140800/232365 (61%)]\tLoss: 162.957367\n",
            "Train Epoch: 149 [142080/232365 (61%)]\tLoss: 172.959915\n",
            "Train Epoch: 149 [143360/232365 (62%)]\tLoss: 182.018875\n",
            "Train Epoch: 149 [144640/232365 (62%)]\tLoss: 180.299393\n",
            "Train Epoch: 149 [145920/232365 (63%)]\tLoss: 176.719803\n",
            "Train Epoch: 149 [147200/232365 (63%)]\tLoss: 174.183075\n",
            "Train Epoch: 149 [148480/232365 (64%)]\tLoss: 180.407471\n",
            "Train Epoch: 149 [149760/232365 (64%)]\tLoss: 177.263138\n",
            "Train Epoch: 149 [151040/232365 (65%)]\tLoss: 178.316116\n",
            "Train Epoch: 149 [152320/232365 (66%)]\tLoss: 169.768295\n",
            "Train Epoch: 149 [153600/232365 (66%)]\tLoss: 166.737289\n",
            "Train Epoch: 149 [154880/232365 (67%)]\tLoss: 180.248199\n",
            "Train Epoch: 149 [156160/232365 (67%)]\tLoss: 171.479080\n",
            "Train Epoch: 149 [157440/232365 (68%)]\tLoss: 180.026321\n",
            "Train Epoch: 149 [158720/232365 (68%)]\tLoss: 168.345901\n",
            "Train Epoch: 149 [160000/232365 (69%)]\tLoss: 171.125870\n",
            "Train Epoch: 149 [161280/232365 (69%)]\tLoss: 175.754562\n",
            "Train Epoch: 149 [162560/232365 (70%)]\tLoss: 178.058441\n",
            "Train Epoch: 149 [163840/232365 (70%)]\tLoss: 174.432770\n",
            "Train Epoch: 149 [165120/232365 (71%)]\tLoss: 167.102448\n",
            "Train Epoch: 149 [166400/232365 (72%)]\tLoss: 170.532837\n",
            "Train Epoch: 149 [167680/232365 (72%)]\tLoss: 176.876358\n",
            "Train Epoch: 149 [168960/232365 (73%)]\tLoss: 175.470230\n",
            "Train Epoch: 149 [170240/232365 (73%)]\tLoss: 172.819443\n",
            "Train Epoch: 149 [171520/232365 (74%)]\tLoss: 173.132431\n",
            "Train Epoch: 149 [172800/232365 (74%)]\tLoss: 166.050110\n",
            "Train Epoch: 149 [174080/232365 (75%)]\tLoss: 175.206772\n",
            "Train Epoch: 149 [175360/232365 (75%)]\tLoss: 162.116302\n",
            "Train Epoch: 149 [176640/232365 (76%)]\tLoss: 167.258743\n",
            "Train Epoch: 149 [177920/232365 (77%)]\tLoss: 181.469894\n",
            "Train Epoch: 149 [179200/232365 (77%)]\tLoss: 174.402863\n",
            "Train Epoch: 149 [180480/232365 (78%)]\tLoss: 166.260529\n",
            "Train Epoch: 149 [181760/232365 (78%)]\tLoss: 179.541962\n",
            "Train Epoch: 149 [183040/232365 (79%)]\tLoss: 174.405853\n",
            "Train Epoch: 149 [184320/232365 (79%)]\tLoss: 182.283340\n",
            "Train Epoch: 149 [185600/232365 (80%)]\tLoss: 165.493240\n",
            "Train Epoch: 149 [186880/232365 (80%)]\tLoss: 175.444977\n",
            "Train Epoch: 149 [188160/232365 (81%)]\tLoss: 182.047073\n",
            "Train Epoch: 149 [189440/232365 (81%)]\tLoss: 172.060883\n",
            "Train Epoch: 149 [190720/232365 (82%)]\tLoss: 174.713470\n",
            "Train Epoch: 149 [192000/232365 (83%)]\tLoss: 179.976501\n",
            "Train Epoch: 149 [193280/232365 (83%)]\tLoss: 166.353394\n",
            "Train Epoch: 149 [194560/232365 (84%)]\tLoss: 170.740723\n",
            "Train Epoch: 149 [195840/232365 (84%)]\tLoss: 172.507233\n",
            "Train Epoch: 149 [197120/232365 (85%)]\tLoss: 158.852753\n",
            "Train Epoch: 149 [198400/232365 (85%)]\tLoss: 174.729660\n",
            "Train Epoch: 149 [199680/232365 (86%)]\tLoss: 170.306793\n",
            "Train Epoch: 149 [200960/232365 (86%)]\tLoss: 176.090286\n",
            "Train Epoch: 149 [202240/232365 (87%)]\tLoss: 170.878418\n",
            "Train Epoch: 149 [203520/232365 (88%)]\tLoss: 178.235016\n",
            "Train Epoch: 149 [204800/232365 (88%)]\tLoss: 165.973068\n",
            "Train Epoch: 149 [206080/232365 (89%)]\tLoss: 175.052246\n",
            "Train Epoch: 149 [207360/232365 (89%)]\tLoss: 176.169220\n",
            "Train Epoch: 149 [208640/232365 (90%)]\tLoss: 174.351334\n",
            "Train Epoch: 149 [209920/232365 (90%)]\tLoss: 167.064590\n",
            "Train Epoch: 149 [211200/232365 (91%)]\tLoss: 172.844528\n",
            "Train Epoch: 149 [212480/232365 (91%)]\tLoss: 172.953568\n",
            "Train Epoch: 149 [213760/232365 (92%)]\tLoss: 175.532715\n",
            "Train Epoch: 149 [215040/232365 (93%)]\tLoss: 175.491730\n",
            "Train Epoch: 149 [216320/232365 (93%)]\tLoss: 166.363953\n",
            "Train Epoch: 149 [217600/232365 (94%)]\tLoss: 173.169891\n",
            "Train Epoch: 149 [218880/232365 (94%)]\tLoss: 165.507385\n",
            "Train Epoch: 149 [220160/232365 (95%)]\tLoss: 173.313690\n",
            "Train Epoch: 149 [221440/232365 (95%)]\tLoss: 167.841705\n",
            "Train Epoch: 149 [222720/232365 (96%)]\tLoss: 173.101471\n",
            "Train Epoch: 149 [224000/232365 (96%)]\tLoss: 188.504318\n",
            "Train Epoch: 149 [225280/232365 (97%)]\tLoss: 173.116089\n",
            "Train Epoch: 149 [226560/232365 (97%)]\tLoss: 177.883484\n",
            "Train Epoch: 149 [227840/232365 (98%)]\tLoss: 180.352295\n",
            "Train Epoch: 149 [229120/232365 (99%)]\tLoss: 182.170517\n",
            "Train Epoch: 149 [230400/232365 (99%)]\tLoss: 173.683807\n",
            "Train Epoch: 149 [231680/232365 (100%)]\tLoss: 169.560776\n",
            "====> Epoch: 149 Average loss: 172.4046, Accuracy: 74.24%\n",
            "====> Test set loss: 183.4241, Accuracy: 74.11%\n",
            "Train Epoch: 150 [0/232365 (0%)]\tLoss: 174.591934\n",
            "Train Epoch: 150 [1280/232365 (1%)]\tLoss: 178.223984\n",
            "Train Epoch: 150 [2560/232365 (1%)]\tLoss: 163.863953\n",
            "Train Epoch: 150 [3840/232365 (2%)]\tLoss: 172.907043\n",
            "Train Epoch: 150 [5120/232365 (2%)]\tLoss: 163.297485\n",
            "Train Epoch: 150 [6400/232365 (3%)]\tLoss: 178.432343\n",
            "Train Epoch: 150 [7680/232365 (3%)]\tLoss: 169.564240\n",
            "Train Epoch: 150 [8960/232365 (4%)]\tLoss: 170.040100\n",
            "Train Epoch: 150 [10240/232365 (4%)]\tLoss: 176.554718\n",
            "Train Epoch: 150 [11520/232365 (5%)]\tLoss: 175.529877\n",
            "Train Epoch: 150 [12800/232365 (6%)]\tLoss: 156.782562\n",
            "Train Epoch: 150 [14080/232365 (6%)]\tLoss: 170.880112\n",
            "Train Epoch: 150 [15360/232365 (7%)]\tLoss: 167.438248\n",
            "Train Epoch: 150 [16640/232365 (7%)]\tLoss: 166.838882\n",
            "Train Epoch: 150 [17920/232365 (8%)]\tLoss: 172.083008\n",
            "Train Epoch: 150 [19200/232365 (8%)]\tLoss: 177.647980\n",
            "Train Epoch: 150 [20480/232365 (9%)]\tLoss: 167.292557\n",
            "Train Epoch: 150 [21760/232365 (9%)]\tLoss: 171.242294\n",
            "Train Epoch: 150 [23040/232365 (10%)]\tLoss: 182.150528\n",
            "Train Epoch: 150 [24320/232365 (10%)]\tLoss: 169.872604\n",
            "Train Epoch: 150 [25600/232365 (11%)]\tLoss: 177.290924\n",
            "Train Epoch: 150 [26880/232365 (12%)]\tLoss: 167.405869\n",
            "Train Epoch: 150 [28160/232365 (12%)]\tLoss: 175.327805\n",
            "Train Epoch: 150 [29440/232365 (13%)]\tLoss: 175.073181\n",
            "Train Epoch: 150 [30720/232365 (13%)]\tLoss: 181.803711\n",
            "Train Epoch: 150 [32000/232365 (14%)]\tLoss: 178.522858\n",
            "Train Epoch: 150 [33280/232365 (14%)]\tLoss: 178.678284\n",
            "Train Epoch: 150 [34560/232365 (15%)]\tLoss: 170.548203\n",
            "Train Epoch: 150 [35840/232365 (15%)]\tLoss: 170.144562\n",
            "Train Epoch: 150 [37120/232365 (16%)]\tLoss: 169.301193\n",
            "Train Epoch: 150 [38400/232365 (17%)]\tLoss: 169.744995\n",
            "Train Epoch: 150 [39680/232365 (17%)]\tLoss: 170.807617\n",
            "Train Epoch: 150 [40960/232365 (18%)]\tLoss: 184.790131\n",
            "Train Epoch: 150 [42240/232365 (18%)]\tLoss: 167.007050\n",
            "Train Epoch: 150 [43520/232365 (19%)]\tLoss: 167.097488\n",
            "Train Epoch: 150 [44800/232365 (19%)]\tLoss: 177.075104\n",
            "Train Epoch: 150 [46080/232365 (20%)]\tLoss: 171.942017\n",
            "Train Epoch: 150 [47360/232365 (20%)]\tLoss: 182.564423\n",
            "Train Epoch: 150 [48640/232365 (21%)]\tLoss: 187.345566\n",
            "Train Epoch: 150 [49920/232365 (21%)]\tLoss: 168.261292\n",
            "Train Epoch: 150 [51200/232365 (22%)]\tLoss: 165.763596\n",
            "Train Epoch: 150 [52480/232365 (23%)]\tLoss: 168.813354\n",
            "Train Epoch: 150 [53760/232365 (23%)]\tLoss: 179.329514\n",
            "Train Epoch: 150 [55040/232365 (24%)]\tLoss: 165.663162\n",
            "Train Epoch: 150 [56320/232365 (24%)]\tLoss: 178.958130\n",
            "Train Epoch: 150 [57600/232365 (25%)]\tLoss: 166.422272\n",
            "Train Epoch: 150 [58880/232365 (25%)]\tLoss: 159.876221\n",
            "Train Epoch: 150 [60160/232365 (26%)]\tLoss: 161.428711\n",
            "Train Epoch: 150 [61440/232365 (26%)]\tLoss: 165.508972\n",
            "Train Epoch: 150 [62720/232365 (27%)]\tLoss: 174.546051\n",
            "Train Epoch: 150 [64000/232365 (28%)]\tLoss: 184.124908\n",
            "Train Epoch: 150 [65280/232365 (28%)]\tLoss: 177.223129\n",
            "Train Epoch: 150 [66560/232365 (29%)]\tLoss: 170.791763\n",
            "Train Epoch: 150 [67840/232365 (29%)]\tLoss: 167.560135\n",
            "Train Epoch: 150 [69120/232365 (30%)]\tLoss: 179.317215\n",
            "Train Epoch: 150 [70400/232365 (30%)]\tLoss: 173.047943\n",
            "Train Epoch: 150 [71680/232365 (31%)]\tLoss: 179.487106\n",
            "Train Epoch: 150 [72960/232365 (31%)]\tLoss: 175.684723\n",
            "Train Epoch: 150 [74240/232365 (32%)]\tLoss: 173.914413\n",
            "Train Epoch: 150 [75520/232365 (32%)]\tLoss: 173.687973\n",
            "Train Epoch: 150 [76800/232365 (33%)]\tLoss: 169.784378\n",
            "Train Epoch: 150 [78080/232365 (34%)]\tLoss: 168.041779\n",
            "Train Epoch: 150 [79360/232365 (34%)]\tLoss: 166.835403\n",
            "Train Epoch: 150 [80640/232365 (35%)]\tLoss: 165.644348\n",
            "Train Epoch: 150 [81920/232365 (35%)]\tLoss: 162.925308\n",
            "Train Epoch: 150 [83200/232365 (36%)]\tLoss: 179.452606\n",
            "Train Epoch: 150 [84480/232365 (36%)]\tLoss: 164.497971\n",
            "Train Epoch: 150 [85760/232365 (37%)]\tLoss: 173.309769\n",
            "Train Epoch: 150 [87040/232365 (37%)]\tLoss: 178.366226\n",
            "Train Epoch: 150 [88320/232365 (38%)]\tLoss: 179.722748\n",
            "Train Epoch: 150 [89600/232365 (39%)]\tLoss: 170.670425\n",
            "Train Epoch: 150 [90880/232365 (39%)]\tLoss: 171.084320\n",
            "Train Epoch: 150 [92160/232365 (40%)]\tLoss: 164.684265\n",
            "Train Epoch: 150 [93440/232365 (40%)]\tLoss: 167.762726\n",
            "Train Epoch: 150 [94720/232365 (41%)]\tLoss: 169.227951\n",
            "Train Epoch: 150 [96000/232365 (41%)]\tLoss: 168.146561\n",
            "Train Epoch: 150 [97280/232365 (42%)]\tLoss: 174.274353\n",
            "Train Epoch: 150 [98560/232365 (42%)]\tLoss: 172.519989\n",
            "Train Epoch: 150 [99840/232365 (43%)]\tLoss: 169.294128\n",
            "Train Epoch: 150 [101120/232365 (44%)]\tLoss: 168.507828\n",
            "Train Epoch: 150 [102400/232365 (44%)]\tLoss: 165.159012\n",
            "Train Epoch: 150 [103680/232365 (45%)]\tLoss: 172.150833\n",
            "Train Epoch: 150 [104960/232365 (45%)]\tLoss: 170.900543\n",
            "Train Epoch: 150 [106240/232365 (46%)]\tLoss: 170.968109\n",
            "Train Epoch: 150 [107520/232365 (46%)]\tLoss: 171.361420\n",
            "Train Epoch: 150 [108800/232365 (47%)]\tLoss: 171.689133\n",
            "Train Epoch: 150 [110080/232365 (47%)]\tLoss: 168.932098\n",
            "Train Epoch: 150 [111360/232365 (48%)]\tLoss: 176.715622\n",
            "Train Epoch: 150 [112640/232365 (48%)]\tLoss: 173.644104\n",
            "Train Epoch: 150 [113920/232365 (49%)]\tLoss: 187.573700\n",
            "Train Epoch: 150 [115200/232365 (50%)]\tLoss: 172.492935\n",
            "Train Epoch: 150 [116480/232365 (50%)]\tLoss: 171.942993\n",
            "Train Epoch: 150 [117760/232365 (51%)]\tLoss: 177.245743\n",
            "Train Epoch: 150 [119040/232365 (51%)]\tLoss: 181.105606\n",
            "Train Epoch: 150 [120320/232365 (52%)]\tLoss: 171.880646\n",
            "Train Epoch: 150 [121600/232365 (52%)]\tLoss: 172.227692\n",
            "Train Epoch: 150 [122880/232365 (53%)]\tLoss: 168.459763\n",
            "Train Epoch: 150 [124160/232365 (53%)]\tLoss: 174.835648\n",
            "Train Epoch: 150 [125440/232365 (54%)]\tLoss: 167.952316\n",
            "Train Epoch: 150 [126720/232365 (55%)]\tLoss: 181.523193\n",
            "Train Epoch: 150 [128000/232365 (55%)]\tLoss: 176.503555\n",
            "Train Epoch: 150 [129280/232365 (56%)]\tLoss: 167.343781\n",
            "Train Epoch: 150 [130560/232365 (56%)]\tLoss: 163.671585\n",
            "Train Epoch: 150 [131840/232365 (57%)]\tLoss: 173.712570\n",
            "Train Epoch: 150 [133120/232365 (57%)]\tLoss: 173.033661\n",
            "Train Epoch: 150 [134400/232365 (58%)]\tLoss: 170.797791\n",
            "Train Epoch: 150 [135680/232365 (58%)]\tLoss: 175.578049\n",
            "Train Epoch: 150 [136960/232365 (59%)]\tLoss: 171.379532\n",
            "Train Epoch: 150 [138240/232365 (59%)]\tLoss: 183.407944\n",
            "Train Epoch: 150 [139520/232365 (60%)]\tLoss: 176.606857\n",
            "Train Epoch: 150 [140800/232365 (61%)]\tLoss: 173.390503\n",
            "Train Epoch: 150 [142080/232365 (61%)]\tLoss: 174.384033\n",
            "Train Epoch: 150 [143360/232365 (62%)]\tLoss: 177.857910\n",
            "Train Epoch: 150 [144640/232365 (62%)]\tLoss: 174.744095\n",
            "Train Epoch: 150 [145920/232365 (63%)]\tLoss: 180.459885\n",
            "Train Epoch: 150 [147200/232365 (63%)]\tLoss: 176.328796\n",
            "Train Epoch: 150 [148480/232365 (64%)]\tLoss: 171.913147\n",
            "Train Epoch: 150 [149760/232365 (64%)]\tLoss: 178.884430\n",
            "Train Epoch: 150 [151040/232365 (65%)]\tLoss: 170.496902\n",
            "Train Epoch: 150 [152320/232365 (66%)]\tLoss: 167.159729\n",
            "Train Epoch: 150 [153600/232365 (66%)]\tLoss: 165.837891\n",
            "Train Epoch: 150 [154880/232365 (67%)]\tLoss: 186.677231\n",
            "Train Epoch: 150 [156160/232365 (67%)]\tLoss: 165.389557\n",
            "Train Epoch: 150 [157440/232365 (68%)]\tLoss: 166.012817\n",
            "Train Epoch: 150 [158720/232365 (68%)]\tLoss: 168.890930\n",
            "Train Epoch: 150 [160000/232365 (69%)]\tLoss: 178.628571\n",
            "Train Epoch: 150 [161280/232365 (69%)]\tLoss: 179.087860\n",
            "Train Epoch: 150 [162560/232365 (70%)]\tLoss: 175.862900\n",
            "Train Epoch: 150 [163840/232365 (70%)]\tLoss: 172.806793\n",
            "Train Epoch: 150 [165120/232365 (71%)]\tLoss: 172.352371\n",
            "Train Epoch: 150 [166400/232365 (72%)]\tLoss: 176.460434\n",
            "Train Epoch: 150 [167680/232365 (72%)]\tLoss: 168.864166\n",
            "Train Epoch: 150 [168960/232365 (73%)]\tLoss: 174.852829\n",
            "Train Epoch: 150 [170240/232365 (73%)]\tLoss: 174.269104\n",
            "Train Epoch: 150 [171520/232365 (74%)]\tLoss: 166.615448\n",
            "Train Epoch: 150 [172800/232365 (74%)]\tLoss: 172.208710\n",
            "Train Epoch: 150 [174080/232365 (75%)]\tLoss: 167.047714\n",
            "Train Epoch: 150 [175360/232365 (75%)]\tLoss: 174.724594\n",
            "Train Epoch: 150 [176640/232365 (76%)]\tLoss: 176.229080\n",
            "Train Epoch: 150 [177920/232365 (77%)]\tLoss: 168.458847\n",
            "Train Epoch: 150 [179200/232365 (77%)]\tLoss: 172.086792\n",
            "Train Epoch: 150 [180480/232365 (78%)]\tLoss: 174.718353\n",
            "Train Epoch: 150 [181760/232365 (78%)]\tLoss: 166.710846\n",
            "Train Epoch: 150 [183040/232365 (79%)]\tLoss: 170.008240\n",
            "Train Epoch: 150 [184320/232365 (79%)]\tLoss: 168.620499\n",
            "Train Epoch: 150 [185600/232365 (80%)]\tLoss: 178.856644\n",
            "Train Epoch: 150 [186880/232365 (80%)]\tLoss: 177.915207\n",
            "Train Epoch: 150 [188160/232365 (81%)]\tLoss: 175.914841\n",
            "Train Epoch: 150 [189440/232365 (81%)]\tLoss: 175.506088\n",
            "Train Epoch: 150 [190720/232365 (82%)]\tLoss: 169.055420\n",
            "Train Epoch: 150 [192000/232365 (83%)]\tLoss: 167.236710\n",
            "Train Epoch: 150 [193280/232365 (83%)]\tLoss: 166.570633\n",
            "Train Epoch: 150 [194560/232365 (84%)]\tLoss: 167.666977\n",
            "Train Epoch: 150 [195840/232365 (84%)]\tLoss: 172.108215\n",
            "Train Epoch: 150 [197120/232365 (85%)]\tLoss: 176.414673\n",
            "Train Epoch: 150 [198400/232365 (85%)]\tLoss: 172.979736\n",
            "Train Epoch: 150 [199680/232365 (86%)]\tLoss: 169.935196\n",
            "Train Epoch: 150 [200960/232365 (86%)]\tLoss: 167.641785\n",
            "Train Epoch: 150 [202240/232365 (87%)]\tLoss: 163.758804\n",
            "Train Epoch: 150 [203520/232365 (88%)]\tLoss: 166.684647\n",
            "Train Epoch: 150 [204800/232365 (88%)]\tLoss: 164.201538\n",
            "Train Epoch: 150 [206080/232365 (89%)]\tLoss: 170.686981\n",
            "Train Epoch: 150 [207360/232365 (89%)]\tLoss: 174.198120\n",
            "Train Epoch: 150 [208640/232365 (90%)]\tLoss: 168.513885\n",
            "Train Epoch: 150 [209920/232365 (90%)]\tLoss: 169.892303\n",
            "Train Epoch: 150 [211200/232365 (91%)]\tLoss: 171.078049\n",
            "Train Epoch: 150 [212480/232365 (91%)]\tLoss: 162.904572\n",
            "Train Epoch: 150 [213760/232365 (92%)]\tLoss: 182.891205\n",
            "Train Epoch: 150 [215040/232365 (93%)]\tLoss: 178.510056\n",
            "Train Epoch: 150 [216320/232365 (93%)]\tLoss: 176.291641\n",
            "Train Epoch: 150 [217600/232365 (94%)]\tLoss: 168.379700\n",
            "Train Epoch: 150 [218880/232365 (94%)]\tLoss: 179.404861\n",
            "Train Epoch: 150 [220160/232365 (95%)]\tLoss: 176.474182\n",
            "Train Epoch: 150 [221440/232365 (95%)]\tLoss: 175.683167\n",
            "Train Epoch: 150 [222720/232365 (96%)]\tLoss: 175.301743\n",
            "Train Epoch: 150 [224000/232365 (96%)]\tLoss: 175.505066\n",
            "Train Epoch: 150 [225280/232365 (97%)]\tLoss: 164.522675\n",
            "Train Epoch: 150 [226560/232365 (97%)]\tLoss: 170.999985\n",
            "Train Epoch: 150 [227840/232365 (98%)]\tLoss: 179.684479\n",
            "Train Epoch: 150 [229120/232365 (99%)]\tLoss: 176.656738\n",
            "Train Epoch: 150 [230400/232365 (99%)]\tLoss: 174.240265\n",
            "Train Epoch: 150 [231680/232365 (100%)]\tLoss: 179.525879\n",
            "====> Epoch: 150 Average loss: 172.4109, Accuracy: 74.24%\n",
            "====> Test set loss: 183.4830, Accuracy: 74.12%\n"
          ]
        }
      ],
      "source": [
        "# Model instantiation\n",
        "input_dim = 784  # 28x28 images flattened\n",
        "hidden_dim = 512\n",
        "latent_dim = 20\n",
        "label_dim = 49\n",
        "style_dim = 1\n",
        "\n",
        "model = CVAE(input_dim, hidden_dim, latent_dim, label_dim, style_dim)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training and testing functions\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, labels, styles) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data, labels, styles)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        pred = recon_batch.round()\n",
        "        correct += pred.eq(data.view_as(pred)).sum().item()\n",
        "        total += data.size(0) * data.size(1)\n",
        " \n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}')\n",
        "    accuracy = 100. * correct / total\n",
        "    print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, labels, styles in test_loader:\n",
        "            recon, mu, logvar = model(data, labels, styles)\n",
        "            test_loss += loss_function(recon, data, mu, logvar).item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred = recon.round()\n",
        "            correct += pred.eq(data.view_as(pred)).sum().item()\n",
        "            total += data.size(0) * data.size(1)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / total\n",
        "    print(f'====> Test set loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Training loop\n",
        "epochs = 150\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visualize Reconstructed Images from Trained C-VAE Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Pu1PC8kz2eUn"
      },
      "outputs": [],
      "source": [
        "# Visualize one reconstructed image from each class\n",
        "def visualize_reconstructions(model):\n",
        "    model.eval()\n",
        "    fig, axes = plt.subplots(7, 7, figsize=(5, 5))  # Match the figsize\n",
        "    for i in range(49):\n",
        "        idx = np.where(test_labels == i)[0][0]\n",
        "        data, labels, styles = test_imgs[idx], test_labels_one_hot[idx], test_styles[idx]\n",
        "        data, labels, styles = data.unsqueeze(0), labels.unsqueeze(0), styles.unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            recon, _, _ = model(data, labels, styles)\n",
        "        ax = axes[i // 7, i % 7]\n",
        "        ax.imshow(recon.view(28, 28).cpu().numpy(), cmap='gray', interpolation='none')\n",
        "        ax.axis('on')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.grid(False)  # Remove internal grids\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_edgecolor('black')  # Add border to the grid\n",
        "\n",
        "    # Add common x and y axis labels outside the image grid\n",
        "    fig.add_subplot(111, frameon=False)\n",
        "    plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
        "    plt.grid(False)\n",
        "    plt.suptitle(\"Reconstructed Images from Each Class\", fontsize=16)\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "qJLxnMeC2eUo",
        "outputId": "c4757864-08cf-433d-e09d-4a067e3ebf2e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 50 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize reconstructions\n",
        "visualize_reconstructions(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generate Characters using trained C-VAE model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OovQ_10z2eUo"
      },
      "outputs": [],
      "source": [
        "# Generate new images\n",
        "def generate_images(model, num_images, label, style):\n",
        "    model.eval()\n",
        "    labels_one_hot = F.one_hot(torch.tensor([label] * num_images), num_classes=label_dim).float()\n",
        "    styles = torch.tensor([style] * num_images).reshape(-1, 1)\n",
        "    z = torch.randn(num_images, latent_dim)\n",
        "    with torch.no_grad():\n",
        "        generated_imgs = model.decode(z, labels_one_hot, styles).cpu()\n",
        "    return generated_imgs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "ubK9dZFq2eUo",
        "outputId": "8e62b29d-b3d7-4b6f-c94d-e1cce48f2bfc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x200 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example: Generate new images of class 0 with style 'thin' (1)\n",
        "generated_imgs = generate_images(model, 10, 0, 1)\n",
        "\n",
        "# Plot the generated images\n",
        "plt.figure(figsize=(10, 2))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.imshow(generated_imgs[i].view(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
